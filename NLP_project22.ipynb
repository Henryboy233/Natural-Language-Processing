{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8df8807",
   "metadata": {},
   "source": [
    "# CITS 4012 - Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3bc00",
   "metadata": {},
   "source": [
    "### Henry Liu ( 22672083 ) <br> Harry Huang（ 22642989 ）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64618817",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009639a3",
   "metadata": {},
   "source": [
    "This project is to try out different neural language models on one NLP downsteam task: Document Classification. The dataset **`(seek_australia.csv)`** we use in this project contains job descriptions in natural language, alongside structured information about city, job categories, and salary scale. In this project, we attempt to unlock the information from text narratives in this dataset through document classifications. We have two tasks to do: **`1. Binary Document Classification.` 2. `Multi-class Document Classification`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b7995c",
   "metadata": {},
   "source": [
    "## Setup Libraries and load data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf541f33",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414ea3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6848ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0884a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/liugensheng/OneDrive - The University of Western Australia/2022 sem1/CITS4012 NLP/project2',\n",
       " '/Users/liugensheng/miniconda3/lib/python39.zip',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc0378",
   "metadata": {},
   "source": [
    "### Take a quick look at the data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e3193",
   "metadata": {},
   "source": [
    "**After loading the data, try to use some functions(*i.e. head(), describe()..*) to take a glance at the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5cea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"seek_australia.csv\")\n",
    "data = pd.read_csv(\"dataset/seek_australia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e10029b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ddc7894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category',\n",
       " 'city',\n",
       " 'company_name',\n",
       " 'geo',\n",
       " 'job_board',\n",
       " 'job_description',\n",
       " 'job_title',\n",
       " 'job_type',\n",
       " 'post_date',\n",
       " 'salary_offered',\n",
       " 'state',\n",
       " 'url']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd11e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data)) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4c3650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>company_name</th>\n",
       "      <th>geo</th>\n",
       "      <th>job_board</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "      <th>post_date</th>\n",
       "      <th>salary_offered</th>\n",
       "      <th>state</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail &amp; Consumer Products</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Frontline Executive Retail Sydney</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>Have you had 10 years experience in fresh pro...</td>\n",
       "      <td>Store Manager - Fresh Produce</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:13:45Z</td>\n",
       "      <td>$100k Base + Super + Benefits</td>\n",
       "      <td>North Shore &amp; Northern Beaches</td>\n",
       "      <td>https://www.seek.com.au/job/35989382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Government &amp; Defence</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Powerlink</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>The Opportunity: The Client Solution Analyst ...</td>\n",
       "      <td>Client Solution Analyst</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:04:40Z</td>\n",
       "      <td>Excellent remuneration packages</td>\n",
       "      <td>Northern Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35989272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Richard Jay Laundry</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>An innovative business development role for a...</td>\n",
       "      <td>Service Technician / Installer - NSW</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:04:31Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parramatta &amp; Western Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35989270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Adaptalift Hyster</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>About the role: We are seeking an Automotive W...</td>\n",
       "      <td>Workshop Technician I Material Handling Equipment</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-16T03:15:17Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside &amp; South Eastern Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35993203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Bakers Delight G&amp;M</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>Â Early starts and weekend shifts. No experie...</td>\n",
       "      <td>APPRENTICESHIP JUNIOR BAKER</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-16T01:26:50Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.seek.com.au/job/35991578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category       city                       company_name  \\\n",
       "0  Retail & Consumer Products     Sydney  Frontline Executive Retail Sydney   \n",
       "1        Government & Defence   Brisbane                          Powerlink   \n",
       "2           Trades & Services     Sydney                Richard Jay Laundry   \n",
       "3           Trades & Services  Melbourne                  Adaptalift Hyster   \n",
       "4           Trades & Services   Adelaide                 Bakers Delight G&M   \n",
       "\n",
       "  geo job_board                                    job_description  \\\n",
       "0  AU      seek   Have you had 10 years experience in fresh pro...   \n",
       "1  AU      seek   The Opportunity: The Client Solution Analyst ...   \n",
       "2  AU      seek   An innovative business development role for a...   \n",
       "3  AU      seek  About the role: We are seeking an Automotive W...   \n",
       "4  AU      seek   Â Early starts and weekend shifts. No experie...   \n",
       "\n",
       "                                           job_title   job_type  \\\n",
       "0                      Store Manager - Fresh Produce  Full Time   \n",
       "1                            Client Solution Analyst  Full Time   \n",
       "2               Service Technician / Installer - NSW  Full Time   \n",
       "3  Workshop Technician I Material Handling Equipment  Full Time   \n",
       "4                        APPRENTICESHIP JUNIOR BAKER  Full Time   \n",
       "\n",
       "              post_date                   salary_offered  \\\n",
       "0  2018-04-15T23:13:45Z    $100k Base + Super + Benefits   \n",
       "1  2018-04-15T23:04:40Z  Excellent remuneration packages   \n",
       "2  2018-04-15T23:04:31Z                              NaN   \n",
       "3  2018-04-16T03:15:17Z                              NaN   \n",
       "4  2018-04-16T01:26:50Z                              NaN   \n",
       "\n",
       "                             state                                   url  \n",
       "0   North Shore & Northern Beaches  https://www.seek.com.au/job/35989382  \n",
       "1                 Northern Suburbs  https://www.seek.com.au/job/35989272  \n",
       "2     Parramatta & Western Suburbs  https://www.seek.com.au/job/35989270  \n",
       "3  Bayside & South Eastern Suburbs  https://www.seek.com.au/job/35993203  \n",
       "4                              NaN  https://www.seek.com.au/job/35991578  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b418cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>company_name</th>\n",
       "      <th>geo</th>\n",
       "      <th>job_board</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "      <th>post_date</th>\n",
       "      <th>salary_offered</th>\n",
       "      <th>state</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>29655</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>8952</td>\n",
       "      <td>19180</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>9054</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26850</td>\n",
       "      <td>20979</td>\n",
       "      <td>4</td>\n",
       "      <td>24747</td>\n",
       "      <td>5373</td>\n",
       "      <td>19</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Private Advertiser</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>Today we have around 250 people who work to h...</td>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-16T09:29:00Z</td>\n",
       "      <td>$100,502 - $114,624</td>\n",
       "      <td>CBD &amp; Inner Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35989382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3346</td>\n",
       "      <td>9412</td>\n",
       "      <td>1491</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>101</td>\n",
       "      <td>122</td>\n",
       "      <td>20203</td>\n",
       "      <td>14</td>\n",
       "      <td>130</td>\n",
       "      <td>4690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category    city        company_name    geo job_board  \\\n",
       "count               30000   30000               30000  30000     30000   \n",
       "unique                 30      65                9054      1         1   \n",
       "top     Trades & Services  Sydney  Private Advertiser     AU      seek   \n",
       "freq                 3346    9412                1491  30000     30000   \n",
       "\n",
       "                                          job_description  \\\n",
       "count                                               29655   \n",
       "unique                                              26850   \n",
       "top      Today we have around 250 people who work to h...   \n",
       "freq                                                  101   \n",
       "\n",
       "                           job_title   job_type             post_date  \\\n",
       "count                          30000      30000                 30000   \n",
       "unique                         20979          4                 24747   \n",
       "top     Business Development Manager  Full Time  2018-04-16T09:29:00Z   \n",
       "freq                             122      20203                    14   \n",
       "\n",
       "             salary_offered                state  \\\n",
       "count                  8952                19180   \n",
       "unique                 5373                   19   \n",
       "top     $100,502 - $114,624  CBD & Inner Suburbs   \n",
       "freq                    130                 4690   \n",
       "\n",
       "                                         url  \n",
       "count                                  30000  \n",
       "unique                                 30000  \n",
       "top     https://www.seek.com.au/job/35989382  \n",
       "freq                                       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babdc9f0",
   "metadata": {},
   "source": [
    "**From *`describe()`* we can find that all data *`geo`* is *`AU`* and all *`job_board`* is *`seek`*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97dc33e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   category         30000 non-null  object\n",
      " 1   city             30000 non-null  object\n",
      " 2   company_name     30000 non-null  object\n",
      " 3   geo              30000 non-null  object\n",
      " 4   job_board        30000 non-null  object\n",
      " 5   job_description  29655 non-null  object\n",
      " 6   job_title        30000 non-null  object\n",
      " 7   job_type         30000 non-null  object\n",
      " 8   post_date        30000 non-null  object\n",
      " 9   salary_offered   8952 non-null   object\n",
      " 10  state            19180 non-null  object\n",
      " 11  url              30000 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5320f3f2",
   "metadata": {},
   "source": [
    "**Create two different functions(*`lexical_diversity()` and `tf()`*) to determine the weight**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e4cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c46a038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(text, token):\n",
    "    count = text.count(token) \n",
    "    total = len(text)\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e71bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95cdd5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Have you had 10 years experience in fresh pro...\n",
       "1         The Opportunity: The Client Solution Analyst ...\n",
       "2         An innovative business development role for a...\n",
       "3        About the role: We are seeking an Automotive W...\n",
       "4         Â Early starts and weekend shifts. No experie...\n",
       "                               ...                        \n",
       "29995     Hotel snapshot The Radisson Blu Plaza Sydney ...\n",
       "29996     The Organisation Airservices is a government ...\n",
       "29997    ABOUT THE COMPANY AND ROLE Our client is one o...\n",
       "29998     Long term contract for 12 months with possibl...\n",
       "29999     Customer Service Representative - (West Wyalo...\n",
       "Name: job_description, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0433fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "fw = open(\"job_description.txt\", 'w') #Export the address of the file to be saved\n",
    "fw.write(\"job_description\\n\")\n",
    "for line in data.job_description:    #Read the file\n",
    "        fw.write(str(line))   # Writing a string to a file\n",
    "        # line.rstrip(\"\\n\")To remove end-of-line newlines\n",
    "        fw.write(\"\\n\")    # line feed\n",
    "'''\n",
    "delimiter=\"\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7810530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_job = pd.read_csv(\"job_description.txt\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9f269",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467aefa",
   "metadata": {},
   "source": [
    "**Use gensim to train the word embeddings and TSNE to visualise some examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "857758e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# All Import Statements Defined Here # ----------------\n",
    "import sys\n",
    "assert sys.version_info[0]==3 \n",
    "assert sys.version_info[1] >= 5\n",
    "from gensim.models import KeyedVectors \n",
    "from gensim.test.utils import datapath \n",
    "import pprint\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [10, 5] \n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.decomposition import PCA\n",
    "START_TOKEN = '<START>' \n",
    "END_TOKEN = '<END>'\n",
    "np.random.seed(1212) \n",
    "random.seed(1212)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca0ca8",
   "metadata": {},
   "source": [
    "**Find distinct_words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9367c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Determine a list of distinct words for the corpus.\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "Return:\n",
    "corpus_words (list of strings): list of distinct words across the corpus,␣\n",
    "↪sorted (using python 'sorted' function)\n",
    "num_corpus_words (integer): number of distinct words across the corpus\n",
    "\"\"\"\n",
    "def distinct_words(corpus):\n",
    "\n",
    "    corpus_words = [] \n",
    "    num_corpus_words = -1\n",
    "# ------------------\n",
    "# Write your implementation here.\n",
    "    corpus_words = sorted(list(set([y for x in corpus for y in x])))\n",
    "    corpus_words = [y for x in corpus for y in x] \n",
    "    corpus_words = list(set(corpus_words)) # unique words \n",
    "    corpus_words = sorted(corpus_words) # sorts\n",
    "    num_corpus_words = len(corpus_words)\n",
    "    return corpus_words, num_corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "465c1807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Run this sanity check\n",
    "# Note that this not an exhaustive check for correctness. \n",
    "# Very simple tokenization using the Python string split \n",
    "# with space - string.split(\" \").\n",
    "# ---------------------\n",
    "# Define toy corpus\n",
    "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
    "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
    "# Correct answers\n",
    "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN])\n",
    "ans_num_corpus_words = len(ans_test_corpus_words)\n",
    "# Test correct number of words\n",
    "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. ↪ Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words)\n",
    "# Test correct words\n",
    "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours: {}\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
    "# Print Success\n",
    "print (\"-\" * 80) \n",
    "print(\"Passed All Tests!\") \n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f30a5",
   "metadata": {},
   "source": [
    "**Visualise the embeddings using plot_embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0d9add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
    "NOTE: do not plot all the words listed in M_reduced / word2Ind. Include a label next to each point.\n",
    "Params:\n",
    "M_reduced (numpy matrix of shape (number of unique words in the corpus , 2)): matrix of 2-dimensioal word embeddings\n",
    "word2Ind (dict): dictionary that maps word to indices for matrix M words (list of strings): words whose embeddings we want to visualize\n",
    "\"\"\"\n",
    "def plot_embeddings(M_reduced, word2Ind, words):\n",
    "\n",
    "# ------------------\n",
    "    import matplotlib.pyplot as plt \n",
    "    x_coords = M_reduced[:,0] \n",
    "    y_coords = M_reduced[:,1]\n",
    "    \n",
    "    for word in words:\n",
    "        i = word2Ind[word]\n",
    "        x = x_coords[i]\n",
    "        y = y_coords[i]\n",
    "        plt.scatter(x, y, color='r', marker='x') \n",
    "        plt.annotate(word, (x, y))\n",
    "    plt.show()\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d22c22d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab8ac1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'city', 'company_name', 'geo', 'job_board',\n",
       "       'job_description', 'job_title', 'job_type', 'post_date',\n",
       "       'salary_offered', 'state', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8234bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jot_category_map: {'Trades & Services': 0, 'Information & Communication Technology': 1, 'Healthcare & Medical': 2, 'Manufacturing, Transport & Logistics': 3, 'Administration & Office Support': 4, 'Accounting': 5, 'Hospitality & Tourism': 6, 'Sales': 7, 'Government & Defence': 8, 'Construction': 9, 'Education & Training': 10, 'Retail & Consumer Products': 11, 'Community Services & Development': 12, 'Mining, Resources & Energy': 13, 'Engineering': 14, 'Call Centre & Customer Service': 15, 'Banking & Financial Services': 16, 'Marketing & Communications': 17, 'Human Resources & Recruitment': 18, 'Real Estate & Property': 19, 'Legal': 20, 'Design & Architecture': 21, 'Insurance & Superannuation': 22, 'Advertising, Arts & Media': 23, 'Consulting & Strategy': 24, 'Science & Technology': 25, 'Sport & Recreation': 26, 'Farming, Animals & Conservation': 27, 'CEO & General Management': 28, 'Self Employment': 29}\n",
      "--------------------------------------------------------------------------------\n",
      "job_type_map: {'Full Time': 0, 'Contract/Temp': 1, 'Casual/Vacation': 1, 'Part Time': 1}\n"
     ]
    }
   ],
   "source": [
    "values = data['category'].value_counts()\n",
    "jot_category_map = {}\n",
    "for i, t in enumerate(values.keys()):\n",
    "    jot_category_map[t] = i\n",
    "print(\"jot_category_map:\", jot_category_map)\n",
    "print(80*'-')\n",
    "values = data['job_type'].value_counts()\n",
    "job_type_map = {}\n",
    "for t in values.keys():\n",
    "    if t == \"Full Time\":\n",
    "        job_type_map[t] = 0\n",
    "    else:\n",
    "        job_type_map[t] = 1\n",
    "print(\"job_type_map:\", job_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcaca636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before process\n",
      "  Have you had 10 years experience in fresh produce that wants to manage their own store for a family owned Australian company that is passionate about food. We are looking for: Must have 10+ years in the fresh food business and have the passion for the role. Current 2IC looking to progress with training into Store manager role. Excellent customer service and communication skills Be hands on and have a can do attitude Be into the fresh food business and have the passion for the role Hardworking, ambitious and competitive people who are passionate about good food. Are able to maximise the financial return in their market, ensuring it meets sales, margin and wages budgets. Have exceptional merchandising capabilities and customer service skills helping us to create unique shopping experiences for our customers. Have a wealth of knowledge of fresh food retailing and a willingness to share this knowledge. Can lead, manage and motivate a teams. Must be able to work weekend and use to early starts which is what fresh produce is all about Whats in it for you: Good salary package $100 K + super + benefits Fun and challenging work environment Great career opportunities Exceptional products and brand reputation Amazing teams Strong expanding business If this is you apply now, interviewing now To apply online, please click on the apply button. Alternatively, for a confidential discussion, please contact Sebastian Waddell on , quoting Ref No. 147061 or otherwise please check out our website for other available positions. www.frontlineretail.com.au \n",
      "\n",
      "after process:\n",
      " year experi fresh produc want manag store famili own australian compani passion food look year fresh food busi passion role current ic look progress train store manag role excel custom servic commun skill hand attitud fresh food busi passion role hardwork ambiti competit peopl passion good food abl maximis financi return market ensur meet sale margin wage budget except merchandis capabl custom servic skill help creat uniqu shop experi custom wealth knowledg fresh food retail willing share knowledg lead manag motiv team abl work weekend use earli start fresh produc what good salari packag k super benefit fun challeng work environ great career opportun except product brand reput amaz team strong expand busi appli interview appli onlin click appli button altern confidenti discus contact sebastian waddel quot ref check websit avail posit wwwfrontlineretailcomau\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn import feature_extraction \n",
    "stop_words = feature_extraction.text.ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess(text):\n",
    "  text = text.lower() #lowercase\n",
    "  text = re.sub(r'[^\\w\\s]', '', text) #remove punctuations\n",
    "  text = re.sub(r'\\d+', '', text) #remove numbers\n",
    "  text = re.sub(r'_', '', text) #remove numbers\n",
    "  text = \" \".join(text.split()) #stripWhitespace\n",
    "  text = text.split()\n",
    "  text = [x for x in text if x not in stop_words] #remove stopwords\n",
    "  text = [x for x in text if x not in [\"user\"]] #remove task specific stopwords\n",
    "  text = \" \".join(text)\n",
    "  \n",
    "  # extract the word stemmer, [\"creates\", \"cats\"] -> [\"creat\", \"cats\"]\n",
    "  # these words could not in dictionary.\n",
    "  stemmer_ps = PorterStemmer()  \n",
    "  text = [stemmer_ps.stem(word) for word in text.split()] #stemming\n",
    "  text = \" \".join(text)\n",
    "\n",
    "  # extract the word lemmatizer, [\"creates\", \"cats\"] -> [\"create\", \"cats\"]\n",
    "  # these words are all in dictionary.\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  text = [lemmatizer.lemmatize(word) for word in text.split()]  #lemmatization\n",
    "  text = \" \".join(text)\n",
    "  return(text)\n",
    "\n",
    "print(\"before process\\n\", data['job_description'][0])\n",
    "print()\n",
    "print(\"after process:\\n\", preprocess(data['job_description'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfc1b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[['job_description','job_type','category']].copy()\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# generate bi and mutli label for bi classific and multi classific respectively\n",
    "df['job_type']=df['job_type'].apply(lambda x: job_type_map[x]) \n",
    "df['category']=df['category'].apply(lambda x: jot_category_map[x]) \n",
    "\n",
    "# clean data and to tokenzier\n",
    "df['job_description']=df['job_description'].apply(lambda x:preprocess(x))\n",
    "\n",
    "# save\n",
    "df.to_csv(\"./dataset/job.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6825d",
   "metadata": {},
   "source": [
    "### Train and visualise my embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b11835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from utils import display_closestwords_tsnescatterplot, visual_wv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(\"./dataset/job.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(lambda x:x.split())\n",
    "\n",
    "my_embedding = Word2Vec(sentences=df['job_description'], min_count=1, window=5, vector_size=100, workers=10)\n",
    "# model = Word2Vec(senteces=df['description'], min_count=1, window=2, vector_size=100, sample=6e-5, alpha=0.03, min_alpha=0.0007, negative=20)\n",
    "\n",
    "my_embedding.save(\"./dataset/my_embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6d2a405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_closestwords_tsnescatterplot(my_embedding.wv, \"custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81e305f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAE/CAYAAADWuXIeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzpElEQVR4nO3de3QV5b3/8fc3IUa5GG9gLRiCrUohOwkQEKRYaASxIlh/Imq0YK3Bqqf2tEcEYysq1Es5lWI9trFaL0RF8QZelpd4pyomNpA2oKAmKKWCoikhIAl8f3/sSbqJuXAJSch8XmtlMfPMk5nvzF6Nnz7PzB5zd0REREQkPOLaugARERERaV0KgCIiIiIhowAoIiIiEjIKgCIiIiIhowAoIiIiEjIKgCIiIiIhowAoIvuEmc00s/ktuL8pZvZGS+0vzMwsxczczDq1dS0i0jYUAEVCwsxmmNmz9dpWNdJ2TutW176Z2T1mNquZPm5m326tmnaHmZWZ2cltXYeItB8KgCLh8RpwopnFA5jZUUACMKBe27eDvrtMI0kiIvsXBUCR8HiHaODLCNZHAC8D79Vr+8Dd/2lm3zSzRWa20cxWm9nFtTsKpncXmtl8M/s3MMXM+pjZq2a2ycxeAI6I6X9g0PdzM/vSzN4xsyMbKtLMjjazx8xsQ9D/D430OzHYT0Xw74kx26aY2YdBLR+ZWXbMth+b2Qoz+8LMnjOz3kG7mdmtZrbezP5tZiVmlmpmOUA2MM3MKs1scQO11AbmZUGfSUH7xcG12xhcy282+unsvL/aKdoLzezjoNZLzGywmS0PruEfYvp/y8xeCq7XZ2aWb2aHBNvuB5KBxUFt02IOlW1ma4Lfyd2V2kSkY1AAFAkJd98GvA2cFDSdBLwOvFGvrTbMPAR8AnwTOAv4jZl9P2aXE4CFwCFAPvAAUEQ0+N0ATI7pOxlIAo4GDgcuAbbUrzEYiXwKKAdSgJ5BHfX7HQY8DcwL9vc74GkzO9zMugTtp7p7N+BEoDj4vQnA1cCZQPfg/B8MdjsmOP/jglrPBj5397zg/G5x967ufnr9ety99vqlB30WBNfqxmA/RwXnVHcuZvaUmU2vv696TgCOBSYBc4Fc4GSgP3C2mX2vdnfBsb4JfIfodZ4Z1HYBsAY4Pajtlpj9fxc4HsgCfm1m32mmHhHpIBQARcLlVf4T9kYQDUCv12t71cyOBoYDV7n7VncvBv4M/ChmX2+6+xPuvoNomBoM/Mrdv3L314DYkbJqokHt2+6+3d2L3P3fDdQ3hGiIudLdNwfHbujBj9OAVe5+v7vXuPuDwEqgNpztAFLN7CB3X+fu/wjaLwFudPcV7l4D/AbICEYBq4FuQF/Agj7rmryaTcsG7nb3d939K2AGMMzMUgDcfZy739TMPm4IrsHzwGbgQXdf7+5riX5uA4J9rXb3F4Jrv4FoIP5e47utc527b3H3ZcAyIH1PTlRE9j8KgCLh8hrw3WAErbu7rwL+SvTewMOA1KDPN4GN7r4p5nfLiY7I1fo4ZvmbwBfuvrle/1r3A88BD5nZP83sFjNLaKC+o4HyIJw15Zv19l9XX1DDJKJhb52ZPW1mfYM+vYHfB1OoXwIbiY6e9XT3l4A/ALcD680sz8wObqaOXa7R3SuBz9n5Gjbn05jlLQ2sdwUwsyPN7CEzWxtMyc8nZgq+Cf+KWa6q3Z+IdHwKgCLh8ibR6c2LgSUAwUjcP4O2f7r7R8H6YWbWLeZ3k4G1Meses7wOODSYfo3tT3CMane/zt37EZ2SHcfOo4m1PgaSd+Ghkn8SDXOx6upz9+fcfTTRqdeVwJ0x+5/q7ofE/Bzk7n8Nfm+euw8C+hGdCr6ygXPdVTvVGFybw9n5GraU3xCtMeLuBwPnEw22tfakfhHpwBQARULE3bcAhcAviE4h1nojaHst6Pcx0ZHBG4MHONKAi4iOLDW03/Jgv9eZ2QFm9l3+Mx2LmY0ys0hwj9+/iU637mhgV0uJhsmbzKxLcOzhDfR7BjjOzM4zs07BQxf9gKeC0bAJQeD6CqiMOdYfgRlm1j+oK8nMJgbLg83shGBkcjOwNeb3PgWOaejcY9Tv8yBwoZllmFki0ZD2truXNbOfPdGN6HlWmFlP/hNcG6tNREJOAVAkfF4FehANfbVeD9piv/7lXKIPYvwTeBy41t1fbGK/5xF9aGEjcC1wX8y2bxB9YOTfwIqghvvr78DdtxMNjt8m+uDCJ0Snc+v3+5zoKOIviU6rTgPGuftnRP+u/SKoeyPRe+F+Gvze48DNRKei/w38HTg12O3BREcKvyA6dfs58Ntg211Av2Dq+IlGzn8mcG/Q5+zgWv0KeJRoqP0WUPf9imb2rJld3ci+dtd1wECggujDMY/V234jcE1Q2/+00DFFZD9m7poZEBEREQkTjQCKiIiIhIwCoIiIiEjIKACKiIiIhIwCoIiIiEjIKACKiIiIhExzX7baLhxxxBGekpLS1mWIiIiINKuoqOgzd+/e1nU0Zb8IgCkpKRQWFrZ1GSIiIiLNMrP6r6psdzQFLCIiIhIyCoAiIiIiIaMAKCIiIhIyCoAiIiIiIaMAKCIiIhIyCoAiIrLPjBw5Ut/iINIOKQCKiIiIhIwCoIiI7CS/JJ+UuSnEXRdHytwU8kvyd9o+f/58hgwZQkZGBlOnTmX79u389Kc/JTMzk/79+3Pttde2UeUisqsUAEVEpE5+ST45i3MoryjHccoryslZnFMXAlesWMGCBQtYsmQJxcXFxMfHk5+fz+zZsyksLGT58uW8+uqrLF++vI3PRESasl+8CURERFpHbkEuVdVVO7VVVVeRW5BLdiSbgoICioqKGDx4MABbtmyhR48ePPzww+Tl5VFTU8O6desoLS0lLS2tLU5BRHaBAqCIiNRZU7GmyXZ3Z/Lkydx444112z766CNGjx7NO++8w6GHHsqUKVPYunVrq9QrIntGU8AiIlInOSm5yfasrCwWLlzI+vXrAdi4cSNr1qyhS5cuJCUl8emnn/Lss8+2Wr0ismcUAEVEpM7srNl0Tui8U1vnhM7MzpoNQL9+/Zg1axZjxowhLS2N0aNHk5iYyIABA+jbty/nnXcew4cPb4vSRWQ3mLu3dQ3NyszMdH2PlIhI68gvySe3IJc1FWtITkpmdtZssiPZbV2WyH7DzIrcPbOt62iKAqCIiIhIC9ofAqCmgEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGRaLACaWbyZ/c3MngrW+5jZ22a22swWmNkBQXtisL462J7SUjWIiIiISPNacgTwCmBFzPrNwK3u/m3gC+CioP0i4Iug/dagn4iIiIi0khYJgGbWCzgN+HOwbsD3gYVBl3uBM4LlCcE6wfasoL+IiIiItIKWGgGcC0wDdgTrhwNfuntNsP4J0DNY7gl8DBBsrwj6i4iIiEgr2OsAaGbjgPXuXtQC9cTuN8fMCs2scMOGDS25axEREZFQa4kRwOHAeDMrAx4iOvX7e+AQM+sU9OkFrA2W1wJHAwTbk4DP6+/U3fPcPdPdM7t3794CZYqIiIgItEAAdPcZ7t7L3VOAc4CX3D0beBk4K+g2GXgyWF4UrBNsf8ndfW/rEGlr+SX5pMxNIe66OFLmppBfkr/T9unTp3P77bfXrc+cOZM5c+Zw8803E4lESE9PZ/r06QB88MEHjB07lkGDBjFixAhWrlzZquciIiId2778HsCrgF+Y2Wqi9/jdFbTfBRwetP8CmL4PaxBpFfkl+eQszqG8ohzHKa8oJ2dxzk4hcNKkSTz88MN16w8//DBHHnkkTz75JG+//TbLli1j2rRpAOTk5HDbbbdRVFTEnDlzuPTSS1v9nEREpOOy/WHwLTMz0wsLC9u6DJFGpcxNobyi/GvtvZN6U/bzsrr173znOxQUFLBhwwYuvfRShg4dSt++fbn44ovr+lRWVtK9e3eOP/74uravvvqKFStiv2VJRETaKzMrcvfMtq6jKZ2a7yIizVlTsWaX2idOnMjChQv517/+xaRJkygv/3po3LFjB4cccgjFxcX7olQRERG9Ck6kJSQnJe9S+6RJk3jooYdYuHAhEydOZPTo0fzlL3+hqqoKgI0bN3LwwQfTp08fHnnkEQDcnWXLlu3bExARkVBRABRpAbOzZtM5ofNObZ0TOjM7a/ZObf3792fTpk307NmTo446irFjxzJ+/HgyMzPJyMhgzpw5AOTn53PXXXeRnp5O//79efLJJxEREWkpugdQpIXkl+STW5DLmoo1JCclMztrNtmR7LYuS0REWtn+cA+gAqCIiIhIC9ofAqCmgEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREJGQUAEVERERCRgFQREREpBFz586lqqqq1Y5nZiPN7MSY9XvM7KyWPo4CoIiIiEgjWjsAAiOBE5vrtLcUAEVERCR0fve735Gamkpqaipz585l8+bNnHbaaaSnp5OamsqCBQuYN28e//znPxk1ahSjRo0C4Pnnn2fYsGEMHDiQiRMnUllZCUBBQQEDBgwgEokApJhZIoCZlZnZLWZWYmZLzezbQfvpZva2mf3NzF40syPNLAW4BPhvMys2sxFBuSeZ2V/N7MOWGg00d2+J/exTmZmZXlhY2NZliIiIyH4ivySf3IJc1lSsITkpmdlZs8mOZANQVFTElClTeOutt3B3TjjhBH784x+zcuVK7rzzTgAqKipISkoiJSWFwsJCjjjiCD777DPOPPNMnn32Wbp06cLNN9/MV199xbRp0zj22GMpKCjguOOOw8w+B2a5+1wzKwPudPfZZvYj4Gx3H2dmhwJfurub2U+A77j7L81sJlDp7nMgOgUMdAEmAX2BRe7+7b29Pp32dgciIiIi7Ul+ST45i3Ooqo5O3ZZXlJOzOAeA7Eg2b7zxBj/84Q/p0qULAGeeeSYJCQm88MILXHXVVYwbN44RI0Z8bb9vvfUWpaWlDB8+HIBt27YxbNgw3nvvPfr06cNxxx1X2/Vz4CRgbrD+YMy/twbLvYAFZnYUcADwUROn9IS77wBKzezI3b4gDdAUsIiIiHQouQW5deGvVlV1FbkFuU3+3rvvvkskEuGaa67h+uuv/9p2d2f06NEUFxdTXFxMaWkpd911166U5A0s3wb8wd0jwFTgwCZ+/6uYZduVAzZHAVBEREQ6lDUVa5psHzFiBE888QRVVVVs3ryZxx9/nEGDBtG5c2fOP/98rrzySt59910AunXrxqZNmwAYOnQoS5YsYfXq1QBs3ryZ999/n+OPP56ysrK6duBw4NWYQ0+K+ffNYDkJWBssT47puwnotqfnvqs0BSwiIiIdSnJSMuUV5Q22AwwcOJApU6YwZMgQAH7yk59QWVnJkCFDiIuLIyEhgTvuuAOAnJwcxo4dyze/+U1efvll7rnnHs4991y++io6KDdr1iyOO+44/vKXvzBx4kRqampqD/fHmEMfambLiY7knRu0zQQeMbMvgJeAPkH7YmChmU0A/qtlrsjX6SEQERER6VDq3wMI0DmhM3mn59U9CLIvmVmRu2cGy2VAprt/ts8PvBs0BSwiIiIdSnYkm7zT8+id1BvD6J3Uu9XC3/5CI4AiIiIiLSh2BLC90gigiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMjsdQA0s6PN7GUzKzWzf5jZFUH7YWb2gpmtCv49NGg3M5tnZqvNbLmZDdzbGkRERERk17XECGAN8Et37wcMBS4zs37AdKDA3Y8FCoJ1gFOBY4OfHOCOFqhBRERERHbRXgdAd1/n7u8Gy5uAFUBPYAJwb9DtXuCMYHkCcJ9HvQUcYmZH7W0dIiIiIrJrWvQeQDNLAQYAbwNHuvu6YNO/gCOD5Z7AxzG/9knQJiIiIiKtoMUCoJl1BR4Ffu7u/47d5u4O+G7uL8fMCs2scMOGDS1VpoiIiEjotUgANLMEouEv390fC5o/rZ3aDf5dH7SvBY6O+fVeQdtO3D3P3TPdPbN79+4tUaaIiIiI0DJPARtwF7DC3X8Xs2kRMDlYngw8GdP+o+Bp4KFARcxUsYiIiIjsY51aYB/DgQuAEjMrDtquBm4CHjazi4By4Oxg2zPAD4DVQBVwYQvUICIiIiK7aK8DoLu/AVgjm7Ma6O/AZXt7XBERERHZM3oTiIiItKni4mKeeeaZuvWZM2cyZ86cNqxIpONTABQRkTZVPwCKyL6nACgiInutrKyMvn37MmXKFI477jiys7N58cUXGT58OMceeyxLly5l6dKlDBs2jAEDBnDiiSfy3nvvsW3bNn7961+zYMECMjIyWLBgAQClpaWMHDmSY445hnnz5rXx2Yl0PAqAIiLSvPx8SEmBuLjov/n5X+uyevVqfvnLX7Jy5UpWrlzJAw88wBtvvMGcOXP4zW9+Q9++fXn99df529/+xvXXX8/VV1/NAQccwPXXX8+kSZMoLi5m0qRJAKxcuZLnnnuOpUuXct1111FdXd265yvSwbXEU8AiItKR5edDTg5UVUXXy8uj6wDZ2XXd+vTpQyQSAaB///5kZWVhZkQiEcrKyqioqGDy5MmsWrUKM2sy1J122mkkJiaSmJhIjx49+PTTT+nVq9c+O0WRsNEIoIiINC039z/hr1ZVVbQ9RmJiYt1yXFxc3XpcXBw1NTX86le/YtSoUfz9739n8eLFbN26tdFDxu4rPj6empqaFjgREamlACgiIk1bs2b32htRUVFBz57RV7/fc889de3dunVj06ZNe1qdiOwBBUAREWlacvLutTdi2rRpzJgxgwEDBuw0ojdq1ChKS0t3eghERPYti34vc/uWmZnphYWFbV2GiEg41b8HEKBzZ8jL2+keQBGJMrMid89s6zqaohFAERFpWnZ2NOz17g1m0X8V/kT2a3oKWEREmpedrcAn0oFoBFBEREQkZBQARUREREJGAXAPTJkyhYULF7b4fhctWsRNN93U6Pbm3pdZWFjIz372sxavS0RERDoW3QPYjowfP57x48c3ur24uJjCwkJ+8IMffG1bTU0NmZmZZGa264eOREREpB3QCOAuuO+++0hLSyM9PZ0LLrgAgNdee40TTzyRY445ZqfRwN/+9rcMHjyYtLQ0rr32WmDXXpIO0S9GvfzyywF45JFHSE1NJT09nZNOOqnBF6bPnDmTCy64gOHDh3PBBRfwyiuvMG7cuFa+OiIiIrK/UQAE8kvySZmbQtx1caTMTSG/5D8vOf/HP/7BrFmzeOmll1i2bBm///3vAVi3bh1vvPEGTz31FNOnTwfg+eefZ9WqVSxdupTi4mKKiop47bXXgOZfkl7f9ddfz3PPPceyZctYtGhRoy9MLy0t5cUXX+TBBx/c15dJREREOojQTwHnl+STsziHquroF5yWV5STszj6kvPsSDYvvfQSEydO5IgjjgDgsMMOA+CMM84gLi6Ofv368emnnwLRAPj8888zYMAAACorK1m1ahXJycnNviS9vuHDhzNlyhTOPvtszjzzzEbrHz9+PAcddFDLXAwREREJhdAHwNyC3LrwV6uquorcglyyI41/51Xsi8pr36bi7syYMYOpU6fu1LesrKzZl6TX98c//pG3336bp59+mkGDBlFUVNRgHV26dGnmDEVERER2Fvop4DUVDb/MvLb9+9//Po888giff/45ABs3bmx0X6eccgp33303lZWVAKxdu5b169fvUV0ffPABJ5xwAtdffz3du3fn448/1gvTRUREpEWEfgQwOSmZ8oryBtshOl2bm5vL9773PeLj4+umdxsyZswYVqxYwbBhwwDo2rUr8+fPJz4+frfruvLKK1m1ahXuTlZWFunp6SQnJ3PTTTeRkZHBjBkzdnufIiIiIgBWO33ZnmVmZnphYeE+2Xf9ewABOid0Ju/0vCangEVEREQaYmZF7t6uv5ct9FPA2ZFs8k7Po3dSbwyjd1JvhT8RERHp0EI/AigiIiLSkjQCKCIiIiLtjgKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMi0WQA0s7Fm9p6ZrTaz6W1Vh4iIiEjYtEkANLN44HbgVKAfcK6Z9WuLWkSkYcXFxTzzzDN16zNnzmTOnDmtdvyysjIeeOCBVjueiEiYtNUI4BBgtbt/6O7bgIeACW1Ui4g0oH4AbG0KgCIi+05bBcCewMcx658EbXXMLMfMCs2scMOGDa1anEhHUVZWRt++fZkyZQrHHXcc2dnZvPjiiwwfPpxjjz2WpUuXsnTpUoYNG8aAAQM48cQTee+999i2bRu//vWvWbBgARkZGSxYsACA0tJSRo4cyTHHHMO8efPqjjN//nyGDBlCRkYGU6dOZfv27QB07dqVK6+8kv79+3PyySezdOnSut9ftGhRXY0jRoxg4MCBDBw4kL/+9a8ATJ8+nddff52MjAxuvfXWVr5yIiIdnLu3+g9wFvDnmPULgD801n/QoEEuIg2bv3y+9761t9tM89639vb5y+fXbfvoo488Pj7ely9f7tu3b/eBAwf6hRde6Dt27PAnnnjCJ0yY4BUVFV5dXe3u7i+88IKfeeaZ7u7+l7/8xS+77LK6fV177bU+bNgw37p1q2/YsMEPO+ww37Ztm5eWlvq4ceN827Zt7u7+05/+1O+99153dwf8mWeecXf3M844w0ePHu3btm3z4uJiT09Pd3f3zZs3+5YtW9zd/f333/fa/72//PLLftppp+3DKycism8Ahd4G+Wp3fjq1Ue5cCxwds94raBOR3ZBfkk/O4hyqqqsAKK8oJ2dxDgDZkWwA+vTpQyQSAaB///5kZWVhZkQiEcrKyqioqGDy5MmsWrUKM6O6urrR45122mkkJiaSmJhIjx49+PTTTykoKKCoqIjBgwcDsGXLFnr06AHAAQccwNixYwGIRCIkJiaSkJBQd2yA6upqLr/8coqLi4mPj+f9999v+QslIiI7aasA+A5wrJn1IRr8zgHOa6NaRPZbuQW5deGvVlV1FbkFuXUBMDExsW5bXFxc3XpcXBw1NTX86le/YtSoUTz++OOUlZUxcuTIRo8Xu6/4+HhqampwdyZPnsyNN974tf4JCQmYWaPHBrj11ls58sgjWbZsGTt27ODAAw/cgyshIiK7o03uAXT3GuBy4DlgBfCwu/+jLWoR2Z+tqVizW+0NqaiooGfP6C2499xzT117t27d2LRpU7O/n5WVxcKFC1m/fj0AGzdupLy8fLeOf9RRRxEXF8f9999fd//grh5fRER2X5t9D6C7P+Pux7n7t9x9dlvVIbI/S05K3q32hkybNo0ZM2YwYMCAulE5gFGjRlFaWrrTQyAN6devH7NmzWLMmDGkpaUxevRo1q1bt8vHv/TSS7n33ntJT09n5cqVdOnSBYC0tDTi4+NJT0/XQyAiIi3Movcqtm+ZmZleWFjY1mWItDv17wEE6JzQmbzT8+qmgEVEpHWZWZG7Z7Z1HU3Rq+BE9mPZkWzyTs+jd1JvDKN3Um+FPxERaZZGAEVERERakEYARURERKTdUQAUERERCRkFQBEREZGQUQAUERERCRkFQBEREZGQUQAUERERCRkFQBEREZGQUQAUERERCRkFQBEREZEOwMz6mtnZu9JXAVBERESkHTCzv+7lLq4DzjCzbzfXUQFQREREpJWYWafGtrn7iXux36OA24HLgG81118BUERERASYP38+Q4YMISMjg6lTp/L222+TlpbG1q1b2bx5M/379+fvf/8727dv53/+539ITU0lLS2N2267DYCUlBQ+++wzAMws08xeCZZnmtn9ZrYEuN/M+pvZUjMrNrPlZnZs0K8y+NfM7Ldm9nczKzGzSUH7SDN7xcwWmtlKM8s3MwvKvxj4X+B14P/FtDeo0RQqIiIi0lHkl+STW5DLmoo1JCclMztrNtmR7LrtK1asYMGCBSxZsoSEhAQuvfRS3nvvPcaPH88111zDli1bOP/880lNTeWOO+6grKyM4uJiOnXqxMaNG3elhH7Ad919i5ndBvze3fPN7AAgvl7fM4EMIB04AnjHzF4Ltg0A+gP/BJYAw4E3gD+4+/UAZnY/MA5Y3FgxCoAiIiLSoeWX5JOzOIeq6ioAyivKyVmcA1AXAgsKCigqKmLw4MEAbNmyhR49evDrX/+awYMHc+CBBzJv3jwAXnzxRS655BI6dYrGqMMOO2xXyljk7luC5TeBXDPrBTzm7qvq9f0u8KC7bwc+NbNXgcHAv4Gl7v4JgJkVAylEA+AoM5sGdAYOA/6BAqCIiIiEVW5Bbl34q1VVXUVuQW5dAHR3Jk+ezI033rhTv3Xr1lFZWUl1dTVbt26lS5cujR6nU6dO7Nixo3b1wHqbN9cuuPsDZvY2cBrwjJlNdfeXdvF0vopZ3g50MrMDgf8DMt39YzOb2cDxd6J7AEVERKRDW1Oxptn2rKwsFi5cyPr16wHYuHEj5eXlTJ06lRtuuIHs7GyuuuoqAEaPHs2f/vQnampq6vpC9B7AoqKi2l3+v8bqMbNjgA/dfR7wJJBWr8vrwCQzizez7sBJwNImTrE27H1mZl2Bs5roC2gEUERERDq45KRkyivKG2yv1a9fP2bNmsWYMWPYsWMHCQkJTJgwgYSEBM477zy2b9/OiSeeyEsvvcRPfvIT3n//fdLS0khISODiiy/m8ssv59prr+Wiiy4C+A7wShMlnQ1cYGbVwL+A39Tb/jgwDFgGODDN3f9lZn0b2pm7f2lmdwJ/D/b3TnPXxNy9uT5tLjMz0wsLC9u6DBEREdkP1b8HEKBzQmfyTs/b6UGQlmJmRe6e2eI7bkGaAhYREZEOLTuSTd7pefRO6o1h9E7qvc/C3/5CI4AiIiIiLUgjgCIiIiLS7igAioiIiISMAqCIiIhIyCgAioiIiISMAqCIiIhIyCgAioiIiISMAqCIiIhIyCgAioiIiISMAqCIiIhIyCgAioiIiISMAqCIiIhIyCgAioiIiISMAqCIiIhIyCgAiohIo8rKykhNTW3rMkSkhe1VADSz35rZSjNbbmaPm9khMdtmmNlqM3vPzE6JaR8btK02s+l7c3wRERER2X17OwL4ApDq7mnA+8AMADPrB5wD9AfGAv9nZvFmFg/cDpwK9APODfqKiEgbyC/JJ2VuCnHXxZEyN4X8kvyv9dm+fTsXX3wx/fv3Z8yYMWzZsoV58+bRr18/0tLSOOeccwCorKzkwgsvJBKJkJaWxqOPPtrapyMiu6jT3vyyuz8fs/oWcFawPAF4yN2/Aj4ys9XAkGDbanf/EMDMHgr6lu5NHSIisvvyS/LJWZxDVXUVAOUV5eQszgEgO5Jd12/VqlU8+OCD3HnnnZx99tk8+uij3HTTTXz00UckJiby5ZdfAnDDDTeQlJRESUkJAF988UXrnpCI7LKWvAfwx8CzwXJP4OOYbZ8EbY21i4hIK8styK0Lf7WqqqvILcjdqa1Pnz5kZGQAMGjQIMrKykhLSyM7O5v58+fTqVN0LOHFF1/ksssuq/u9Qw89dN+egIjssWYDoJm9aGZ/b+BnQkyfXKAG+PrcwR4ysxwzKzSzwg0bNrTUbkVEJLCmYs0utScmJtYtx8fHU1NTw9NPP81ll13Gu+++y+DBg6mpqdmntYpIy2o2ALr7ye6e2sDPkwBmNgUYB2S7uwe/thY4OmY3vYK2xtobOm6eu2e6e2b37t13+8RERKRpyUnJu9Vea8eOHXz88ceMGjWKm2++mYqKCiorKxk9ejS33357XT9NAYu0X3v7FPBYYBow3t1j5xEWAeeYWaKZ9QGOBZYC7wDHmlkfMzuA6IMii/amBhER2TOzs2bTOaHzTm2dEzozO2t2k7+3fft2zj//fCKRCAMGDOBnP/sZhxxyCNdccw1ffPEFqamppKen8/LLL+/L8kVkL9h/Bu324JejD3ckAp8HTW+5+yXBtlyi9wXWAD9392eD9h8Ac4F44G53b/ovDZCZmemFhYV7XKeIiDQsvySf3IJc1lSsITkpmdlZs3d6AEREdp+ZFbl7ZlvX0ZS9CoCtRQFQRERE9hf7QwDUm0BEREREQkYBUERERCRkFABFREREQkYBUERERCRkFABFREREQkYBUERERCRkFABFREREQkYBUERERCRkFABFREREQkYBUERERCRkFABFREREQkYBUERERCRkFABFREREQkYBUERERCRkFABFREREQkYBUERERCRkFAClWV27dm1ye1lZGQ888EArVSMiIiJ7SwFQ9poCoIiIyP5FAVB2mbtz5ZVXkpqaSiQSYcGCBQBMnz6d119/nYyMDG699Va2b9/OlVdeyeDBg0lLS+NPf/pTG1cuIiIisTq1dQHS9vJL8sktyGVNxRqSk5KZnTWb7Ej21/o99thjFBcXs2zZMj777DMGDx7MSSedxE033cScOXN46qmnAMjLyyMpKYl33nmHr776iuHDhzNmzBj69OnT2qcmIiIiDVAADLn8knxyFudQVV0FQHlFOTmLcwC+FgLfeOMNzj33XOLj4znyyCP53ve+xzvvvMPBBx+8U7/nn3+e5cuXs3DhQgAqKipYtWqVAqCIiEg7oQAYcrkFuXXhr1ZVdRW5BbkNjgLuCnfntttu45RTTmmJEkVERKSF6R7AkFtTsWaX20eMGMGCBQvYvn07GzZs4LXXXmPIkCF069aNTZs21fU75ZRTuOOOO6iurgbg/fffZ/PmzfvmBERERGS3aQQw5JKTkimvKG+wvb4f/vCHvPnmm6Snp2Nm3HLLLXzjG9/g8MMPJz4+nvT0dKZMmcIVV1xBWVkZAwcOxN3p3r07TzzxRCucjYiIiOwKc/e2rqFZmZmZXlhY2NZldEj17wEE6JzQmbzT8/Z4ClhERCTMzKzI3TPbuo6maAo45LIj2eSdnkfvpN4YRu+k3gp/IiIiHZxGAEVERERakEYARURERKTdUQAUERERCRkFQBEREZGQUQAUERERCRkFQBEREZGQUQAUERERCRkFQBEREZGQUQAUERERCRkFQBEREZGQUQAUERERCRkFQBEREZGQaZEAaGa/NDM3syOCdTOzeWa22syWm9nAmL6TzWxV8DO5JY4vIiIiIruu097uwMyOBsYAa2KaTwWODX5OAO4ATjCzw4BrgUzAgSIzW+TuX+xtHSIiIiKya1piBPBWYBrRQFdrAnCfR70FHGJmRwGnAC+4+8Yg9L0AjG2BGkRERERkF+1VADSzCcBad19Wb1NP4OOY9U+CtsbaRURERKSVNDsFbGYvAt9oYFMucDXR6d8WZ2Y5QA5AcnLyvjiEiIiISCg1GwDd/eSG2s0sAvQBlpkZQC/gXTMbAqwFjo7p3itoWwuMrNf+SiPHzQPyADIzM72hPiIiIiKy+/Z4CtjdS9y9h7unuHsK0encge7+L2AR8KPgaeChQIW7rwOeA8aY2aFmdijR0cPn9v40RERERGRX7fVTwI14BvgBsBqoAi4EcPeNZnYD8E7Q73p337iPahARERGRBrRYAAxGAWuXHbiskX53A3e31HFFREREZPfoTSAiIiIiIaMAKCIiIhIyCoAiIiIiIaMAKCIiIhIyCoAiIiIiIaMAKCIiIhIyCoAiIiIiIaMAKCIiIhIyCoAiIiIiIaMAKCIiInukrKyM1NRUAAoLC/nZz37WaN9XXnmFcePGtVZp0ox99S5gERERCZHMzEwyMzPbugzZRRoBFBERCaH58+czZMgQMjIymDp1Ktu3b6dr167k5uaSnp7O0KFD+fTTTwH44IMPGDp0KJFIhGuuuYauXbt+bX+xI3yvvvoqGRkZZGRkMGDAADZt2gRAZWUlZ511Fn379iU7Oxt3b70Tlp0oAIqIiHQw+SX5pMxNIe66OFLmppBfkr/T9hUrVrBgwQKWLFlCcXEx8fHx5Ofns3nzZoYOHcqyZcs46aSTuPPOOwG44ooruOKKKygpKaFXr17NHn/OnDncfvvtFBcX8/rrr3PQQQcB8Le//Y25c+dSWlrKhx9+yJIlS1r+5GWXKACKiIh0IPkl+eQszqG8ohzHKa8oJ2dxzk4hsKCggKKiIgYPHkxGRgYFBQV8+OGHHHDAAXWjeIMGDaKsrAyAN998k4kTJwJw3nnnNVvD8OHD+cUvfsG8efP48ssv6dQpesfZkCFD6NWrF3FxcWRkZNTtX1qfAqCIiEgHkluQS1V11U5tVdVV5Bbk1q27O5MnT6a4uJji4mLee+89Zs6cSUJCAmYGQHx8PDU1NXtUw/Tp0/nzn//Mli1bGD58OCtXrgQgMTGxrs/e7F/2ngKgiIhIB7KmYk2z7VlZWSxcuJD169cDsHHjRsrLyxvd59ChQ3n00UcBeOihh5qt4YMPPiASiXDVVVcxePDgugAo7YcCoIiISAeSnJTcbHu/fv2YNWsWY8aMIS0tjdGjR7Nu3bpG9zl37lx+97vfkZaWxurVq0lKSmqyhrlz55KamkpaWhoJCQmceuqpe3Yyss/Y/vAETmZmphcWFrZ1GSIiIu1e7T2AsdPAnRM6k3d6HtmR7D3aZ1VVFQcddBBmxkMPPcSDDz7Ik08+2VIldzhmVuTu7fo7cfQ9gCIiIh1IbcjLLchlTcUakpOSmZ01e4/DH0BRURGXX3457s4hhxzC3Xff3VLlShvRCKCIiIhIC9ofRgB1D6CIdBjt6YlCd2fHjh1tXYaISIMUAEWk3Wjuy2tvuOEGjj/+eL773e9y7rnnMmfOHEaOHMnPf/5zMjMz+f3vf8/ixYs54YQTGDBgACeffHLdmwxmzpzJ5MmTGTFiBL179+axxx5j2rRpRCIRxo4dS3V1NQApKSnMmDGDjIwMMjMzeffddznllFP41re+xR//+Ecg+jaDrKwsBg4cSCQSqbsXqqysjOOPP54f/ehHpKam8vHHH7fi1RMR2XW6B1BE2oX6N67XfnktRO9peuedd3j00UdZtmwZ1dXVDBw4kEGDBgGwbds2am8T+eKLL3jrrbcwM/785z9zyy238L//+79A9KspXn75ZUpLSxk2bBiPPvoot9xyCz/84Q95+umnOeOMMwBITk6muLiY//7v/2bKlCksWbKErVu3kpqayiWXXMKBBx7I448/zsEHH8xnn33G0KFDGT9+PACrVq3i3nvvZejQoa15+UREdosCoIi0C019eW12JJslS5YwYcIEDjzwQA488EBOP/30un6TJk2qW/7kk0+YNGkS69atY9u2bfTp06du26mnnkpCQgKRSITt27czduxYACKRyE5vJKgNc5FIhMrKSrp160a3bt1ITEzkyy+/pEuXLlx99dW89tprxMXFsXbt2rqRxt69eyv8iUi7pylgEWkXduXLaxvTpUuXuuX/+q//4vLLL6ekpIQ//elPbN26tW5b7VsI4uLidnrjQVxc3E73D8b2i31zQW2//Px8NmzYQFFREcXFxRx55JF1x4mtRUSkvVIAFJF2obkvrx0+fDiLFy9m69atVFZW8tRTTzXYv6Kigp49ewJw77337pNaKyoq6NGjBwkJCbz88stNvkFBRKQ9UgAUkXZhdtZsOid03qmtc0JnZmfNBmDw4MGMHz+etLQ0Tj31VCKRSINvI5g5cyYTJ05k0KBBHHHEEfuk1uzsbAoLC4lEItx333307dt3nxxHRGRf0fcAiki7kV+S3+SX11ZWVtK1a1eqqqo46aSTyMvLY+DAgW1YsYjI1+0P3wOoh0BEpN3IjmQ3+baCnJwcSktL2bp1K5MnT1b4ExHZQwqAIrLfeOCBB9q6BBGRDkH3AIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEjAKgiIiISMgoAIqIiIiEzH7xJhAz2wDoZZt75wjgs7YuQvQ5tCP6LNoHfQ7thz6LltPb3bu3dRFN2S8CoOw9Myts76+lCQN9Du2HPov2QZ9D+6HPIlw0BSwiIiISMgqAIiIiIiGjABgeeW1dgAD6HNoTfRbtgz6H9kOfRYjoHkARERGRkNEIoIiIiEjIKAB2UGb2SzNzMzsiWDczm2dmq81suZkNjOk72cxWBT+T267qjsXMfmtmK4Pr/biZHRKzbUbwWbxnZqfEtI8N2lab2fQ2KbyD0zVuXWZ2tJm9bGalZvYPM7siaD/MzF4I/u68YGaHBu2N/q2SvWdm8Wb2NzN7KljvY2ZvB9d7gZkdELQnBuurg+0pbVq4tDgFwA7IzI4GxgBrYppPBY4NfnKAO4K+hwHXAicAQ4Bra/8Qy157AUh19zTgfWAGgJn1A84B+gNjgf8L/ijHA7cT/az6AecGfaWF6Bq3iRrgl+7eDxgKXBZc8+lAgbsfCxQE69DI3yppMVcAK2LWbwZudfdvA18AFwXtFwFfBO23Bv2kA1EA7JhuBaYBsTd4TgDu86i3gEPM7CjgFOAFd9/o7l8QDS1jW73iDsjdn3f3mmD1LaBXsDwBeMjdv3L3j4DVRMP3EGC1u3/o7tuAh4K+0nJ0jVuZu69z93eD5U1Ew0dPotf93qDbvcAZwXJjf6tkL5lZL+A04M/BugHfBxYGXep/DrWfz0IgK+gvHYQCYAdjZhOAte6+rN6mnsDHMeufBG2NtUvL+jHwbLCsz6Lt6Bq3oWAacQDwNnCku68LNv0LODJY1me078wlOjiwI1g/HPgy5v+oxl7rus8h2F4R9JcOolNbFyC7z8xeBL7RwKZc4Gqi07/SCpr6LNz9yaBPLtFpsPzWrE2kPTGzrsCjwM/d/d+xg0nu7mamr6TYh8xsHLDe3YvMbGQblyPtgALgfsjdT26o3cwiQB9gWfDHtRfwrpkNAdYCR8d07xW0rQVG1mt/pcWL7qAa+yxqmdkUYByQ5f/5zqXGPguaaJeW0dS1l33EzBKIhr98d38saP7UzI5y93XBFO/6oF2f0b4xHBhvZj8ADgQOBn5PdIq9UzDKF3utaz+HT8ysE5AEfN76Zcu+oingDsTdS9y9h7unuHsK0eH8ge7+L2AR8KPgCbuhQEUw/fIcMMbMDg0e/hgTtMleMrOxRKdbxrt7VcymRcA5wVN2fYje7L4UeAc4Nngq7wCiD4osau26Ozhd41YW3Dd2F7DC3X8Xs2kRUPutA5OBJ2PaG/pbJXvB3We4e6/gvw3nAC+5ezbwMnBW0K3+51D7+ZwV9NcobQeiEcDweAb4AdEHDqqACwHcfaOZ3UD0P4wA17v7xrYpscP5A5AIvBCMyL7l7pe4+z/M7GGglOjU8GXuvh3AzC4nGsDjgbvd/R9tU3rH5O41usatbjhwAVBiZsVB29XATcDDZnYRUA6cHWxr8G+V7DNXAQ+Z2Szgb0TDOsG/95vZamAj0dAoHYjeBCIiIiISMpoCFhEREQkZBUARERGRkFEAFBEREQkZBUARERGRkFEAFBEREQkZBUARERGRkFEAFBEREQkZBUARERGRkPn/xeAdy1+LXXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_closestwords_tsnescatterplot(my_embedding.wv, \"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0465c77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1047\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1047\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1047\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1047\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1047\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"0a678743-9c6e-4762-982c-19a26f5eb5f6\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  const docs_json = {\"cff52807-5d9f-4d2d-9550-b0646230a95f\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1011\"}],\"center\":[{\"id\":\"1014\"},{\"id\":\"1018\"},{\"id\":\"1045\"}],\"height\":700,\"left\":[{\"id\":\"1015\"}],\"renderers\":[{\"id\":\"1043\"}],\"title\":{\"id\":\"1048\"},\"toolbar\":{\"id\":\"1029\"},\"width\":700,\"x_range\":{\"id\":\"1003\"},\"x_scale\":{\"id\":\"1007\"},\"y_range\":{\"id\":\"1005\"},\"y_scale\":{\"id\":\"1009\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1038\"},\"glyph\":{\"id\":\"1040\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1042\"},\"nonselection_glyph\":{\"id\":\"1041\"},\"view\":{\"id\":\"1044\"}},\"id\":\"1043\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#8724B5\"},\"hatch_alpha\":{\"value\":0.2},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1042\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1052\",\"type\":\"AllLabels\"},{\"attributes\":{\"source\":{\"id\":\"1038\"}},\"id\":\"1044\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1054\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1003\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1055\",\"type\":\"AllLabels\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"source\":{\"id\":\"1038\"},\"text\":{\"field\":\"text_labels\"},\"text_align\":{\"value\":\"center\"},\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":8}},\"id\":\"1045\",\"type\":\"LabelSet\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1027\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"1048\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"overlay\":{\"id\":\"1027\"}},\"id\":\"1026\",\"type\":\"BoxSelectTool\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"ZoomOutTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.6},\"fill_color\":{\"value\":\"#8724B5\"},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1040\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"ZoomInTool\"},{\"attributes\":{},\"id\":\"1056\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis\":{\"id\":\"1011\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1014\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1019\",\"type\":\"HoverTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1028\"}},\"id\":\"1022\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"data\":{\"index\":[\"\\u00e2\",\"work\",\"experi\",\"manag\",\"role\",\"team\",\"servic\",\"skill\",\"provid\",\"develop\",\"busi\",\"opportun\",\"support\",\"requir\",\"commun\",\"applic\",\"posit\",\"includ\",\"appli\",\"custom\",\"abil\",\"client\",\"project\",\"success\",\"peopl\",\"environ\",\"strong\",\"compani\",\"respons\",\"excel\",\"time\",\"new\",\"look\",\"oper\",\"ensur\",\"current\",\"high\",\"need\",\"industri\",\"profession\",\"join\",\"organis\",\"lead\",\"train\",\"offer\",\"candid\",\"year\",\"assist\",\"career\",\"product\",\"base\",\"health\",\"australia\",\"offic\",\"sale\",\"process\",\"report\",\"contact\",\"inform\",\"program\",\"level\",\"knowledg\",\"qualiti\",\"care\",\"market\",\"deliv\",\"plan\",\"build\",\"employ\",\"key\",\"staff\",\"demonstr\",\"experienc\",\"seek\",\"rang\",\"account\",\"day\",\"great\",\"highli\",\"job\",\"maintain\",\"design\",\"commit\",\"use\",\"person\",\"understand\",\"australian\",\"benefit\",\"make\",\"follow\",\"meet\",\"avail\",\"perform\",\"abl\",\"cultur\",\"recruit\",\"practic\",\"close\",\"intern\",\"diver\"],\"text_labels\":[\"\\u00e2\",\"work\",\"experi\",\"manag\",\"role\",\"team\",\"servic\",\"skill\",\"provid\",\"develop\",\"busi\",\"opportun\",\"support\",\"requir\",\"commun\",\"applic\",\"posit\",\"includ\",\"appli\",\"custom\",\"abil\",\"client\",\"project\",\"success\",\"peopl\",\"environ\",\"strong\",\"compani\",\"respons\",\"excel\",\"time\",\"new\",\"look\",\"oper\",\"ensur\",\"current\",\"high\",\"need\",\"industri\",\"profession\",\"join\",\"organis\",\"lead\",\"train\",\"offer\",\"candid\",\"year\",\"assist\",\"career\",\"product\",\"base\",\"health\",\"australia\",\"offic\",\"sale\",\"process\",\"report\",\"contact\",\"inform\",\"program\",\"level\",\"knowledg\",\"qualiti\",\"care\",\"market\",\"deliv\",\"plan\",\"build\",\"employ\",\"key\",\"staff\",\"demonstr\",\"experienc\",\"seek\",\"rang\",\"account\",\"day\",\"great\",\"highli\",\"job\",\"maintain\",\"design\",\"commit\",\"use\",\"person\",\"understand\",\"australian\",\"benefit\",\"make\",\"follow\",\"meet\",\"avail\",\"perform\",\"abl\",\"cultur\",\"recruit\",\"practic\",\"close\",\"intern\",\"diver\"],\"x\":{\"__ndarray__\":\"SlEIQXz9iEEDXrvBAgxxwaKv3kELod9BM/OjQbdbhEJQuBZCFDrNwW/Myj0Mj39CWhA0QQnW5L/HVEBCWvAmQqN2CUKMUby/dM3xQQ5Kf0EhAYTC984hQU7+MMKKhD7B3HVuQrViVEDN2x7C4ay4QZe2KMEizDTC3NB7Qd81PsIWoZ1BVaN6wPpAbcEO3aVAwgXYwR89EsEP1N/B511LQt7ht8IxwANCARRgwT7dy0KyaJVC4rA4Qi55JsLKjwxApFSlQqWnIkFSafjAQeakQvCQ18KuzILCBwM4QCHGfcJOqY1BGQSBwDGnLkIGqw3C6ZN6Qn/T4UKJE2RC/ChuQrLT/MHKsBNCjNbqwSuw8sGrX4dCvwjWwShNF0IRbwHCNyDMQFMVvkGPGPDB9nKOwWuF88ANtSrCXtEJQtCmJkKD9nPC+1Miwq3YjEK8u7VC35tUQiQF4kIlzMjCQ8SpQoxPbcLy48NBp7CywH64ckGn1TxCfn1owtsGSkG2n9RAovGBwg8AnsK4AjrCbw4SQg==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[100]},\"y\":{\"__ndarray__\":\"J/1IwZ43dcAhL6LB4fvZQTmaS8FogKNAxqCIQZwru0GYujJCUfAZQvTu9kHziCzCOEIgQY34rsE1ZNlB310mwp2XksGGpXHAKQlIwhiORULaIwfCmw0eQu2vx0FDKQnCemgMwfy4zcKWCynCASIEQp+QokA/pkjCC86swXRHYUJuApLCC/yZQQpIlcJHmAXCu9BWwjZOjMEisH/ASSf7QKL4YEGKDuRBUlxaQlZJ2MGcqNDBaT4EwktuhMFDQ/lAGK4+wuCB1UHSWEzCxeAkQr6EmMGRCI3CwqFeQit0eUFxDY9ChKPdQrDVfcII2ajCQPmNQsertkGZSqNCO/ouQkRh7ECTd1pCBxrCQT8qPULUjJHCkyODQjyASUE+hffByaZ5wmDXoMKk8KdCG9VnQSbyJEKacnHCnL7MQpUeEcG6kg9CJ6UJQoA0c0ChsR1BGDyrwV0V/EGFp7fBxeWIwVQ7okL0BATCHjOXQiHvM8L0QpBCIOPuwX481cIBir5C6MXMwFSqUUIo2K9AAmnTwg==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[100]}},\"selected\":{\"id\":\"1057\"},\"selection_policy\":{\"id\":\"1056\"}},\"id\":\"1038\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1057\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#8724B5\"},\"hatch_alpha\":{\"value\":0.1},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1041\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"RedoTool\"},{\"attributes\":{},\"id\":\"1051\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1015\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1018\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"UndoTool\"},{\"attributes\":{},\"id\":\"1016\",\"type\":\"BasicTicker\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1051\"},\"group\":null,\"major_label_policy\":{\"id\":\"1052\"},\"ticker\":{\"id\":\"1016\"}},\"id\":\"1015\",\"type\":\"LinearAxis\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1028\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"tools\":[{\"id\":\"1019\"},{\"id\":\"1020\"},{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"}]},\"id\":\"1029\",\"type\":\"Toolbar\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1054\"},\"group\":null,\"major_label_policy\":{\"id\":\"1055\"},\"ticker\":{\"id\":\"1012\"}},\"id\":\"1011\",\"type\":\"LinearAxis\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.2\"}};\n",
       "  const render_items = [{\"docid\":\"cff52807-5d9f-4d2d-9550-b0646230a95f\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"0a678743-9c6e-4762-982c-19a26f5eb5f6\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_wv(my_embedding, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "031d5d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1165\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1165\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1165\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1165\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1165\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"da63df96-8cf2-46e7-81e4-c39e820773e4\" data-root-id=\"1120\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  const docs_json = {\"90eac291-23b1-40ea-9bed-f4eed5e94f08\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1129\"}],\"center\":[{\"id\":\"1132\"},{\"id\":\"1136\"},{\"id\":\"1163\"}],\"height\":700,\"left\":[{\"id\":\"1133\"}],\"renderers\":[{\"id\":\"1161\"}],\"title\":{\"id\":\"1178\"},\"toolbar\":{\"id\":\"1147\"},\"width\":700,\"x_range\":{\"id\":\"1121\"},\"x_scale\":{\"id\":\"1125\"},\"y_range\":{\"id\":\"1123\"},\"y_scale\":{\"id\":\"1127\"}},\"id\":\"1120\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1185\",\"type\":\"AllLabels\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#8724B5\"},\"hatch_alpha\":{\"value\":0.1},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1159\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.6},\"fill_color\":{\"value\":\"#8724B5\"},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1158\",\"type\":\"Scatter\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1184\"},\"group\":null,\"major_label_policy\":{\"id\":\"1185\"},\"ticker\":{\"id\":\"1130\"}},\"id\":\"1129\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1123\",\"type\":\"DataRange1d\"},{\"attributes\":{\"tools\":[{\"id\":\"1137\"},{\"id\":\"1138\"},{\"id\":\"1139\"},{\"id\":\"1140\"},{\"id\":\"1141\"},{\"id\":\"1142\"},{\"id\":\"1143\"},{\"id\":\"1144\"}]},\"id\":\"1147\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1125\",\"type\":\"LinearScale\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"1178\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1186\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1146\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1145\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1187\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1142\",\"type\":\"RedoTool\"},{\"attributes\":{},\"id\":\"1143\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1121\",\"type\":\"DataRange1d\"},{\"attributes\":{\"overlay\":{\"id\":\"1146\"}},\"id\":\"1140\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1139\",\"type\":\"ZoomOutTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1137\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1138\",\"type\":\"ZoomInTool\"},{\"attributes\":{\"source\":{\"id\":\"1156\"}},\"id\":\"1162\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1141\",\"type\":\"UndoTool\"},{\"attributes\":{},\"id\":\"1134\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1133\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1136\",\"type\":\"Grid\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1156\"},\"glyph\":{\"id\":\"1158\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1160\"},\"nonselection_glyph\":{\"id\":\"1159\"},\"view\":{\"id\":\"1162\"}},\"id\":\"1161\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"1129\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1132\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1130\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1181\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"source\":{\"id\":\"1156\"},\"text\":{\"field\":\"text_labels\"},\"text_align\":{\"value\":\"center\"},\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":8}},\"id\":\"1163\",\"type\":\"LabelSet\"},{\"attributes\":{\"data\":{\"index\":[\"\\u00e2\",\"work\",\"experi\",\"manag\",\"role\",\"team\",\"servic\",\"skill\",\"provid\",\"develop\",\"busi\",\"opportun\",\"support\",\"requir\",\"commun\",\"applic\",\"posit\",\"includ\",\"appli\",\"custom\",\"abil\",\"client\",\"project\",\"success\",\"peopl\",\"environ\",\"strong\",\"compani\",\"respons\",\"excel\",\"time\",\"new\",\"look\",\"oper\",\"ensur\",\"current\",\"high\",\"need\",\"industri\",\"profession\",\"join\",\"organis\",\"lead\",\"train\",\"offer\",\"candid\",\"year\",\"assist\",\"career\",\"product\",\"base\",\"health\",\"australia\",\"offic\",\"sale\",\"process\",\"report\",\"contact\",\"inform\",\"program\",\"level\",\"knowledg\",\"qualiti\",\"care\",\"market\",\"deliv\",\"plan\",\"build\",\"employ\",\"key\",\"staff\",\"demonstr\",\"experienc\",\"seek\",\"rang\",\"account\",\"day\",\"great\",\"highli\",\"job\",\"maintain\",\"design\",\"commit\",\"use\",\"person\",\"understand\",\"australian\",\"benefit\",\"make\",\"follow\",\"meet\",\"avail\",\"perform\",\"abl\",\"cultur\",\"recruit\",\"practic\",\"close\",\"intern\",\"diver\",\"gener\",\"activ\",\"learn\",\"relationship\",\"valu\",\"solut\",\"data\",\"passion\",\"effect\",\"locat\",\"qualif\",\"administr\",\"essenti\",\"grow\",\"group\",\"flexibl\",\"salari\",\"improv\",\"stakehold\",\"click\",\"area\",\"deliveri\",\"hour\",\"good\",\"resum\",\"employe\",\"right\",\"achiev\",\"system\",\"financi\",\"relat\",\"implement\",\"educ\",\"engin\",\"duti\",\"technic\",\"standard\",\"relev\",\"help\",\"drive\",\"continu\",\"best\",\"safeti\",\"amp\",\"prepar\",\"complet\",\"technolog\",\"like\",\"contract\",\"growth\",\"site\",\"leader\",\"coordin\",\"excit\",\"child\",\"senior\",\"commerci\",\"check\",\"engag\",\"nation\",\"construct\",\"consult\",\"email\",\"innov\",\"member\",\"previou\",\"packag\",\"individu\",\"written\",\"desir\",\"proven\",\"integr\",\"ongo\",\"chang\",\"creat\",\"govern\",\"document\",\"consid\",\"cover\",\"sydney\",\"mainten\",\"ideal\",\"focu\",\"encourag\",\"secur\",\"initi\",\"motiv\",\"centr\",\"brand\",\"start\",\"review\",\"want\",\"\\u00e2\\u00e2\",\"perman\",\"school\",\"licenc\",\"collabor\",\"submit\",\"driver\",\"famili\",\"ass\",\"background\",\"strategi\",\"establish\",\"prefer\",\"leadership\",\"except\",\"student\",\"contribut\",\"retail\",\"global\",\"depart\",\"complianc\",\"progress\",\"reward\",\"sound\",\"week\",\"attent\",\"polici\",\"month\",\"approach\",\"network\",\"present\",\"minimum\",\"identifi\",\"criterion\",\"record\",\"challeng\",\"local\",\"task\",\"certif\",\"larg\",\"focus\",\"confidenti\",\"medic\",\"regard\",\"target\",\"trade\",\"equip\",\"order\",\"transport\",\"onlin\",\"letter\",\"direct\",\"attitud\",\"live\",\"discus\",\"issu\",\"analysi\",\"dynam\",\"promot\",\"access\",\"region\",\"number\",\"extern\",\"interest\",\"resourc\",\"verbal\",\"melbourn\",\"differ\",\"execut\",\"set\",\"procedur\",\"clinic\",\"function\",\"travel\",\"enjoy\",\"nsw\",\"sector\",\"test\",\"research\",\"refer\",\"agenc\",\"outcom\",\"safe\",\"risk\",\"note\",\"partner\",\"control\",\"friendli\",\"button\",\"problem\",\"competit\",\"social\",\"exist\",\"effici\",\"tool\",\"similar\",\"appropri\",\"detail\",\"complex\",\"undertak\",\"corpor\",\"youll\",\"specialist\",\"age\",\"store\",\"conduct\",\"term\",\"descript\",\"select\",\"softwar\",\"immedi\",\"nurs\",\"qualifi\",\"extens\",\"reliabl\",\"posse\",\"public\",\"strateg\",\"pm\",\"cv\",\"involv\",\"result\",\"andor\",\"shift\",\"vehicl\",\"facil\",\"life\",\"home\",\"end\",\"advic\",\"april\",\"forward\",\"return\",\"addit\",\"liais\",\"advanc\",\"rate\",\"hospit\",\"talent\",\"audit\",\"world\",\"comput\",\"expect\",\"analyt\",\"receiv\",\"workplac\",\"disabl\",\"multipl\",\"capabl\",\"fit\",\"confid\",\"visit\",\"properti\",\"fast\",\"interperson\",\"firm\",\"limit\",\"phone\",\"specif\",\"hold\",\"driven\",\"insur\",\"hr\",\"open\",\"negoti\",\"field\",\"event\",\"financ\",\"monitor\",\"futur\",\"degre\",\"send\",\"medium\",\"manufactur\",\"inclus\",\"suit\",\"advantag\",\"potenti\",\"manner\",\"dedic\",\"track\",\"digit\",\"largest\",\"love\",\"teach\",\"small\",\"food\",\"proactiv\",\"patient\",\"varieti\",\"long\",\"variou\",\"respect\",\"independ\",\"structur\",\"websit\",\"recognis\",\"leav\",\"equal\",\"portfolio\",\"particip\",\"outstand\",\"place\",\"infrastructur\",\"monday\",\"budget\",\"roster\",\"microsoft\",\"remuner\",\"friday\",\"link\",\"plu\",\"mine\",\"solv\",\"enquiri\",\"wide\",\"major\",\"south\",\"licens\",\"schedul\",\"date\",\"electr\",\"aborigin\",\"address\",\"suppli\",\"resid\",\"accur\",\"polic\",\"run\",\"daili\",\"state\",\"legal\",\"list\",\"enthusiast\",\"consist\",\"basi\",\"casual\",\"suitabl\",\"supervis\",\"fantast\",\"import\",\"regist\",\"line\",\"cost\",\"balanc\",\"attract\",\"claim\",\"tertiari\",\"reput\",\"way\",\"act\",\"investig\",\"goal\",\"word\",\"award\",\"think\",\"mechan\",\"today\",\"whilst\",\"condit\",\"come\",\"know\",\"privat\",\"associ\",\"succeed\",\"share\",\"pace\",\"face\",\"unit\",\"possibl\",\"bank\",\"compet\",\"workforc\",\"teacher\",\"earli\",\"director\",\"pride\",\"increas\",\"supplier\",\"creativ\",\"object\",\"expertis\",\"bring\",\"allow\",\"univers\",\"hand\",\"handl\",\"cbd\",\"asset\",\"brisban\",\"model\",\"mentor\",\"australia\\u00e2\",\"ethic\",\"will\",\"superannu\",\"decis\",\"view\",\"annual\",\"own\",\"hear\",\"discount\",\"m\",\"island\",\"interview\",\"legisl\",\"real\",\"take\",\"free\",\"materi\",\"believ\",\"clearanc\",\"residenti\",\"exposur\",\"campaign\",\"civil\",\"class\",\"uniqu\",\"pay\",\"citi\",\"expand\",\"arrang\",\"regular\",\"autonom\",\"and\\u00e2\",\"energi\",\"prior\",\"instal\",\"park\",\"stock\",\"directli\",\"fulltim\",\"divis\",\"repair\",\"deadlin\",\"specialis\",\"accord\",\"facilit\",\"player\",\"weekend\",\"fun\",\"framework\",\"repres\",\"card\",\"platform\",\"forklift\",\"invest\",\"deal\",\"copi\",\"quot\",\"produc\",\"torr\",\"feel\",\"aspect\",\"capac\",\"contractor\",\"valid\",\"comprehens\",\"strait\",\"updat\",\"appoint\",\"head\",\"fund\",\"you\\u00e2ll\",\"queensland\",\"worker\",\"commenc\",\"primari\",\"car\",\"option\",\"countri\",\"monthli\",\"step\",\"paid\",\"super\",\"enabl\",\"gain\",\"influenc\",\"call\",\"matter\",\"welcom\",\"sustain\",\"payrol\",\"purpos\",\"case\",\"clean\",\"critic\",\"attend\",\"coach\",\"natur\",\"prioriti\",\"just\",\"signific\",\"plant\",\"genuin\",\"enhanc\",\"a\\u00e2\",\"registr\",\"collect\",\"impact\",\"solid\",\"healthcar\",\"truck\",\"obtain\",\"histori\",\"equival\",\"willing\",\"road\",\"point\",\"energet\",\"content\",\"tax\",\"load\",\"readi\",\"core\",\"behaviour\",\"connect\",\"recent\",\"wellb\",\"disciplin\",\"council\",\"mobil\",\"request\",\"form\",\"altern\",\"years\\u00e2\",\"shortlist\",\"question\",\"expert\",\"hard\",\"your\",\"perth\",\"commiss\",\"provis\",\"north\",\"zealand\",\"play\",\"workshop\",\"ap\",\"distribut\",\"law\",\"trust\",\"entri\",\"human\",\"necessari\",\"subject\",\"vari\",\"profici\",\"period\",\"young\",\"prioritis\",\"write\",\"databas\",\"analys\",\"warehous\",\"orient\",\"elig\",\"screen\",\"profit\",\"depend\",\"onsit\",\"sourc\",\"th\",\"space\",\"vision\",\"agil\",\"thrive\",\"enterpris\",\"labour\",\"to\\u00e2\",\"pressur\",\"mental\",\"power\",\"the\\u00e2\",\"sell\",\"western\",\"broad\",\"analyst\",\"victoria\",\"action\",\"volum\",\"overse\",\"respond\",\"protect\",\"manual\",\"partnership\",\"physic\",\"inspir\",\"scienc\",\"adher\",\"better\",\"logist\",\"queri\",\"profil\",\"attribut\",\"interact\",\"insight\",\"architectur\",\"demand\",\"web\",\"fix\",\"clear\",\"file\",\"branch\",\"weekli\",\"short\",\"accept\",\"read\",\"format\",\"transform\",\"thing\",\"graduat\",\"woman\",\"citizen\",\"regul\",\"adapt\",\"supervisor\",\"section\",\"advertis\",\"room\",\"basic\",\"principl\",\"serv\",\"water\",\"ad\",\"accommod\",\"proud\",\"selfmotiv\",\"have\",\"post\",\"code\",\"suburb\",\"idea\",\"attach\",\"modern\",\"assign\",\"we\\u00e2r\",\"heavi\",\"team\\u00e2\",\"ticket\",\"environment\",\"drug\",\"advis\",\"type\",\"payment\",\"studi\",\"reach\",\"purchas\",\"evalu\",\"procur\",\"book\",\"invoic\",\"practition\",\"temporari\",\"cours\",\"utilis\",\"aid\",\"combin\",\"align\",\"hire\",\"machin\",\"coast\",\"recommend\",\"style\",\"scope\",\"highest\",\"fulli\",\"win\",\"alcohol\",\"k\",\"page\",\"vacanc\",\"classroom\",\"keen\",\"incent\",\"hous\",\"carri\",\"central\",\"guidanc\",\"victorian\",\"consum\",\"earn\",\"bonu\",\"automot\",\"adelaid\",\"aim\",\"junior\",\"lifestyl\",\"choic\",\"sap\",\"board\",\"west\",\"determin\",\"night\",\"accredit\",\"pas\",\"main\",\"outlin\",\"skills\\u00e2\",\"hotel\",\"estat\",\"restaur\",\"econom\",\"crimin\",\"known\",\"rail\",\"preemploy\",\"parent\",\"correct\",\"resolv\",\"approv\",\"search\",\"exceed\",\"treat\",\"strive\",\"amaz\",\"sunday\",\"experience\\u00e2\",\"kpi\",\"white\",\"awar\",\"brief\",\"role\\u00e2\",\"shop\",\"kitchen\",\"emerg\",\"comfort\",\"interpret\",\"you\\u00e2\",\"chanc\",\"oral\",\"referr\",\"statement\",\"autom\",\"incom\",\"mean\",\"sport\",\"agre\",\"channel\",\"quickli\",\"institut\",\"defin\",\"forecast\",\"answer\",\"evid\",\"incorrect\",\"childhood\",\"parti\",\"technician\",\"curriculum\",\"reconcili\",\"resolut\",\"territori\",\"canberra\",\"multidisciplinari\",\"induct\",\"overal\",\"beauti\",\"vibrant\",\"estim\",\"worklif\",\"in\\u00e2\",\"accuraci\",\"revenu\",\"special\",\"motor\",\"colleg\",\"compon\",\"big\",\"express\",\"st\",\"art\",\"foster\",\"satisfact\",\"fraud\",\"mind\",\"alongsid\",\"part\",\"mission\",\"given\",\"methodolog\",\"regulatori\",\"embrac\",\"sure\",\"instruct\",\"uptod\",\"consider\",\"occup\",\"price\",\"draw\",\"cloud\",\"intermedi\",\"do\",\"fastpac\",\"hit\",\"prospect\",\"alloc\",\"guid\",\"multitask\",\"trend\",\"guidelin\",\"assur\",\"prevent\",\"alli\",\"dont\",\"built\",\"bill\",\"east\",\"measur\",\"inspect\",\"perk\",\"personnel\",\"ga\",\"stage\",\"situat\",\"heart\",\"reflect\",\"diploma\",\"indigen\",\"maximis\",\"capit\",\"telephon\",\"colleagu\",\"pick\",\"vendor\",\"self\",\"met\",\"hourli\",\"statu\",\"wa\",\"parttim\",\"treatment\",\"eye\",\"guest\",\"million\",\"english\",\"membership\",\"remot\",\"scheme\",\"you\\u00e2r\",\"of\\u00e2\",\"oh\",\"doe\",\"credit\",\"ownership\",\"domest\",\"pa\",\"techniqu\",\"ahpra\",\"academ\",\"overtim\",\"concept\",\"literaci\",\"qld\",\"recept\",\"healthi\",\"rehabilit\",\"propos\",\"owner\",\"iii\",\"correspond\",\"rotat\",\"chef\",\"organ\",\"rapidli\",\"happi\",\"builder\",\"display\",\"northern\",\"eastern\",\"pipelin\",\"gold\",\"c\",\"shape\",\"journey\",\"chain\",\"ground\",\"club\",\"sen\",\"superior\",\"for\\u00e2\",\"tender\",\"visa\",\"pack\",\"acquisit\",\"method\",\"transact\",\"now\\u00e2\",\"mandatori\",\"lift\",\"intervent\",\"dental\",\"advisor\",\"optimis\",\"box\",\"inventori\",\"categori\",\"steel\",\"server\",\"merchandis\",\"feedback\",\"holiday\",\"iv\",\"agreement\",\"deploy\",\"scale\",\"wage\",\"what\"],\"text_labels\":[\"\\u00e2\",\"work\",\"experi\",\"manag\",\"role\",\"team\",\"servic\",\"skill\",\"provid\",\"develop\",\"busi\",\"opportun\",\"support\",\"requir\",\"commun\",\"applic\",\"posit\",\"includ\",\"appli\",\"custom\",\"abil\",\"client\",\"project\",\"success\",\"peopl\",\"environ\",\"strong\",\"compani\",\"respons\",\"excel\",\"time\",\"new\",\"look\",\"oper\",\"ensur\",\"current\",\"high\",\"need\",\"industri\",\"profession\",\"join\",\"organis\",\"lead\",\"train\",\"offer\",\"candid\",\"year\",\"assist\",\"career\",\"product\",\"base\",\"health\",\"australia\",\"offic\",\"sale\",\"process\",\"report\",\"contact\",\"inform\",\"program\",\"level\",\"knowledg\",\"qualiti\",\"care\",\"market\",\"deliv\",\"plan\",\"build\",\"employ\",\"key\",\"staff\",\"demonstr\",\"experienc\",\"seek\",\"rang\",\"account\",\"day\",\"great\",\"highli\",\"job\",\"maintain\",\"design\",\"commit\",\"use\",\"person\",\"understand\",\"australian\",\"benefit\",\"make\",\"follow\",\"meet\",\"avail\",\"perform\",\"abl\",\"cultur\",\"recruit\",\"practic\",\"close\",\"intern\",\"diver\",\"gener\",\"activ\",\"learn\",\"relationship\",\"valu\",\"solut\",\"data\",\"passion\",\"effect\",\"locat\",\"qualif\",\"administr\",\"essenti\",\"grow\",\"group\",\"flexibl\",\"salari\",\"improv\",\"stakehold\",\"click\",\"area\",\"deliveri\",\"hour\",\"good\",\"resum\",\"employe\",\"right\",\"achiev\",\"system\",\"financi\",\"relat\",\"implement\",\"educ\",\"engin\",\"duti\",\"technic\",\"standard\",\"relev\",\"help\",\"drive\",\"continu\",\"best\",\"safeti\",\"amp\",\"prepar\",\"complet\",\"technolog\",\"like\",\"contract\",\"growth\",\"site\",\"leader\",\"coordin\",\"excit\",\"child\",\"senior\",\"commerci\",\"check\",\"engag\",\"nation\",\"construct\",\"consult\",\"email\",\"innov\",\"member\",\"previou\",\"packag\",\"individu\",\"written\",\"desir\",\"proven\",\"integr\",\"ongo\",\"chang\",\"creat\",\"govern\",\"document\",\"consid\",\"cover\",\"sydney\",\"mainten\",\"ideal\",\"focu\",\"encourag\",\"secur\",\"initi\",\"motiv\",\"centr\",\"brand\",\"start\",\"review\",\"want\",\"\\u00e2\\u00e2\",\"perman\",\"school\",\"licenc\",\"collabor\",\"submit\",\"driver\",\"famili\",\"ass\",\"background\",\"strategi\",\"establish\",\"prefer\",\"leadership\",\"except\",\"student\",\"contribut\",\"retail\",\"global\",\"depart\",\"complianc\",\"progress\",\"reward\",\"sound\",\"week\",\"attent\",\"polici\",\"month\",\"approach\",\"network\",\"present\",\"minimum\",\"identifi\",\"criterion\",\"record\",\"challeng\",\"local\",\"task\",\"certif\",\"larg\",\"focus\",\"confidenti\",\"medic\",\"regard\",\"target\",\"trade\",\"equip\",\"order\",\"transport\",\"onlin\",\"letter\",\"direct\",\"attitud\",\"live\",\"discus\",\"issu\",\"analysi\",\"dynam\",\"promot\",\"access\",\"region\",\"number\",\"extern\",\"interest\",\"resourc\",\"verbal\",\"melbourn\",\"differ\",\"execut\",\"set\",\"procedur\",\"clinic\",\"function\",\"travel\",\"enjoy\",\"nsw\",\"sector\",\"test\",\"research\",\"refer\",\"agenc\",\"outcom\",\"safe\",\"risk\",\"note\",\"partner\",\"control\",\"friendli\",\"button\",\"problem\",\"competit\",\"social\",\"exist\",\"effici\",\"tool\",\"similar\",\"appropri\",\"detail\",\"complex\",\"undertak\",\"corpor\",\"youll\",\"specialist\",\"age\",\"store\",\"conduct\",\"term\",\"descript\",\"select\",\"softwar\",\"immedi\",\"nurs\",\"qualifi\",\"extens\",\"reliabl\",\"posse\",\"public\",\"strateg\",\"pm\",\"cv\",\"involv\",\"result\",\"andor\",\"shift\",\"vehicl\",\"facil\",\"life\",\"home\",\"end\",\"advic\",\"april\",\"forward\",\"return\",\"addit\",\"liais\",\"advanc\",\"rate\",\"hospit\",\"talent\",\"audit\",\"world\",\"comput\",\"expect\",\"analyt\",\"receiv\",\"workplac\",\"disabl\",\"multipl\",\"capabl\",\"fit\",\"confid\",\"visit\",\"properti\",\"fast\",\"interperson\",\"firm\",\"limit\",\"phone\",\"specif\",\"hold\",\"driven\",\"insur\",\"hr\",\"open\",\"negoti\",\"field\",\"event\",\"financ\",\"monitor\",\"futur\",\"degre\",\"send\",\"medium\",\"manufactur\",\"inclus\",\"suit\",\"advantag\",\"potenti\",\"manner\",\"dedic\",\"track\",\"digit\",\"largest\",\"love\",\"teach\",\"small\",\"food\",\"proactiv\",\"patient\",\"varieti\",\"long\",\"variou\",\"respect\",\"independ\",\"structur\",\"websit\",\"recognis\",\"leav\",\"equal\",\"portfolio\",\"particip\",\"outstand\",\"place\",\"infrastructur\",\"monday\",\"budget\",\"roster\",\"microsoft\",\"remuner\",\"friday\",\"link\",\"plu\",\"mine\",\"solv\",\"enquiri\",\"wide\",\"major\",\"south\",\"licens\",\"schedul\",\"date\",\"electr\",\"aborigin\",\"address\",\"suppli\",\"resid\",\"accur\",\"polic\",\"run\",\"daili\",\"state\",\"legal\",\"list\",\"enthusiast\",\"consist\",\"basi\",\"casual\",\"suitabl\",\"supervis\",\"fantast\",\"import\",\"regist\",\"line\",\"cost\",\"balanc\",\"attract\",\"claim\",\"tertiari\",\"reput\",\"way\",\"act\",\"investig\",\"goal\",\"word\",\"award\",\"think\",\"mechan\",\"today\",\"whilst\",\"condit\",\"come\",\"know\",\"privat\",\"associ\",\"succeed\",\"share\",\"pace\",\"face\",\"unit\",\"possibl\",\"bank\",\"compet\",\"workforc\",\"teacher\",\"earli\",\"director\",\"pride\",\"increas\",\"supplier\",\"creativ\",\"object\",\"expertis\",\"bring\",\"allow\",\"univers\",\"hand\",\"handl\",\"cbd\",\"asset\",\"brisban\",\"model\",\"mentor\",\"australia\\u00e2\",\"ethic\",\"will\",\"superannu\",\"decis\",\"view\",\"annual\",\"own\",\"hear\",\"discount\",\"m\",\"island\",\"interview\",\"legisl\",\"real\",\"take\",\"free\",\"materi\",\"believ\",\"clearanc\",\"residenti\",\"exposur\",\"campaign\",\"civil\",\"class\",\"uniqu\",\"pay\",\"citi\",\"expand\",\"arrang\",\"regular\",\"autonom\",\"and\\u00e2\",\"energi\",\"prior\",\"instal\",\"park\",\"stock\",\"directli\",\"fulltim\",\"divis\",\"repair\",\"deadlin\",\"specialis\",\"accord\",\"facilit\",\"player\",\"weekend\",\"fun\",\"framework\",\"repres\",\"card\",\"platform\",\"forklift\",\"invest\",\"deal\",\"copi\",\"quot\",\"produc\",\"torr\",\"feel\",\"aspect\",\"capac\",\"contractor\",\"valid\",\"comprehens\",\"strait\",\"updat\",\"appoint\",\"head\",\"fund\",\"you\\u00e2ll\",\"queensland\",\"worker\",\"commenc\",\"primari\",\"car\",\"option\",\"countri\",\"monthli\",\"step\",\"paid\",\"super\",\"enabl\",\"gain\",\"influenc\",\"call\",\"matter\",\"welcom\",\"sustain\",\"payrol\",\"purpos\",\"case\",\"clean\",\"critic\",\"attend\",\"coach\",\"natur\",\"prioriti\",\"just\",\"signific\",\"plant\",\"genuin\",\"enhanc\",\"a\\u00e2\",\"registr\",\"collect\",\"impact\",\"solid\",\"healthcar\",\"truck\",\"obtain\",\"histori\",\"equival\",\"willing\",\"road\",\"point\",\"energet\",\"content\",\"tax\",\"load\",\"readi\",\"core\",\"behaviour\",\"connect\",\"recent\",\"wellb\",\"disciplin\",\"council\",\"mobil\",\"request\",\"form\",\"altern\",\"years\\u00e2\",\"shortlist\",\"question\",\"expert\",\"hard\",\"your\",\"perth\",\"commiss\",\"provis\",\"north\",\"zealand\",\"play\",\"workshop\",\"ap\",\"distribut\",\"law\",\"trust\",\"entri\",\"human\",\"necessari\",\"subject\",\"vari\",\"profici\",\"period\",\"young\",\"prioritis\",\"write\",\"databas\",\"analys\",\"warehous\",\"orient\",\"elig\",\"screen\",\"profit\",\"depend\",\"onsit\",\"sourc\",\"th\",\"space\",\"vision\",\"agil\",\"thrive\",\"enterpris\",\"labour\",\"to\\u00e2\",\"pressur\",\"mental\",\"power\",\"the\\u00e2\",\"sell\",\"western\",\"broad\",\"analyst\",\"victoria\",\"action\",\"volum\",\"overse\",\"respond\",\"protect\",\"manual\",\"partnership\",\"physic\",\"inspir\",\"scienc\",\"adher\",\"better\",\"logist\",\"queri\",\"profil\",\"attribut\",\"interact\",\"insight\",\"architectur\",\"demand\",\"web\",\"fix\",\"clear\",\"file\",\"branch\",\"weekli\",\"short\",\"accept\",\"read\",\"format\",\"transform\",\"thing\",\"graduat\",\"woman\",\"citizen\",\"regul\",\"adapt\",\"supervisor\",\"section\",\"advertis\",\"room\",\"basic\",\"principl\",\"serv\",\"water\",\"ad\",\"accommod\",\"proud\",\"selfmotiv\",\"have\",\"post\",\"code\",\"suburb\",\"idea\",\"attach\",\"modern\",\"assign\",\"we\\u00e2r\",\"heavi\",\"team\\u00e2\",\"ticket\",\"environment\",\"drug\",\"advis\",\"type\",\"payment\",\"studi\",\"reach\",\"purchas\",\"evalu\",\"procur\",\"book\",\"invoic\",\"practition\",\"temporari\",\"cours\",\"utilis\",\"aid\",\"combin\",\"align\",\"hire\",\"machin\",\"coast\",\"recommend\",\"style\",\"scope\",\"highest\",\"fulli\",\"win\",\"alcohol\",\"k\",\"page\",\"vacanc\",\"classroom\",\"keen\",\"incent\",\"hous\",\"carri\",\"central\",\"guidanc\",\"victorian\",\"consum\",\"earn\",\"bonu\",\"automot\",\"adelaid\",\"aim\",\"junior\",\"lifestyl\",\"choic\",\"sap\",\"board\",\"west\",\"determin\",\"night\",\"accredit\",\"pas\",\"main\",\"outlin\",\"skills\\u00e2\",\"hotel\",\"estat\",\"restaur\",\"econom\",\"crimin\",\"known\",\"rail\",\"preemploy\",\"parent\",\"correct\",\"resolv\",\"approv\",\"search\",\"exceed\",\"treat\",\"strive\",\"amaz\",\"sunday\",\"experience\\u00e2\",\"kpi\",\"white\",\"awar\",\"brief\",\"role\\u00e2\",\"shop\",\"kitchen\",\"emerg\",\"comfort\",\"interpret\",\"you\\u00e2\",\"chanc\",\"oral\",\"referr\",\"statement\",\"autom\",\"incom\",\"mean\",\"sport\",\"agre\",\"channel\",\"quickli\",\"institut\",\"defin\",\"forecast\",\"answer\",\"evid\",\"incorrect\",\"childhood\",\"parti\",\"technician\",\"curriculum\",\"reconcili\",\"resolut\",\"territori\",\"canberra\",\"multidisciplinari\",\"induct\",\"overal\",\"beauti\",\"vibrant\",\"estim\",\"worklif\",\"in\\u00e2\",\"accuraci\",\"revenu\",\"special\",\"motor\",\"colleg\",\"compon\",\"big\",\"express\",\"st\",\"art\",\"foster\",\"satisfact\",\"fraud\",\"mind\",\"alongsid\",\"part\",\"mission\",\"given\",\"methodolog\",\"regulatori\",\"embrac\",\"sure\",\"instruct\",\"uptod\",\"consider\",\"occup\",\"price\",\"draw\",\"cloud\",\"intermedi\",\"do\",\"fastpac\",\"hit\",\"prospect\",\"alloc\",\"guid\",\"multitask\",\"trend\",\"guidelin\",\"assur\",\"prevent\",\"alli\",\"dont\",\"built\",\"bill\",\"east\",\"measur\",\"inspect\",\"perk\",\"personnel\",\"ga\",\"stage\",\"situat\",\"heart\",\"reflect\",\"diploma\",\"indigen\",\"maximis\",\"capit\",\"telephon\",\"colleagu\",\"pick\",\"vendor\",\"self\",\"met\",\"hourli\",\"statu\",\"wa\",\"parttim\",\"treatment\",\"eye\",\"guest\",\"million\",\"english\",\"membership\",\"remot\",\"scheme\",\"you\\u00e2r\",\"of\\u00e2\",\"oh\",\"doe\",\"credit\",\"ownership\",\"domest\",\"pa\",\"techniqu\",\"ahpra\",\"academ\",\"overtim\",\"concept\",\"literaci\",\"qld\",\"recept\",\"healthi\",\"rehabilit\",\"propos\",\"owner\",\"iii\",\"correspond\",\"rotat\",\"chef\",\"organ\",\"rapidli\",\"happi\",\"builder\",\"display\",\"northern\",\"eastern\",\"pipelin\",\"gold\",\"c\",\"shape\",\"journey\",\"chain\",\"ground\",\"club\",\"sen\",\"superior\",\"for\\u00e2\",\"tender\",\"visa\",\"pack\",\"acquisit\",\"method\",\"transact\",\"now\\u00e2\",\"mandatori\",\"lift\",\"intervent\",\"dental\",\"advisor\",\"optimis\",\"box\",\"inventori\",\"categori\",\"steel\",\"server\",\"merchandis\",\"feedback\",\"holiday\",\"iv\",\"agreement\",\"deploy\",\"scale\",\"wage\",\"what\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]}},\"selected\":{\"id\":\"1187\"},\"selection_policy\":{\"id\":\"1186\"}},\"id\":\"1156\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"overlay\":{\"id\":\"1145\"}},\"id\":\"1144\",\"type\":\"BoxSelectTool\"},{\"attributes\":{},\"id\":\"1182\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1127\",\"type\":\"LinearScale\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1181\"},\"group\":null,\"major_label_policy\":{\"id\":\"1182\"},\"ticker\":{\"id\":\"1134\"}},\"id\":\"1133\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1184\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#8724B5\"},\"hatch_alpha\":{\"value\":0.2},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1160\",\"type\":\"Scatter\"}],\"root_ids\":[\"1120\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.2\"}};\n",
       "  const render_items = [{\"docid\":\"90eac291-23b1-40ea-9bed-f4eed5e94f08\",\"root_ids\":[\"1120\"],\"roots\":{\"1120\":\"da63df96-8cf2-46e7-81e4-c39e820773e4\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1120"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_wv(my_embedding, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041216f4",
   "metadata": {},
   "source": [
    "#### GloVe: Global Vectors for Word Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a634fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# All Import Statements Defined Here # Note: Do not add to this list.\n",
    "# ----------------\n",
    "import sys\n",
    "assert sys.version_info[0]==3 \n",
    "assert sys.version_info[1] >= 5\n",
    "from gensim.models import KeyedVectors \n",
    "from gensim.test.utils import datapath \n",
    "import pprint\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [10, 5] \n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.decomposition import PCA\n",
    "START_TOKEN = '<START>' \n",
    "END_TOKEN = '<END>'\n",
    "np.random.seed(1212) \n",
    "random.seed(1212)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20393f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load GloVe Vectors\"\"\"\n",
    "def load_embedding_model(data_job): \n",
    "    import gensim.downloader as api\n",
    "    #data_job = api.load(\"glove-wiki-gigaword-200\")\n",
    "    print(\"Loaded vocab size %i\" % len(data_job))\n",
    "    print(\"The loaded object is of type %s\" % str(type(data_job))) \n",
    "    return data_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7db5c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size 29654\n",
      "The loaded object is of type <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------- # Run Cell to Load Word Vectors\n",
    "# Note: This will take several minutes # (8 mins in my case )\n",
    "# -----------------------------------\n",
    "data_job = load_embedding_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "681039ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=29654, step=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9fe981a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[year, experi, fresh, produc, want, manag, sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[opportun, client, solut, analyst, provid, tec...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[innov, busi, develop, role, awardwin, compani...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[role, seek, automot, workshop, technician, jo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[â, earli, start, weekend, shift, experi, nece...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29649</th>\n",
       "      <td>[hotel, snapshot, radisson, blu, plaza, sydney...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29650</th>\n",
       "      <td>[organis, airservic, govern, own, organis, pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29651</th>\n",
       "      <td>[compani, role, client, australiaâ, lead, comm...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29652</th>\n",
       "      <td>[long, term, contract, month, possibl, extens,...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29653</th>\n",
       "      <td>[custom, servic, repres, west, wyalong, time, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29654 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         job_description  job_type  category\n",
       "0      [year, experi, fresh, produc, want, manag, sto...         0        11\n",
       "1      [opportun, client, solut, analyst, provid, tec...         0         8\n",
       "2      [innov, busi, develop, role, awardwin, compani...         0         0\n",
       "3      [role, seek, automot, workshop, technician, jo...         0         0\n",
       "4      [â, earli, start, weekend, shift, experi, nece...         0         0\n",
       "...                                                  ...       ...       ...\n",
       "29649  [hotel, snapshot, radisson, blu, plaza, sydney...         0         6\n",
       "29650  [organis, airservic, govern, own, organis, pro...         0        28\n",
       "29651  [compani, role, client, australiaâ, lead, comm...         0         5\n",
       "29652  [long, term, contract, month, possibl, extens,...         1         8\n",
       "29653  [custom, servic, repres, west, wyalong, time, ...         1         8\n",
       "\n",
       "[29654 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd9000",
   "metadata": {},
   "source": [
    "#### Train a complete model and then get its model.wv property, which contains independent keyed vectors. e.g., train vectors using word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1862ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#model = Word2Vec(common_texts, window=5, min_count=1, workers=4)\n",
    "model = Word2Vec(data_job, window=5, min_count=1, workers=4)\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb452236",
   "metadata": {},
   "source": [
    "#### Load word vector file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf6508be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_vectors.save(\"vectors_wv\")\n",
    "word_vectors = KeyedVectors.load(\"vectors_wv\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0849a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors_m = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87bd2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = my_embedding.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5704c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_scores = model.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8800fdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'â': 0,\n",
       " 'work': 1,\n",
       " 'experi': 2,\n",
       " 'manag': 3,\n",
       " 'role': 4,\n",
       " 'team': 5,\n",
       " 'servic': 6,\n",
       " 'skill': 7,\n",
       " 'provid': 8,\n",
       " 'develop': 9}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in word_vectors.key_to_index.items() if value<10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e29024a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9507627 ,  1.0146029 ,  1.0702271 , -1.09274   , -0.23753747,\n",
       "        2.345818  , -0.02056601, -1.1699958 ,  2.3283718 ,  0.5882244 ,\n",
       "       -1.6269332 ,  0.4547017 , -0.23103994,  0.8603506 ,  0.2097447 ,\n",
       "        1.8126026 ,  2.1914046 ,  3.0524237 ,  1.2384477 ,  0.32909718,\n",
       "       -0.8360463 , -0.4356144 ,  0.00347651,  0.5036618 ,  1.5680369 ,\n",
       "        3.7829072 ,  0.21651338,  0.8203105 , -0.68331975,  2.1179786 ,\n",
       "       -0.257093  , -0.01681009, -1.2799481 , -0.7847436 ,  1.3500309 ,\n",
       "        1.5619758 , -0.05659841,  0.32628757,  1.6478388 ,  3.3144503 ,\n",
       "        1.2479017 , -0.23970324, -0.21563555, -1.8496777 ,  0.25740215,\n",
       "        1.2076046 ,  3.3718114 , -0.55889475, -0.5681432 ,  0.06519304,\n",
       "        1.0654566 ,  1.8309411 ,  1.1765432 ,  2.2018282 ,  2.1071627 ,\n",
       "        0.48404068, -0.84435576,  0.05815728,  1.0042373 , -0.5717208 ,\n",
       "       -1.3523595 ,  0.79126054, -1.71321   , -0.9088836 ,  0.7349794 ,\n",
       "       -2.0533893 , -0.2595059 , -1.5880747 ,  0.46655884, -0.14522608,\n",
       "       -1.0190488 , -1.4927531 , -0.32952666,  2.349276  , -2.4195514 ,\n",
       "       -0.18313022, -2.1127582 , -1.6950568 ,  2.839163  ,  1.805307  ,\n",
       "       -0.5680501 , -0.00273096,  0.57253706, -0.67230785,  0.2194053 ,\n",
       "       -0.03203251, -0.8117124 , -0.01270298,  0.71674514, -1.4395173 ,\n",
       "       -2.280829  ,  1.0166706 ,  0.43044657, -2.1231291 , -1.1919523 ,\n",
       "        0.30229205, -0.49083626, -1.8656304 , -0.7616805 ,  0.90306276],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.get_vector('work')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5143815",
   "metadata": {},
   "source": [
    "#### Reducing dimensionality of Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4192a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Put the GloVe vectors into a matrix M. Param:\n",
    "wv_pretrained: KeyedVectors object; the 400000 GloVe vectors loaded from file\n",
    "Return:\n",
    "            M: numpy matrix shape (num words, 200) containing the vectors\n",
    "            word2Ind: dictionary mapping each word to its row number in M\n",
    "\"\"\"\n",
    "def get_matrix_of_vectors(wv_pretrained, required_words=['barrels', 'bpd', 'ecuador','energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'venezuela']):\n",
    "    import random\n",
    "    words = list(wv_pretrained.key_to_index.keys())\n",
    "    print(\"Shuffling words ...\")\n",
    "    random.seed(224)\n",
    "    random.shuffle(words)\n",
    "    words = words[:10000]\n",
    "    print(\"Putting %i words into word2Ind and matrix M...\" % len(words)) \n",
    "    word2Ind = {}\n",
    "    M = []\n",
    "    curInd = 0\n",
    "    for w in words: \n",
    "        try:\n",
    "            M.append(wv_pretrained.get_vector(w, norm=True)) \n",
    "            word2Ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError: \n",
    "            continue\n",
    "    for w in required_words:\n",
    "        if w in words: \n",
    "            continue\n",
    "        try:\n",
    "            M.append(wv_pretrained.get_vector(w, norm=True)) \n",
    "            word2Ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError: \n",
    "            continue\n",
    "    M = np.stack(M) \n",
    "    print(\"Done.\") \n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f23450",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8dfe62",
   "metadata": {},
   "source": [
    "**Using Pretrained Word2Vec Vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d260e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "#wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50671697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bash', 0.9530633091926575),\n",
       " ('perl', 0.9224193096160889),\n",
       " ('mysql', 0.9156444072723389),\n",
       " ('plsql', 0.9116639494895935),\n",
       " ('mongodb', 0.9014299511909485),\n",
       " ('apach', 0.9001218676567078),\n",
       " ('python', 0.8969963192939758),\n",
       " ('tsql', 0.8958423137664795),\n",
       " ('script', 0.892011821269989),\n",
       " ('docker', 0.8869137763977051)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=[\"powershel\", \"sccm\"], negative=[\"sccm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf64bb",
   "metadata": {},
   "source": [
    "**Plot using TSNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5f2bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_closestwords_tsnescatterplot(model, word): \n",
    "    arr = np.empty((0,100), dtype='f')\n",
    "    word_labels = [word] \n",
    "    # get close words\n",
    "    close_words = model.similar_by_word(word)\n",
    "    # add the vector for each of the closest words to the array\n",
    "    arr = np.append(arr, np.array([model[word]]), axis=0) \n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model[wrd_score[0]] \n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "    # find tsne coords for 2 dimensions\n",
    "    tsne = TSNE(n_components=2, random_state=0) \n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    # display scatter plot plt.scatter(x_coords, y_coords)\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005) \n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005) \n",
    "    plt.title(f'Words closest to: {word}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42668d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_closestwords_tsnescatterplot(word_vectors, \"sccm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98958de",
   "metadata": {},
   "source": [
    "**Interactive Visualisation using bokeh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da8e155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import push_notebook, output_notebook \n",
    "from bokeh.models import ColumnDataSource, LabelSet \n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import push_notebook, output_notebook \n",
    "from bokeh.models import ColumnDataSource, LabelSet \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bf7b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''makes an interactive scatter plot with text labels for each point'''\n",
    "def interactive_tsne(text_labels, tsne_array):\n",
    "    # Define a dataframe to be used by bokeh context\n",
    "    bokeh_df = pd.DataFrame(tsne_array, text_labels, columns=['x','y']) \n",
    "    bokeh_df['text_labels'] = bokeh_df.index\n",
    "# interactive controls to include to the plot\n",
    "    TOOLS=\"hover, zoom_in, zoom_out, box_zoom, undo, redo, reset, box_select\" \n",
    "    p = figure(tools=TOOLS, plot_width=700, plot_height=700)\n",
    "# define data source for the plot\n",
    "    source = ColumnDataSource(bokeh_df)\n",
    "# scatter plot\n",
    "    p.scatter('x', 'y', source=source, fill_alpha=0.6, fill_color=\"#8724B5\", line_color=None)\n",
    "# text labels\n",
    "    labels = LabelSet(x='x', y='y', text='text_labels', y_offset=8, text_font_size=\"8pt\", text_color=\"#555555\", source=source, text_align='center')\n",
    "    p.add_layout(labels)\n",
    "# show plot inline\n",
    "    output_notebook()\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae9dad0",
   "metadata": {},
   "source": [
    "## Data Prepreocessing and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52472974",
   "metadata": {},
   "source": [
    "### Training my own Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2173e",
   "metadata": {},
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf2e6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv(\"./dataset/job.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(lambda x:x.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4efdf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_topword_by_label(df, label_colum, to_colum):\n",
    "    df[to_colum] = \"\"\n",
    "    for k in df[label_colum].value_counts().keys():\n",
    "\n",
    "        df_tmp = df[df[label_colum]==k]\n",
    "        tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False)    \n",
    "        tfidf_matrix = tfidf.fit_transform(df_tmp['job_description'])\n",
    "        xlabels = tfidf.get_feature_names_out()\n",
    "        assert tfidf_matrix.shape[0] == len(df_tmp)\n",
    "\n",
    "        for idx, row in zip(df_tmp.index, tfidf_matrix):\n",
    "            \n",
    "            row = row.toarray()[0].ravel()\n",
    "            top_idx = row.argsort()[-10:][::-1]\n",
    "            top_words = [xlabels[i] for i in top_idx]\n",
    "\n",
    "            df[to_colum][idx] = top_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6456c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_topword_by_label(df, label_colum='job_type', to_colum='10words_type')\n",
    "gene_topword_by_label(df, label_colum='category', to_colum='10words_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1058e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    20757\n",
       "test      5932\n",
       "val       2965\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import split_by_jobtype\n",
    "proportion = [0.7, 0.10, 0.20]\n",
    "df = split_by_jobtype(df, proportion)\n",
    "df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f4b9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset/job_prapare.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63621680",
   "metadata": {},
   "source": [
    "## Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7fef0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/job_prapare.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(eval)\n",
    "df['10words_type']=df['10words_type'].apply(eval)\n",
    "df['10words_category']=df['10words_category'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b24c2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/liugensheng/OneDrive - The University of Western Australia/2022 sem1/CITS4012 NLP/project2',\n",
       " '/Users/liugensheng/miniconda3/lib/python39.zip',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49123f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_text_vectors = [b['text_vector'] for b in batch]\n",
    "    batch_labels = [b['label'] for b in batch]\n",
    "\n",
    "\n",
    "    batch_text_vectors = torch.tensor(np.stack(batch_text_vectors))\n",
    "    batch_labels = torch.tensor(np.stack(batch_labels))\n",
    "\n",
    "\n",
    "    batch_data = {\n",
    "        'batch_text_vectors': batch_text_vectors,\n",
    "        'batch_labels': batch_labels\n",
    "    }\n",
    "\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f529002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mydataset import JobVectorizer, JobDatasetOnehot, JobDatasetMyembedding, JobDatasetPretrainembedding\n",
    "text_column = \"10words_type\"\n",
    "label_column = \"job_type\"\n",
    "label_nums = len(df[label_column].value_counts())\n",
    "\n",
    "train_df = df[df.split=='train'].copy().reset_index(drop=True)\n",
    "val_df = df[df.split=='val'].copy().reset_index(drop=True)\n",
    "test_df = df[df.split=='test'].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d64af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobvectorizer = JobVectorizer.from_dataframe(df, text_column=text_column, cutoff=10)\n",
    "\n",
    "jobtype_onehot_train = JobDatasetOnehot(train_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n",
    "jobtype_onehot_val = JobDatasetOnehot(val_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n",
    "jobtype_onehot_test = JobDatasetOnehot(test_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c41dea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "my_embedding = KeyedVectors.load(\"./dataset/my_embedding\", mmap='r')\n",
    "jobtype_myembedding_train = JobDatasetMyembedding(train_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)\n",
    "jobtype_myembedding_val = JobDatasetMyembedding(val_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)\n",
    "jobtype_myembedding_test = JobDatasetMyembedding(test_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62462754",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtype_pretrainembedding_train = JobDatasetPretrainembedding(train_df, text_column=text_column, label_column=label_column)\n",
    "jobtype_pretrainembedding_val = JobDatasetPretrainembedding(val_df, text_column=text_column, label_column=label_column)\n",
    "jobtype_pretrainembedding_test = JobDatasetPretrainembedding(test_df, text_column=text_column, label_column=label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67460bdb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b655378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad24c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "cores = 16\n",
    "model = Word2Vec(min_count=1, \n",
    "                 window=2, vector_size=100, sample=6e-5, alpha=0.03, min_alpha=0.0007, negative=20, workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a2f10",
   "metadata": {},
   "source": [
    "**Comparing the purposely trained and the pre-trained vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0763a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vsphere', 0.8840079307556152),\n",
       " ('vmware', 0.8793255090713501),\n",
       " ('soe', 0.8749751448631287),\n",
       " ('virtualis', 0.8664376139640808),\n",
       " ('unix', 0.864485502243042),\n",
       " ('hyperv', 0.8633731603622437),\n",
       " ('powershel', 0.8550437688827515),\n",
       " ('scom', 0.8535946607589722),\n",
       " ('mysql', 0.8357590436935425),\n",
       " ('dn', 0.8356968760490417)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our trained domain specific embeddings\n",
    "word_vectors.most_similar(positive=[\"sccm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "028afe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('redhat', 0.939782440662384),\n",
       " ('nginx', 0.9359487891197205),\n",
       " ('cloudform', 0.913392186164856),\n",
       " ('scom', 0.9022396802902222),\n",
       " ('babel', 0.8975291848182678),\n",
       " ('elasticsearch', 0.8940725326538086),\n",
       " ('netscal', 0.8929364681243896),\n",
       " ('xen', 0.8927617073059082),\n",
       " ('kafka', 0.8914523720741272),\n",
       " ('openvswitchcontrailnsxnuagenfv', 0.8912717700004578)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrained embeddings\n",
    "word_vectors.most_similar(positive=[\"ubuntu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce503f",
   "metadata": {},
   "source": [
    "## Task 1: Binary Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd77b2d",
   "metadata": {},
   "source": [
    "### 3.1 Feed-forward Neural Netword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29a9d55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "import pandas as pd\n",
    "\n",
    "from mydataset import JobVectorizer, JobDatasetOnehot, JobDatasetMyembedding, JobDatasetPretrainembedding\n",
    "from mydataset import collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import compute_accuracy, train_engin, test_engine, make_train_state, get_logger\n",
    "import torch.optim as optim \n",
    "\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from models import JobtypeClassifier_FeedForward, JobtypeClassifier_Conv1d\n",
    "from utils import compute_accuracy, train_engin, test_engine, make_train_state\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb2241",
   "metadata": {},
   "source": [
    "**Data and path information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2798d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    loss_func= nn.CrossEntropyLoss(),\n",
    "    optimizer=None,\n",
    "    model_id=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d348944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/job_prapare.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(eval)\n",
    "df['10words_type']=df['10words_type'].apply(eval)\n",
    "df['10words_category']=df['10words_category'].apply(eval)\n",
    "\n",
    "\n",
    "text_column = \"10words_type\"\n",
    "label_column = \"job_type\"\n",
    "label_nums = len(df[label_column].value_counts())\n",
    "\n",
    "train_df = df[df.split=='train'].copy().reset_index(drop=True)\n",
    "val_df = df[df.split=='val'].copy().reset_index(drop=True)\n",
    "test_df = df[df.split=='test'].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25afe180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:loading KeyedVectors object from ./dataset/my_embedding\n",
      "INFO:loading KeyedVectors object from ./dataset/my_embedding\n",
      "INFO:loading KeyedVectors object from ./dataset/my_embedding\n",
      "DEBUG:{'uri': './dataset/my_embedding', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "DEBUG:{'uri': './dataset/my_embedding', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "DEBUG:{'uri': './dataset/my_embedding', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:loading wv recursively from ./dataset/my_embedding.wv.* with mmap=r\n",
      "INFO:loading wv recursively from ./dataset/my_embedding.wv.* with mmap=r\n",
      "INFO:loading wv recursively from ./dataset/my_embedding.wv.* with mmap=r\n",
      "INFO:setting ignored attribute cum_table to None\n",
      "INFO:setting ignored attribute cum_table to None\n",
      "INFO:setting ignored attribute cum_table to None\n",
      "INFO:Word2Vec lifecycle event {'fname': './dataset/my_embedding', 'datetime': '2022-05-30T11:19:34.255874', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'loaded'}\n",
      "INFO:Word2Vec lifecycle event {'fname': './dataset/my_embedding', 'datetime': '2022-05-30T11:19:34.255874', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'loaded'}\n",
      "INFO:Word2Vec lifecycle event {'fname': './dataset/my_embedding', 'datetime': '2022-05-30T11:19:34.255874', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jobvectorizer = JobVectorizer.from_dataframe(df, text_column=text_column, cutoff=10)\n",
    "\n",
    "jobtype_onehot_train = JobDatasetOnehot(train_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n",
    "jobtype_onehot_val = JobDatasetOnehot(val_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n",
    "jobtype_onehot_test = JobDatasetOnehot(test_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "my_embedding = KeyedVectors.load(\"./dataset/my_embedding\", mmap='r')\n",
    "my_embedding.wv.add_vectors(\"<pad>\", torch.zeros(100))\n",
    "\n",
    "jobtype_myembedding_train = JobDatasetMyembedding(train_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)\n",
    "jobtype_myembedding_val = JobDatasetMyembedding(val_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)\n",
    "jobtype_myembedding_test = JobDatasetMyembedding(test_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)\n",
    "\n",
    "jobtype_pretrainembedding_train = JobDatasetPretrainembedding(train_df, text_column=text_column, label_column=label_column)\n",
    "jobtype_pretrainembedding_val = JobDatasetPretrainembedding(val_df, text_column=text_column, label_column=label_column)\n",
    "jobtype_pretrainembedding_test = JobDatasetPretrainembedding(test_df, text_column=text_column, label_column=label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f23115",
   "metadata": {},
   "source": [
    "**Define the model and train**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50966f15",
   "metadata": {},
   "source": [
    "*`Build,train and compare the performance of the following models on Task 1, can switch among three embeddings (one-hot, pre-trained, domain specific). First create a baseline using the top 10 words only with a Feed-forward Neural Network model.Then use the top 10 words only with a CNN Conv1d based model. See Lab 09 for coding examples. Lastly, the full job description as input for a CNN Conv1d based model.`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c772d248",
   "metadata": {},
   "source": [
    "**text--10word/job_description; embedding--onehot/my_embedding/pretrain embedding; model--feed_forward/conv1d**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d916651",
   "metadata": {},
   "source": [
    "**`model 1: text--10word, embedding--onehot, model--feed_forward`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae69b09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=1, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:03, 46.34it/s]\n",
      "INFO:TRAIN loss: 0.6279340766690261, acc: 67.99385590125618\n",
      "24it [00:00, 53.20it/s]\n",
      "INFO:VAL loss: 0.6122090543309848, acc: 66.14583333333331\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:03, 48.98it/s]\n",
      "INFO:TRAIN loss: 0.5770168986422882, acc: 69.30415571136429\n",
      "24it [00:00, 54.28it/s]\n",
      "INFO:VAL loss: 0.592333811024825, acc: 68.10205853174604\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:03, 49.93it/s]\n",
      "INFO:TRAIN loss: 0.5528440808226, acc: 71.21129126497223\n",
      "24it [00:00, 53.42it/s]\n",
      "INFO:VAL loss: 0.5798646447559198, acc: 68.7531001984127\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:03, 48.80it/s]\n",
      "INFO:TRAIN loss: 0.5350118484233785, acc: 73.00955850131461\n",
      "24it [00:00, 53.88it/s]\n",
      "INFO:VAL loss: 0.5719910338521004, acc: 69.99627976190477\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:03, 50.01it/s]\n",
      "INFO:TRAIN loss: 0.5219106933821926, acc: 74.18200408997954\n",
      "24it [00:00, 53.72it/s]\n",
      "INFO:VAL loss: 0.5657257810235022, acc: 71.07669890873015\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:03, 49.33it/s]\n",
      "INFO:TRAIN loss: 0.5100677726458919, acc: 75.3911955886648\n",
      "24it [00:00, 48.02it/s]\n",
      "INFO:VAL loss: 0.5607846242686112, acc: 71.6951884920635\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:03, 47.23it/s]\n",
      "INFO:TRAIN loss: 0.5013387197731468, acc: 76.02728783231083\n",
      "24it [00:00, 52.08it/s]\n",
      "INFO:VAL loss: 0.5586514522631963, acc: 71.89050099206351\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:03, 48.73it/s]\n",
      "INFO:TRAIN loss: 0.49316827596330925, acc: 76.48353052877596\n",
      "24it [00:00, 47.34it/s]\n",
      "INFO:VAL loss: 0.5563807425399622, acc: 72.11836557539682\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:03, 46.30it/s]\n",
      "INFO:TRAIN loss: 0.48553697536328083, acc: 77.15545574057842\n",
      "24it [00:00, 52.01it/s]\n",
      "INFO:VAL loss: 0.5555208424727122, acc: 71.89050099206348\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:03, 48.33it/s]\n",
      "INFO:TRAIN loss: 0.47990692137209195, acc: 77.40902534326624\n",
      "24it [00:00, 51.54it/s]\n",
      "INFO:VAL loss: 0.5542601359387239, acc: 72.15401785714286\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:03, 48.90it/s]\n",
      "INFO:TRAIN loss: 0.4746133054326649, acc: 77.8346844872918\n",
      "24it [00:00, 52.79it/s]\n",
      "INFO:VAL loss: 0.5540018354852994, acc: 72.48263888888889\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:03, 48.20it/s]\n",
      "INFO:TRAIN loss: 0.4701674282550811, acc: 78.01202344434704\n",
      "24it [00:00, 51.82it/s]\n",
      "INFO:VAL loss: 0.5537381954491138, acc: 72.84071180555556\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:03, 48.97it/s]\n",
      "INFO:TRAIN loss: 0.46492861037605376, acc: 78.27654834940111\n",
      "24it [00:00, 50.16it/s]\n",
      "INFO:VAL loss: 0.5531919623414676, acc: 72.8081597222222\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:03, 47.51it/s]\n",
      "INFO:TRAIN loss: 0.460842514879133, acc: 78.65564745836988\n",
      "24it [00:00, 51.94it/s]\n",
      "INFO:VAL loss: 0.553998830417792, acc: 72.97092013888891\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:03, 48.33it/s]\n",
      "INFO:TRAIN loss: 0.45808075231277146, acc: 78.81678169734151\n",
      "24it [00:00, 49.21it/s]\n",
      "INFO:VAL loss: 0.5541514381766319, acc: 72.93836805555554\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:03, 47.30it/s]\n",
      "INFO:TRAIN loss: 0.45405334325655833, acc: 79.14407135553603\n",
      "24it [00:00, 50.02it/s]\n",
      "INFO:VAL loss: 0.5560285312434039, acc: 72.97402033730157\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:03, 46.50it/s]\n",
      "INFO:TRAIN loss: 0.4504228812053892, acc: 79.26343850423608\n",
      "24it [00:00, 49.72it/s]\n",
      "INFO:VAL loss: 0.5560601428151131, acc: 73.23443700396827\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:03, 47.25it/s]\n",
      "INFO:TRAIN loss: 0.4482056668565318, acc: 79.44602687700853\n",
      "24it [00:00, 48.90it/s]\n",
      "INFO:VAL loss: 0.5575724852581819, acc: 73.20188492063494\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:03, 48.06it/s]\n",
      "INFO:TRAIN loss: 0.4460802347016481, acc: 79.44420099328079\n",
      "24it [00:00, 51.98it/s]\n",
      "INFO:VAL loss: 0.5578142901261649, acc: 73.20188492063492\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:03, 47.01it/s]\n",
      "INFO:TRAIN loss: 0.44278932275947613, acc: 79.65645997662871\n",
      "24it [00:00, 49.81it/s]\n",
      "INFO:VAL loss: 0.5594787386556467, acc: 73.42974950396825\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:03, 47.67it/s]\n",
      "INFO:TRAIN loss: 0.44125005749105645, acc: 79.83379893368392\n",
      "24it [00:00, 51.71it/s]\n",
      "INFO:VAL loss: 0.5614990616838138, acc: 73.33209325396825\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:03, 47.26it/s]\n",
      "INFO:TRAIN loss: 0.4382167482302963, acc: 79.87214249196614\n",
      "24it [00:00, 49.55it/s]\n",
      "INFO:VAL loss: 0.5617787390947342, acc: 73.13678075396825\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:03, 46.89it/s]\n",
      "INFO:TRAIN loss: 0.4359767669183343, acc: 80.031679082676\n",
      "24it [00:00, 50.96it/s]\n",
      "INFO:VAL loss: 0.5633253281315167, acc: 73.2995411706349\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:03, 46.08it/s]\n",
      "INFO:TRAIN loss: 0.43452459208073047, acc: 80.1069967864447\n",
      "24it [00:00, 49.26it/s]\n",
      "INFO:VAL loss: 0.5652105050782362, acc: 73.33209325396824\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:03, 48.66it/s]\n",
      "INFO:TRAIN loss: 0.43231517204477726, acc: 80.14488387379497\n",
      "24it [00:00, 53.79it/s]\n",
      "INFO:VAL loss: 0.5658508762717247, acc: 73.20188492063491\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:03, 48.54it/s]\n",
      "INFO:TRAIN loss: 0.43074129860093996, acc: 80.31354988314348\n",
      "24it [00:00, 46.57it/s]\n",
      "INFO:VAL loss: 0.5673712616165479, acc: 73.23443700396825\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:03, 45.94it/s]\n",
      "INFO:TRAIN loss: 0.4286008080456154, acc: 80.37152169149867\n",
      "24it [00:00, 50.46it/s]\n",
      "INFO:VAL loss: 0.5686759799718857, acc: 73.16933283730161\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:03, 47.76it/s]\n",
      "INFO:TRAIN loss: 0.42790940147967427, acc: 80.46646764534037\n",
      "24it [00:00, 51.59it/s]\n",
      "INFO:VAL loss: 0.5700647408763568, acc: 73.13678075396827\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:03, 47.58it/s]\n",
      "INFO:TRAIN loss: 0.4259996668327074, acc: 80.51964650891028\n",
      "24it [00:00, 53.77it/s]\n",
      "INFO:VAL loss: 0.5716565971573194, acc: 73.16933283730158\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:03, 46.82it/s]\n",
      "INFO:TRAIN loss: 0.424139004543515, acc: 80.7079407683319\n",
      "24it [00:00, 48.15it/s]\n",
      "INFO:VAL loss: 0.5737207730611166, acc: 73.16933283730158\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:03, 46.87it/s]\n",
      "INFO:TRAIN loss: 0.42319968013675663, acc: 80.72095018989187\n",
      "24it [00:00, 51.43it/s]\n",
      "INFO:VAL loss: 0.5756102365752062, acc: 73.10422867063492\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:03, 47.32it/s]\n",
      "INFO:TRAIN loss: 0.4219799041748047, acc: 80.79330083260298\n",
      "24it [00:00, 50.88it/s]\n",
      "INFO:VAL loss: 0.5769522984822592, acc: 73.1693328373016\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:03, 47.30it/s]\n",
      "INFO:TRAIN loss: 0.42173578256478345, acc: 80.75838080631027\n",
      "24it [00:00, 48.79it/s]\n",
      "INFO:VAL loss: 0.5781386929253738, acc: 73.00657242063491\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:03, 48.51it/s]\n",
      "INFO:TRAIN loss: 0.4200252177525151, acc: 80.89828914694716\n",
      "24it [00:00, 51.66it/s]\n",
      "INFO:VAL loss: 0.5791306781272092, acc: 72.81125992063494\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:03, 47.65it/s]\n",
      "INFO:TRAIN loss: 0.41847442191071327, acc: 80.98501862401397\n",
      "24it [00:00, 51.58it/s]\n",
      "INFO:VAL loss: 0.5810543882350127, acc: 72.81125992063492\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:03, 46.89it/s]\n",
      "INFO:TRAIN loss: 0.41807560924372045, acc: 80.97451979257958\n",
      "24it [00:00, 50.37it/s]\n",
      "INFO:VAL loss: 0.5829640006025631, acc: 73.00657242063491\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:03, 48.71it/s]\n",
      "INFO:TRAIN loss: 0.416878007306643, acc: 81.0224492404324\n",
      "24it [00:00, 51.34it/s]\n",
      "INFO:VAL loss: 0.5837183718880018, acc: 72.84381200396824\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:03, 48.14it/s]\n",
      "INFO:TRAIN loss: 0.41606533984465094, acc: 81.13359991235764\n",
      "24it [00:00, 51.76it/s]\n",
      "INFO:VAL loss: 0.585462571432193, acc: 73.13988095238093\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:03, 49.34it/s]\n",
      "INFO:TRAIN loss: 0.4152338758933763, acc: 81.19887525562372\n",
      "24it [00:00, 50.57it/s]\n",
      "INFO:VAL loss: 0.5891106923421223, acc: 72.94146825396825\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:03, 48.98it/s]\n",
      "INFO:TRAIN loss: 0.4137135879393735, acc: 81.19636466549807\n",
      "24it [00:00, 51.00it/s]\n",
      "INFO:VAL loss: 0.5887912015120188, acc: 72.81125992063492\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:03, 48.43it/s]\n",
      "INFO:TRAIN loss: 0.41403763681832984, acc: 81.21850350569679\n",
      "24it [00:00, 51.39it/s]\n",
      "INFO:VAL loss: 0.5905287514130275, acc: 72.90891617063491\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:03, 49.60it/s]\n",
      "INFO:TRAIN loss: 0.4119442582496105, acc: 81.25776000584285\n",
      "24it [00:00, 53.82it/s]\n",
      "INFO:VAL loss: 0.5921799366672833, acc: 72.84381200396825\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:03, 48.35it/s]\n",
      "INFO:TRAIN loss: 0.41145746839558384, acc: 81.24817411627231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 50.49it/s]\n",
      "INFO:VAL loss: 0.5932300177713236, acc: 72.91201636904763\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:03, 47.85it/s]\n",
      "INFO:TRAIN loss: 0.41055207640115465, acc: 81.38808245690916\n",
      "24it [00:00, 50.70it/s]\n",
      "INFO:VAL loss: 0.5951797564824423, acc: 72.87946428571428\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:03, 47.68it/s]\n",
      "INFO:TRAIN loss: 0.41079535641553216, acc: 81.2659764826176\n",
      "24it [00:00, 50.80it/s]\n",
      "INFO:VAL loss: 0.5962443848450979, acc: 72.81436011904762\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:03, 47.45it/s]\n",
      "INFO:TRAIN loss: 0.4093617740218626, acc: 81.35841184633365\n",
      "24it [00:00, 52.04it/s]\n",
      "INFO:VAL loss: 0.598241710414489, acc: 72.8794642857143\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:03, 48.16it/s]\n",
      "INFO:TRAIN loss: 0.4095854130259322, acc: 81.27556237218813\n",
      "24it [00:00, 53.62it/s]\n",
      "INFO:VAL loss: 0.5996650792658329, acc: 72.87946428571429\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:03, 49.67it/s]\n",
      "INFO:TRAIN loss: 0.40740330032775735, acc: 81.42642601519138\n",
      "24it [00:00, 51.40it/s]\n",
      "INFO:VAL loss: 0.6015014623602232, acc: 72.87946428571429\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:03, 47.48it/s]\n",
      "INFO:TRAIN loss: 0.40783357254566577, acc: 81.47252957931636\n",
      "24it [00:00, 48.81it/s]\n",
      "INFO:VAL loss: 0.6032675020396709, acc: 72.8794642857143\n",
      "INFO:TRAIN: 49|50\n",
      "163it [00:03, 47.33it/s]\n",
      "INFO:TRAIN loss: 0.40660539415716396, acc: 81.51657902424772\n",
      "24it [00:00, 51.72it/s]\n",
      "INFO:VAL loss: 0.6041094971199831, acc: 72.94456845238098\n",
      "24it [00:00, 52.57it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.6041094971199831, acc: 72.94456845238098\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.6279340766690261, 0.5770168986422882, 0.5528440808226, 0.5350118484233785, 0.5219106933821926, 0.5100677726458919, 0.5013387197731468, 0.49316827596330925, 0.48553697536328083, 0.47990692137209195, 0.4746133054326649, 0.4701674282550811, 0.46492861037605376, 0.460842514879133, 0.45808075231277146, 0.45405334325655833, 0.4504228812053892, 0.4482056668565318, 0.4460802347016481, 0.44278932275947613, 0.44125005749105645, 0.4382167482302963, 0.4359767669183343, 0.43452459208073047, 0.43231517204477726, 0.43074129860093996, 0.4286008080456154, 0.42790940147967427, 0.4259996668327074, 0.424139004543515, 0.42319968013675663, 0.4219799041748047, 0.42173578256478345, 0.4200252177525151, 0.41847442191071327, 0.41807560924372045, 0.416878007306643, 0.41606533984465094, 0.4152338758933763, 0.4137135879393735, 0.41403763681832984, 0.4119442582496105, 0.41145746839558384, 0.41055207640115465, 0.41079535641553216, 0.4093617740218626, 0.4095854130259322, 0.40740330032775735, 0.40783357254566577, 0.40660539415716396], 'train_acc': [67.99385590125618, 69.30415571136429, 71.21129126497223, 73.00955850131461, 74.18200408997954, 75.3911955886648, 76.02728783231083, 76.48353052877596, 77.15545574057842, 77.40902534326624, 77.8346844872918, 78.01202344434704, 78.27654834940111, 78.65564745836988, 78.81678169734151, 79.14407135553603, 79.26343850423608, 79.44602687700853, 79.44420099328079, 79.65645997662871, 79.83379893368392, 79.87214249196614, 80.031679082676, 80.1069967864447, 80.14488387379497, 80.31354988314348, 80.37152169149867, 80.46646764534037, 80.51964650891028, 80.7079407683319, 80.72095018989187, 80.79330083260298, 80.75838080631027, 80.89828914694716, 80.98501862401397, 80.97451979257958, 81.0224492404324, 81.13359991235764, 81.19887525562372, 81.19636466549807, 81.21850350569679, 81.25776000584285, 81.24817411627231, 81.38808245690916, 81.2659764826176, 81.35841184633365, 81.27556237218813, 81.42642601519138, 81.47252957931636, 81.51657902424772], 'val_loss': [0.6122090543309848, 0.592333811024825, 0.5798646447559198, 0.5719910338521004, 0.5657257810235022, 0.5607846242686112, 0.5586514522631963, 0.5563807425399622, 0.5555208424727122, 0.5542601359387239, 0.5540018354852994, 0.5537381954491138, 0.5531919623414676, 0.553998830417792, 0.5541514381766319, 0.5560285312434039, 0.5560601428151131, 0.5575724852581819, 0.5578142901261649, 0.5594787386556467, 0.5614990616838138, 0.5617787390947342, 0.5633253281315167, 0.5652105050782362, 0.5658508762717247, 0.5673712616165479, 0.5686759799718857, 0.5700647408763568, 0.5716565971573194, 0.5737207730611166, 0.5756102365752062, 0.5769522984822592, 0.5781386929253738, 0.5791306781272092, 0.5810543882350127, 0.5829640006025631, 0.5837183718880018, 0.585462571432193, 0.5891106923421223, 0.5887912015120188, 0.5905287514130275, 0.5921799366672833, 0.5932300177713236, 0.5951797564824423, 0.5962443848450979, 0.598241710414489, 0.5996650792658329, 0.6015014623602232, 0.6032675020396709, 0.6041094971199831], 'val_acc': [66.14583333333331, 68.10205853174604, 68.7531001984127, 69.99627976190477, 71.07669890873015, 71.6951884920635, 71.89050099206351, 72.11836557539682, 71.89050099206348, 72.15401785714286, 72.48263888888889, 72.84071180555556, 72.8081597222222, 72.97092013888891, 72.93836805555554, 72.97402033730157, 73.23443700396827, 73.20188492063494, 73.20188492063492, 73.42974950396825, 73.33209325396825, 73.13678075396825, 73.2995411706349, 73.33209325396824, 73.20188492063491, 73.23443700396825, 73.16933283730161, 73.13678075396827, 73.16933283730158, 73.16933283730158, 73.10422867063492, 73.1693328373016, 73.00657242063491, 72.81125992063494, 72.81125992063492, 73.00657242063491, 72.84381200396824, 73.13988095238093, 72.94146825396825, 72.81125992063492, 72.90891617063491, 72.84381200396825, 72.91201636904763, 72.87946428571428, 72.81436011904762, 72.8794642857143, 72.87946428571429, 72.87946428571429, 72.8794642857143, 72.94456845238098], 'test_loss': 0.6041094971199831, 'test_acc': 72.94456845238098}\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "args.model_id=1\n",
    "train_dataloader = DataLoader(jobtype_onehot_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_onehot_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_onehot_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_FeedForward(num_features=len(jobvectorizer.text_vocab)) \n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "args.logger.handlers.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb73c5",
   "metadata": {},
   "source": [
    "**`acc:72.94`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e1737",
   "metadata": {},
   "source": [
    "We can see that the results of the forward propagation training on the one-hot dataset are not bad. It achieves an accuracy of 72.The 10 words selected after the IF-IDF process are already representative of the category. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ebdad",
   "metadata": {},
   "source": [
    "**`model 2: text--10word, embedding--my_embedding, model--feed_forward`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b6fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=2, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=2, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:01, 120.81it/s]\n",
      "INFO:TRAIN loss: 0.6306189666130788, acc: 66.67282902424772\n",
      "INFO:TRAIN loss: 0.6306189666130788, acc: 66.67282902424772\n",
      "24it [00:00, 141.78it/s]\n",
      "INFO:VAL loss: 0.6190424188971521, acc: 65.96602182539684\n",
      "INFO:VAL loss: 0.6190424188971521, acc: 65.96602182539684\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:01, 124.67it/s]\n",
      "INFO:TRAIN loss: 0.5905799542102345, acc: 69.60382887817704\n",
      "INFO:TRAIN loss: 0.5905799542102345, acc: 69.60382887817704\n",
      "24it [00:00, 143.43it/s]\n",
      "INFO:VAL loss: 0.6230197437107563, acc: 65.83581349206351\n",
      "INFO:VAL loss: 0.6230197437107563, acc: 65.83581349206351\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:01, 128.91it/s]\n",
      "INFO:TRAIN loss: 0.5832693777932713, acc: 70.04660568215012\n",
      "INFO:TRAIN loss: 0.5832693777932713, acc: 70.04660568215012\n",
      "24it [00:00, 142.65it/s]\n",
      "INFO:VAL loss: 0.6197305619716644, acc: 67.68818204365081\n",
      "INFO:VAL loss: 0.6197305619716644, acc: 67.68818204365081\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:01, 124.71it/s]\n",
      "INFO:TRAIN loss: 0.5824432356591606, acc: 70.26137525562375\n",
      "INFO:TRAIN loss: 0.5824432356591606, acc: 70.26137525562375\n",
      "24it [00:00, 136.24it/s]\n",
      "INFO:VAL loss: 0.6226911110182604, acc: 67.65562996031747\n",
      "INFO:VAL loss: 0.6226911110182604, acc: 67.65562996031747\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:01, 126.48it/s]\n",
      "INFO:TRAIN loss: 0.5816825114510541, acc: 70.51060838445804\n",
      "INFO:TRAIN loss: 0.5816825114510541, acc: 70.51060838445804\n",
      "24it [00:00, 132.56it/s]\n",
      "INFO:VAL loss: 0.6246705452601116, acc: 65.58469742063492\n",
      "INFO:VAL loss: 0.6246705452601116, acc: 65.58469742063492\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:01, 120.46it/s]\n",
      "INFO:TRAIN loss: 0.579704042592663, acc: 70.65097319602685\n",
      "INFO:TRAIN loss: 0.579704042592663, acc: 70.65097319602685\n",
      "24it [00:00, 130.47it/s]\n",
      "INFO:VAL loss: 0.6292249336838721, acc: 67.19680059523809\n",
      "INFO:VAL loss: 0.6292249336838721, acc: 67.19680059523809\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:01, 124.93it/s]\n",
      "INFO:TRAIN loss: 0.5794536118492754, acc: 70.50490249780896\n",
      "INFO:TRAIN loss: 0.5794536118492754, acc: 70.50490249780896\n",
      "24it [00:00, 132.83it/s]\n",
      "INFO:VAL loss: 0.6233949561913809, acc: 66.79222470238095\n",
      "INFO:VAL loss: 0.6233949561913809, acc: 66.79222470238095\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:01, 119.48it/s]\n",
      "INFO:TRAIN loss: 0.5800317108996805, acc: 70.46701541045867\n",
      "INFO:TRAIN loss: 0.5800317108996805, acc: 70.46701541045867\n",
      "24it [00:00, 142.93it/s]\n",
      "INFO:VAL loss: 0.6187168980638187, acc: 66.49615575396824\n",
      "INFO:VAL loss: 0.6187168980638187, acc: 66.49615575396824\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:01, 125.64it/s]\n",
      "INFO:TRAIN loss: 0.5785918782459446, acc: 70.57382960853049\n",
      "INFO:TRAIN loss: 0.5785918782459446, acc: 70.57382960853049\n",
      "24it [00:00, 146.94it/s]\n",
      "INFO:VAL loss: 0.6212575311462084, acc: 66.94258432539684\n",
      "INFO:VAL loss: 0.6212575311462084, acc: 66.94258432539684\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:01, 124.49it/s]\n",
      "INFO:TRAIN loss: 0.5784192434483513, acc: 70.6884038124452\n",
      "INFO:TRAIN loss: 0.5784192434483513, acc: 70.6884038124452\n",
      "24it [00:00, 138.16it/s]\n",
      "INFO:VAL loss: 0.6231200496355692, acc: 66.6465153769841\n",
      "INFO:VAL loss: 0.6231200496355692, acc: 66.6465153769841\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:01, 123.46it/s]\n",
      "INFO:TRAIN loss: 0.5778340763109592, acc: 70.77125328659072\n",
      "INFO:TRAIN loss: 0.5778340763109592, acc: 70.77125328659072\n",
      "24it [00:00, 132.63it/s]\n",
      "INFO:VAL loss: 0.6215911333759625, acc: 67.01078869047619\n",
      "INFO:VAL loss: 0.6215911333759625, acc: 67.01078869047619\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:01, 125.20it/s]\n",
      "INFO:TRAIN loss: 0.576398966868231, acc: 70.63659436167109\n",
      "INFO:TRAIN loss: 0.576398966868231, acc: 70.63659436167109\n",
      "24it [00:00, 107.18it/s]\n",
      "INFO:VAL loss: 0.6229607996841272, acc: 66.0373263888889\n",
      "INFO:VAL loss: 0.6229607996841272, acc: 66.0373263888889\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:01, 122.48it/s]\n",
      "INFO:TRAIN loss: 0.5775270741775721, acc: 70.51585780017531\n",
      "INFO:TRAIN loss: 0.5775270741775721, acc: 70.51585780017531\n",
      "24it [00:00, 138.83it/s]\n",
      "INFO:VAL loss: 0.6225921784838041, acc: 67.33630952380952\n",
      "INFO:VAL loss: 0.6225921784838041, acc: 67.33630952380952\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:01, 123.28it/s]\n",
      "INFO:TRAIN loss: 0.5765688697253268, acc: 70.79476153958517\n",
      "INFO:TRAIN loss: 0.5765688697253268, acc: 70.79476153958517\n",
      "24it [00:00, 134.66it/s]\n",
      "INFO:VAL loss: 0.6275148006776968, acc: 67.06969246031748\n",
      "INFO:VAL loss: 0.6275148006776968, acc: 67.06969246031748\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:01, 120.34it/s]\n",
      "INFO:TRAIN loss: 0.5791575104181018, acc: 70.55465782938941\n",
      "INFO:TRAIN loss: 0.5791575104181018, acc: 70.55465782938941\n",
      "24it [00:00, 124.85it/s]\n",
      "INFO:VAL loss: 0.6228750683367252, acc: 67.56417410714285\n",
      "INFO:VAL loss: 0.6228750683367252, acc: 67.56417410714285\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:01, 125.57it/s]\n",
      "INFO:TRAIN loss: 0.5783203878651367, acc: 70.29926234297402\n",
      "INFO:TRAIN loss: 0.5783203878651367, acc: 70.29926234297402\n",
      "24it [00:00, 136.35it/s]\n",
      "INFO:VAL loss: 0.6183155390123527, acc: 67.39831349206351\n",
      "INFO:VAL loss: 0.6183155390123527, acc: 67.39831349206351\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:01, 125.77it/s]\n",
      "INFO:TRAIN loss: 0.576884400442334, acc: 70.67836145194275\n",
      "INFO:TRAIN loss: 0.576884400442334, acc: 70.67836145194275\n",
      "24it [00:00, 138.40it/s]\n",
      "INFO:VAL loss: 0.6261529872814814, acc: 66.58141121031746\n",
      "INFO:VAL loss: 0.6261529872814814, acc: 66.58141121031746\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:01, 122.72it/s]\n",
      "INFO:TRAIN loss: 0.5773236089688867, acc: 70.54849547180832\n",
      "INFO:TRAIN loss: 0.5773236089688867, acc: 70.54849547180832\n",
      "24it [00:00, 139.43it/s]\n",
      "INFO:VAL loss: 0.6246172375977039, acc: 66.74107142857143\n",
      "INFO:VAL loss: 0.6246172375977039, acc: 66.74107142857143\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:01, 125.08it/s]\n",
      "INFO:TRAIN loss: 0.5769776385620328, acc: 70.43962715454283\n",
      "INFO:TRAIN loss: 0.5769776385620328, acc: 70.43962715454283\n",
      "24it [00:00, 134.28it/s]\n",
      "INFO:VAL loss: 0.6154723701377709, acc: 68.28342013888887\n",
      "INFO:VAL loss: 0.6154723701377709, acc: 68.28342013888887\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:01, 127.56it/s]\n",
      "INFO:TRAIN loss: 0.5774471450802743, acc: 70.59208844580776\n",
      "INFO:TRAIN loss: 0.5774471450802743, acc: 70.59208844580776\n",
      "24it [00:00, 136.04it/s]\n",
      "INFO:VAL loss: 0.6284741374353568, acc: 66.84182787698413\n",
      "INFO:VAL loss: 0.6284741374353568, acc: 66.84182787698413\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:01, 127.93it/s]\n",
      "INFO:TRAIN loss: 0.5761017581802206, acc: 70.70803206251831\n",
      "INFO:TRAIN loss: 0.5761017581802206, acc: 70.70803206251831\n",
      "24it [00:00, 145.58it/s]\n",
      "INFO:VAL loss: 0.6175943675140539, acc: 66.78292410714285\n",
      "INFO:VAL loss: 0.6175943675140539, acc: 66.78292410714285\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:01, 130.09it/s]\n",
      "INFO:TRAIN loss: 0.576231103550437, acc: 70.65964614373354\n",
      "INFO:TRAIN loss: 0.576231103550437, acc: 70.65964614373354\n",
      "24it [00:00, 141.89it/s]\n",
      "INFO:VAL loss: 0.6191923829416432, acc: 66.25899057539682\n",
      "INFO:VAL loss: 0.6191923829416432, acc: 66.25899057539682\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:01, 127.32it/s]\n",
      "INFO:TRAIN loss: 0.5751176865919965, acc: 71.02482288927835\n",
      "INFO:TRAIN loss: 0.5751176865919965, acc: 71.02482288927835\n",
      "24it [00:00, 143.07it/s]\n",
      "INFO:VAL loss: 0.629997839530309, acc: 67.98115079365078\n",
      "INFO:VAL loss: 0.629997839530309, acc: 67.98115079365078\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:01, 130.17it/s]\n",
      "INFO:TRAIN loss: 0.5759511560750155, acc: 70.81690037978377\n",
      "INFO:TRAIN loss: 0.5759511560750155, acc: 70.81690037978377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 141.77it/s]\n",
      "INFO:VAL loss: 0.6199142237504324, acc: 66.22333829365078\n",
      "INFO:VAL loss: 0.6199142237504324, acc: 66.22333829365078\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:01, 128.16it/s]\n",
      "INFO:TRAIN loss: 0.5759889031846097, acc: 70.88445807770964\n",
      "INFO:TRAIN loss: 0.5759889031846097, acc: 70.88445807770964\n",
      "24it [00:00, 133.78it/s]\n",
      "INFO:VAL loss: 0.6254738296071688, acc: 67.82149057539684\n",
      "INFO:VAL loss: 0.6254738296071688, acc: 67.82149057539684\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:01, 122.07it/s]\n",
      "INFO:TRAIN loss: 0.5762246029874297, acc: 70.8887945515629\n",
      "INFO:TRAIN loss: 0.5762246029874297, acc: 70.8887945515629\n",
      "24it [00:00, 121.43it/s]\n",
      "INFO:VAL loss: 0.62081420297424, acc: 67.10534474206351\n",
      "INFO:VAL loss: 0.62081420297424, acc: 67.10534474206351\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:01, 126.61it/s]\n",
      "INFO:TRAIN loss: 0.5768578511439948, acc: 70.73930032135557\n",
      "INFO:TRAIN loss: 0.5768578511439948, acc: 70.73930032135557\n",
      "24it [00:00, 134.77it/s]\n",
      "INFO:VAL loss: 0.6169458019236724, acc: 66.68216765873017\n",
      "INFO:VAL loss: 0.6169458019236724, acc: 66.68216765873017\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:01, 122.16it/s]\n",
      "INFO:TRAIN loss: 0.5750154106894884, acc: 70.68498028045573\n",
      "INFO:TRAIN loss: 0.5750154106894884, acc: 70.68498028045573\n",
      "24it [00:00, 135.40it/s]\n",
      "INFO:VAL loss: 0.619339036444823, acc: 67.56417410714288\n",
      "INFO:VAL loss: 0.619339036444823, acc: 67.56417410714288\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:01, 122.49it/s]\n",
      "INFO:TRAIN loss: 0.5754560850149285, acc: 70.9250839906515\n",
      "INFO:TRAIN loss: 0.5754560850149285, acc: 70.9250839906515\n",
      "24it [00:00, 132.91it/s]\n",
      "INFO:VAL loss: 0.6228661450246971, acc: 67.17664930555556\n",
      "INFO:VAL loss: 0.6228661450246971, acc: 67.17664930555556\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:01, 128.55it/s]\n",
      "INFO:TRAIN loss: 0.575084787204953, acc: 71.14419003797833\n",
      "INFO:TRAIN loss: 0.575084787204953, acc: 71.14419003797833\n",
      "24it [00:00, 143.08it/s]\n",
      "INFO:VAL loss: 0.6177352132896581, acc: 66.39539930555557\n",
      "INFO:VAL loss: 0.6177352132896581, acc: 66.39539930555557\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:01, 126.41it/s]\n",
      "INFO:TRAIN loss: 0.5750070930989979, acc: 70.65485319894832\n",
      "INFO:TRAIN loss: 0.5750070930989979, acc: 70.65485319894832\n",
      "24it [00:00, 136.59it/s]\n",
      "INFO:VAL loss: 0.6210140660405159, acc: 67.4959697420635\n",
      "INFO:VAL loss: 0.6210140660405159, acc: 67.4959697420635\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:01, 127.76it/s]\n",
      "INFO:TRAIN loss: 0.5757953102237607, acc: 70.57907902424775\n",
      "INFO:TRAIN loss: 0.5757953102237607, acc: 70.57907902424775\n",
      "24it [00:00, 135.92it/s]\n",
      "INFO:VAL loss: 0.625708586225907, acc: 66.39539930555554\n",
      "INFO:VAL loss: 0.625708586225907, acc: 66.39539930555554\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:01, 127.44it/s]\n",
      "INFO:TRAIN loss: 0.5734625769539109, acc: 70.74203914694715\n",
      "INFO:TRAIN loss: 0.5734625769539109, acc: 70.74203914694715\n",
      "24it [00:00, 139.01it/s]\n",
      "INFO:VAL loss: 0.6217037476599216, acc: 67.20610119047619\n",
      "INFO:VAL loss: 0.6217037476599216, acc: 67.20610119047619\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:01, 125.74it/s]\n",
      "INFO:TRAIN loss: 0.5752667252637128, acc: 70.85227687700849\n",
      "INFO:TRAIN loss: 0.5752667252637128, acc: 70.85227687700849\n",
      "24it [00:00, 144.86it/s]\n",
      "INFO:VAL loss: 0.6246724439164001, acc: 67.1999007936508\n",
      "INFO:VAL loss: 0.6246724439164001, acc: 67.1999007936508\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:01, 123.47it/s]\n",
      "INFO:TRAIN loss: 0.5742203810829327, acc: 70.89107690622257\n",
      "INFO:TRAIN loss: 0.5742203810829327, acc: 70.89107690622257\n",
      "24it [00:00, 137.71it/s]\n",
      "INFO:VAL loss: 0.6225653166572254, acc: 68.01680307539682\n",
      "INFO:VAL loss: 0.6225653166572254, acc: 68.01680307539682\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:01, 126.72it/s]\n",
      "INFO:TRAIN loss: 0.5749511373189329, acc: 70.84611451942739\n",
      "INFO:TRAIN loss: 0.5749511373189329, acc: 70.84611451942739\n",
      "24it [00:00, 140.54it/s]\n",
      "INFO:VAL loss: 0.6186163363357385, acc: 65.93346974206348\n",
      "INFO:VAL loss: 0.6186163363357385, acc: 65.93346974206348\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:01, 126.65it/s]\n",
      "INFO:TRAIN loss: 0.575765666786147, acc: 70.99035933391762\n",
      "INFO:TRAIN loss: 0.575765666786147, acc: 70.99035933391762\n",
      "24it [00:00, 137.21it/s]\n",
      "INFO:VAL loss: 0.6231101465721924, acc: 67.46651785714286\n",
      "INFO:VAL loss: 0.6231101465721924, acc: 67.46651785714286\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:01, 130.14it/s]\n",
      "INFO:TRAIN loss: 0.5733976830368389, acc: 71.07275233713116\n",
      "INFO:TRAIN loss: 0.5733976830368389, acc: 71.07275233713116\n",
      "24it [00:00, 137.65it/s]\n",
      "INFO:VAL loss: 0.6308559713264306, acc: 67.35956101190476\n",
      "INFO:VAL loss: 0.6308559713264306, acc: 67.35956101190476\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:01, 129.61it/s]\n",
      "INFO:TRAIN loss: 0.575497037611125, acc: 70.63956142272862\n",
      "INFO:TRAIN loss: 0.575497037611125, acc: 70.63956142272862\n",
      "24it [00:00, 143.09it/s]\n",
      "INFO:VAL loss: 0.6203072890639305, acc: 66.7178199404762\n",
      "INFO:VAL loss: 0.6203072890639305, acc: 66.7178199404762\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:01, 126.75it/s]\n",
      "INFO:TRAIN loss: 0.5735558713872005, acc: 71.16427475898334\n",
      "INFO:TRAIN loss: 0.5735558713872005, acc: 71.16427475898334\n",
      "24it [00:00, 142.40it/s]\n",
      "INFO:VAL loss: 0.627697424342235, acc: 67.29755704365081\n",
      "INFO:VAL loss: 0.627697424342235, acc: 67.29755704365081\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:01, 120.68it/s]\n",
      "INFO:TRAIN loss: 0.5757338580178336, acc: 70.524530747882\n",
      "INFO:TRAIN loss: 0.5757338580178336, acc: 70.524530747882\n",
      "24it [00:00, 133.12it/s]\n",
      "INFO:VAL loss: 0.6182346269488336, acc: 66.90693204365078\n",
      "INFO:VAL loss: 0.6182346269488336, acc: 66.90693204365078\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:01, 128.38it/s]\n",
      "INFO:TRAIN loss: 0.5747960061749069, acc: 70.6744814490213\n",
      "INFO:TRAIN loss: 0.5747960061749069, acc: 70.6744814490213\n",
      "24it [00:00, 139.32it/s]\n",
      "INFO:VAL loss: 0.6146895935138067, acc: 66.26519097222221\n",
      "INFO:VAL loss: 0.6146895935138067, acc: 66.26519097222221\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:01, 128.43it/s]\n",
      "INFO:TRAIN loss: 0.5760851985106441, acc: 70.51060838445805\n",
      "INFO:TRAIN loss: 0.5760851985106441, acc: 70.51060838445805\n",
      "24it [00:00, 139.09it/s]\n",
      "INFO:VAL loss: 0.6200107062856356, acc: 67.86334325396828\n",
      "INFO:VAL loss: 0.6200107062856356, acc: 67.86334325396828\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:01, 125.36it/s]\n",
      "INFO:TRAIN loss: 0.5771031970261064, acc: 70.58638255915866\n",
      "INFO:TRAIN loss: 0.5771031970261064, acc: 70.58638255915866\n",
      "24it [00:00, 139.46it/s]\n",
      "INFO:VAL loss: 0.6193777409692606, acc: 67.07589285714286\n",
      "INFO:VAL loss: 0.6193777409692606, acc: 67.07589285714286\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:01, 128.73it/s]\n",
      "INFO:TRAIN loss: 0.5750822302388269, acc: 70.9663946099912\n",
      "INFO:TRAIN loss: 0.5750822302388269, acc: 70.9663946099912\n",
      "24it [00:00, 142.10it/s]\n",
      "INFO:VAL loss: 0.6263780742883681, acc: 66.13188244047619\n",
      "INFO:VAL loss: 0.6263780742883681, acc: 66.13188244047619\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:01, 128.28it/s]\n",
      "INFO:TRAIN loss: 0.5745479782666166, acc: 70.79339212678939\n",
      "INFO:TRAIN loss: 0.5745479782666166, acc: 70.79339212678939\n",
      "24it [00:00, 118.39it/s]\n",
      "INFO:VAL loss: 0.6188814230263234, acc: 67.17974950396827\n",
      "INFO:VAL loss: 0.6188814230263234, acc: 67.17974950396827\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:01, 124.42it/s]\n",
      "INFO:TRAIN loss: 0.5756421723614439, acc: 70.69319675723051\n",
      "INFO:TRAIN loss: 0.5756421723614439, acc: 70.69319675723051\n",
      "24it [00:00, 147.50it/s]\n",
      "INFO:VAL loss: 0.6250960528850554, acc: 67.52852182539684\n",
      "INFO:VAL loss: 0.6250960528850554, acc: 67.52852182539684\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:01, 129.47it/s]\n",
      "INFO:TRAIN loss: 0.5766101514269237, acc: 70.65873320186974\n",
      "INFO:TRAIN loss: 0.5766101514269237, acc: 70.65873320186974\n",
      "24it [00:00, 144.26it/s]\n",
      "INFO:VAL loss: 0.6173520634571712, acc: 67.63237847222223\n",
      "INFO:VAL loss: 0.6173520634571712, acc: 67.63237847222223\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:01, 133.54it/s]\n",
      "INFO:TRAIN loss: 0.5758192839066674, acc: 70.86916630148995\n",
      "INFO:TRAIN loss: 0.5758192839066674, acc: 70.86916630148995\n",
      "24it [00:00, 145.38it/s]\n",
      "INFO:VAL loss: 0.6213425969084104, acc: 67.24175347222221\n",
      "INFO:VAL loss: 0.6213425969084104, acc: 67.24175347222221\n",
      "INFO:TRAIN: 49|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN: 49|50\n",
      "163it [00:01, 133.89it/s]\n",
      "INFO:TRAIN loss: 0.5781202738636112, acc: 70.48139424481442\n",
      "INFO:TRAIN loss: 0.5781202738636112, acc: 70.48139424481442\n",
      "24it [00:00, 145.53it/s]\n",
      "INFO:VAL loss: 0.6242530134816966, acc: 66.47290426587303\n",
      "INFO:VAL loss: 0.6242530134816966, acc: 66.47290426587303\n",
      "47it [00:00, 141.00it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.626245695225736, acc: 66.31709381044489\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.626245695225736, acc: 66.31709381044489\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.6306189666130788, 0.5905799542102345, 0.5832693777932713, 0.5824432356591606, 0.5816825114510541, 0.579704042592663, 0.5794536118492754, 0.5800317108996805, 0.5785918782459446, 0.5784192434483513, 0.5778340763109592, 0.576398966868231, 0.5775270741775721, 0.5765688697253268, 0.5791575104181018, 0.5783203878651367, 0.576884400442334, 0.5773236089688867, 0.5769776385620328, 0.5774471450802743, 0.5761017581802206, 0.576231103550437, 0.5751176865919965, 0.5759511560750155, 0.5759889031846097, 0.5762246029874297, 0.5768578511439948, 0.5750154106894884, 0.5754560850149285, 0.575084787204953, 0.5750070930989979, 0.5757953102237607, 0.5734625769539109, 0.5752667252637128, 0.5742203810829327, 0.5749511373189329, 0.575765666786147, 0.5733976830368389, 0.575497037611125, 0.5735558713872005, 0.5757338580178336, 0.5747960061749069, 0.5760851985106441, 0.5771031970261064, 0.5750822302388269, 0.5745479782666166, 0.5756421723614439, 0.5766101514269237, 0.5758192839066674, 0.5781202738636112], 'train_acc': [66.67282902424772, 69.60382887817704, 70.04660568215012, 70.26137525562375, 70.51060838445804, 70.65097319602685, 70.50490249780896, 70.46701541045867, 70.57382960853049, 70.6884038124452, 70.77125328659072, 70.63659436167109, 70.51585780017531, 70.79476153958517, 70.55465782938941, 70.29926234297402, 70.67836145194275, 70.54849547180832, 70.43962715454283, 70.59208844580776, 70.70803206251831, 70.65964614373354, 71.02482288927835, 70.81690037978377, 70.88445807770964, 70.8887945515629, 70.73930032135557, 70.68498028045573, 70.9250839906515, 71.14419003797833, 70.65485319894832, 70.57907902424775, 70.74203914694715, 70.85227687700849, 70.89107690622257, 70.84611451942739, 70.99035933391762, 71.07275233713116, 70.63956142272862, 71.16427475898334, 70.524530747882, 70.6744814490213, 70.51060838445805, 70.58638255915866, 70.9663946099912, 70.79339212678939, 70.69319675723051, 70.65873320186974, 70.86916630148995, 70.48139424481442], 'val_loss': [0.6190424188971521, 0.6230197437107563, 0.6197305619716644, 0.6226911110182604, 0.6246705452601116, 0.6292249336838721, 0.6233949561913809, 0.6187168980638187, 0.6212575311462084, 0.6231200496355692, 0.6215911333759625, 0.6229607996841272, 0.6225921784838041, 0.6275148006776968, 0.6228750683367252, 0.6183155390123527, 0.6261529872814814, 0.6246172375977039, 0.6154723701377709, 0.6284741374353568, 0.6175943675140539, 0.6191923829416432, 0.629997839530309, 0.6199142237504324, 0.6254738296071688, 0.62081420297424, 0.6169458019236724, 0.619339036444823, 0.6228661450246971, 0.6177352132896581, 0.6210140660405159, 0.625708586225907, 0.6217037476599216, 0.6246724439164001, 0.6225653166572254, 0.6186163363357385, 0.6231101465721924, 0.6308559713264306, 0.6203072890639305, 0.627697424342235, 0.6182346269488336, 0.6146895935138067, 0.6200107062856356, 0.6193777409692606, 0.6263780742883681, 0.6188814230263234, 0.6250960528850554, 0.6173520634571712, 0.6213425969084104, 0.6242530134816966], 'val_acc': [65.96602182539684, 65.83581349206351, 67.68818204365081, 67.65562996031747, 65.58469742063492, 67.19680059523809, 66.79222470238095, 66.49615575396824, 66.94258432539684, 66.6465153769841, 67.01078869047619, 66.0373263888889, 67.33630952380952, 67.06969246031748, 67.56417410714285, 67.39831349206351, 66.58141121031746, 66.74107142857143, 68.28342013888887, 66.84182787698413, 66.78292410714285, 66.25899057539682, 67.98115079365078, 66.22333829365078, 67.82149057539684, 67.10534474206351, 66.68216765873017, 67.56417410714288, 67.17664930555556, 66.39539930555557, 67.4959697420635, 66.39539930555554, 67.20610119047619, 67.1999007936508, 68.01680307539682, 65.93346974206348, 67.46651785714286, 67.35956101190476, 66.7178199404762, 67.29755704365081, 66.90693204365078, 66.26519097222221, 67.86334325396828, 67.07589285714286, 66.13188244047619, 67.17974950396827, 67.52852182539684, 67.63237847222223, 67.24175347222221, 66.47290426587303], 'test_loss': 0.626245695225736, 'test_acc': 66.31709381044489}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.6306189666130788, 0.5905799542102345, 0.5832693777932713, 0.5824432356591606, 0.5816825114510541, 0.579704042592663, 0.5794536118492754, 0.5800317108996805, 0.5785918782459446, 0.5784192434483513, 0.5778340763109592, 0.576398966868231, 0.5775270741775721, 0.5765688697253268, 0.5791575104181018, 0.5783203878651367, 0.576884400442334, 0.5773236089688867, 0.5769776385620328, 0.5774471450802743, 0.5761017581802206, 0.576231103550437, 0.5751176865919965, 0.5759511560750155, 0.5759889031846097, 0.5762246029874297, 0.5768578511439948, 0.5750154106894884, 0.5754560850149285, 0.575084787204953, 0.5750070930989979, 0.5757953102237607, 0.5734625769539109, 0.5752667252637128, 0.5742203810829327, 0.5749511373189329, 0.575765666786147, 0.5733976830368389, 0.575497037611125, 0.5735558713872005, 0.5757338580178336, 0.5747960061749069, 0.5760851985106441, 0.5771031970261064, 0.5750822302388269, 0.5745479782666166, 0.5756421723614439, 0.5766101514269237, 0.5758192839066674, 0.5781202738636112], 'train_acc': [66.67282902424772, 69.60382887817704, 70.04660568215012, 70.26137525562375, 70.51060838445804, 70.65097319602685, 70.50490249780896, 70.46701541045867, 70.57382960853049, 70.6884038124452, 70.77125328659072, 70.63659436167109, 70.51585780017531, 70.79476153958517, 70.55465782938941, 70.29926234297402, 70.67836145194275, 70.54849547180832, 70.43962715454283, 70.59208844580776, 70.70803206251831, 70.65964614373354, 71.02482288927835, 70.81690037978377, 70.88445807770964, 70.8887945515629, 70.73930032135557, 70.68498028045573, 70.9250839906515, 71.14419003797833, 70.65485319894832, 70.57907902424775, 70.74203914694715, 70.85227687700849, 70.89107690622257, 70.84611451942739, 70.99035933391762, 71.07275233713116, 70.63956142272862, 71.16427475898334, 70.524530747882, 70.6744814490213, 70.51060838445805, 70.58638255915866, 70.9663946099912, 70.79339212678939, 70.69319675723051, 70.65873320186974, 70.86916630148995, 70.48139424481442], 'val_loss': [0.6190424188971521, 0.6230197437107563, 0.6197305619716644, 0.6226911110182604, 0.6246705452601116, 0.6292249336838721, 0.6233949561913809, 0.6187168980638187, 0.6212575311462084, 0.6231200496355692, 0.6215911333759625, 0.6229607996841272, 0.6225921784838041, 0.6275148006776968, 0.6228750683367252, 0.6183155390123527, 0.6261529872814814, 0.6246172375977039, 0.6154723701377709, 0.6284741374353568, 0.6175943675140539, 0.6191923829416432, 0.629997839530309, 0.6199142237504324, 0.6254738296071688, 0.62081420297424, 0.6169458019236724, 0.619339036444823, 0.6228661450246971, 0.6177352132896581, 0.6210140660405159, 0.625708586225907, 0.6217037476599216, 0.6246724439164001, 0.6225653166572254, 0.6186163363357385, 0.6231101465721924, 0.6308559713264306, 0.6203072890639305, 0.627697424342235, 0.6182346269488336, 0.6146895935138067, 0.6200107062856356, 0.6193777409692606, 0.6263780742883681, 0.6188814230263234, 0.6250960528850554, 0.6173520634571712, 0.6213425969084104, 0.6242530134816966], 'val_acc': [65.96602182539684, 65.83581349206351, 67.68818204365081, 67.65562996031747, 65.58469742063492, 67.19680059523809, 66.79222470238095, 66.49615575396824, 66.94258432539684, 66.6465153769841, 67.01078869047619, 66.0373263888889, 67.33630952380952, 67.06969246031748, 67.56417410714285, 67.39831349206351, 66.58141121031746, 66.74107142857143, 68.28342013888887, 66.84182787698413, 66.78292410714285, 66.25899057539682, 67.98115079365078, 66.22333829365078, 67.82149057539684, 67.10534474206351, 66.68216765873017, 67.56417410714288, 67.17664930555556, 66.39539930555557, 67.4959697420635, 66.39539930555554, 67.20610119047619, 67.1999007936508, 68.01680307539682, 65.93346974206348, 67.46651785714286, 67.35956101190476, 66.7178199404762, 67.29755704365081, 66.90693204365078, 66.26519097222221, 67.86334325396828, 67.07589285714286, 66.13188244047619, 67.17974950396827, 67.52852182539684, 67.63237847222223, 67.24175347222221, 66.47290426587303], 'test_loss': 0.626245695225736, 'test_acc': 66.31709381044489}\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "args.model_id=2\n",
    "train_dataloader = DataLoader(jobtype_myembedding_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_myembedding_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_myembedding_test, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_FeedForward(num_features=10*100) \n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "args.logger.handlers.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1583c5",
   "metadata": {},
   "source": [
    "**`acc:66.31`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad42fc",
   "metadata": {},
   "source": [
    "In both mybedding and pretain embedding the accuracy of the model is only 66.This is because the forward propagation model is a single-layer network with weak learning ability, which is not sufficient to learn the semantics in embedding.\n",
    "If we look at the code in model.py, we can see that the 2D embedding is pulled into 1D (view(, -1)) in feed_forward, which breaks the structure of the embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8428239",
   "metadata": {},
   "source": [
    "**`model 3: text--10word, embedding--pretain embedding, model--feed_forward`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd25bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=3, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=3, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=3, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:01, 141.34it/s]\n",
      "INFO:TRAIN loss: 0.6318961484300579, acc: 66.11456507449607\n",
      "INFO:TRAIN loss: 0.6318961484300579, acc: 66.11456507449607\n",
      "INFO:TRAIN loss: 0.6318961484300579, acc: 66.11456507449607\n",
      "24it [00:00, 140.62it/s]\n",
      "INFO:VAL loss: 0.6329316347837448, acc: 65.29947916666667\n",
      "INFO:VAL loss: 0.6329316347837448, acc: 65.29947916666667\n",
      "INFO:VAL loss: 0.6329316347837448, acc: 65.29947916666667\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:01, 144.24it/s]\n",
      "INFO:TRAIN loss: 0.6042374752781869, acc: 68.38299737072738\n",
      "INFO:TRAIN loss: 0.6042374752781869, acc: 68.38299737072738\n",
      "INFO:TRAIN loss: 0.6042374752781869, acc: 68.38299737072738\n",
      "24it [00:00, 156.68it/s]\n",
      "INFO:VAL loss: 0.6317886995772521, acc: 65.69320436507937\n",
      "INFO:VAL loss: 0.6317886995772521, acc: 65.69320436507937\n",
      "INFO:VAL loss: 0.6317886995772521, acc: 65.69320436507937\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:01, 145.24it/s]\n",
      "INFO:TRAIN loss: 0.5958551647472968, acc: 68.92802366345309\n",
      "INFO:TRAIN loss: 0.5958551647472968, acc: 68.92802366345309\n",
      "INFO:TRAIN loss: 0.5958551647472968, acc: 68.92802366345309\n",
      "24it [00:00, 153.91it/s]\n",
      "INFO:VAL loss: 0.6346244377394517, acc: 65.27002728174602\n",
      "INFO:VAL loss: 0.6346244377394517, acc: 65.27002728174602\n",
      "INFO:VAL loss: 0.6346244377394517, acc: 65.27002728174602\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:01, 142.36it/s]\n",
      "INFO:TRAIN loss: 0.590458359820711, acc: 69.27973451650602\n",
      "INFO:TRAIN loss: 0.590458359820711, acc: 69.27973451650602\n",
      "INFO:TRAIN loss: 0.590458359820711, acc: 69.27973451650602\n",
      "24it [00:00, 149.64it/s]\n",
      "INFO:VAL loss: 0.6290393931170305, acc: 65.92106894841271\n",
      "INFO:VAL loss: 0.6290393931170305, acc: 65.92106894841271\n",
      "INFO:VAL loss: 0.6290393931170305, acc: 65.92106894841271\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:01, 137.81it/s]\n",
      "INFO:TRAIN loss: 0.590175021279809, acc: 69.50135115395854\n",
      "INFO:TRAIN loss: 0.590175021279809, acc: 69.50135115395854\n",
      "INFO:TRAIN loss: 0.590175021279809, acc: 69.50135115395854\n",
      "24it [00:00, 158.92it/s]\n",
      "INFO:VAL loss: 0.6350352416435878, acc: 65.66065228174604\n",
      "INFO:VAL loss: 0.6350352416435878, acc: 65.66065228174604\n",
      "INFO:VAL loss: 0.6350352416435878, acc: 65.66065228174604\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:01, 131.86it/s]\n",
      "INFO:TRAIN loss: 0.5865117307820932, acc: 69.67617952088813\n",
      "INFO:TRAIN loss: 0.5865117307820932, acc: 69.67617952088813\n",
      "INFO:TRAIN loss: 0.5865117307820932, acc: 69.67617952088813\n",
      "24it [00:00, 136.57it/s]\n",
      "INFO:VAL loss: 0.6342972069978714, acc: 65.75830853174604\n",
      "INFO:VAL loss: 0.6342972069978714, acc: 65.75830853174604\n",
      "INFO:VAL loss: 0.6342972069978714, acc: 65.75830853174604\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:01, 137.71it/s]\n",
      "INFO:TRAIN loss: 0.5851879054051968, acc: 70.1559304703477\n",
      "INFO:TRAIN loss: 0.5851879054051968, acc: 70.1559304703477\n",
      "INFO:TRAIN loss: 0.5851879054051968, acc: 70.1559304703477\n",
      "24it [00:00, 154.96it/s]\n",
      "INFO:VAL loss: 0.6342929763098558, acc: 65.69320436507935\n",
      "INFO:VAL loss: 0.6342929763098558, acc: 65.69320436507935\n",
      "INFO:VAL loss: 0.6342929763098558, acc: 65.69320436507935\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:01, 137.58it/s]\n",
      "INFO:TRAIN loss: 0.5838019114696175, acc: 70.22485758106926\n",
      "INFO:TRAIN loss: 0.5838019114696175, acc: 70.22485758106926\n",
      "INFO:TRAIN loss: 0.5838019114696175, acc: 70.22485758106926\n",
      "24it [00:00, 151.14it/s]\n",
      "INFO:VAL loss: 0.6403080510596434, acc: 65.62810019841271\n",
      "INFO:VAL loss: 0.6403080510596434, acc: 65.62810019841271\n",
      "INFO:VAL loss: 0.6403080510596434, acc: 65.62810019841271\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:01, 134.00it/s]\n",
      "INFO:TRAIN loss: 0.5839429697010412, acc: 70.09316571720714\n",
      "INFO:TRAIN loss: 0.5839429697010412, acc: 70.09316571720714\n",
      "INFO:TRAIN loss: 0.5839429697010412, acc: 70.09316571720714\n",
      "24it [00:00, 147.56it/s]\n",
      "INFO:VAL loss: 0.6407949353257815, acc: 65.4358878968254\n",
      "INFO:VAL loss: 0.6407949353257815, acc: 65.4358878968254\n",
      "INFO:VAL loss: 0.6407949353257815, acc: 65.4358878968254\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:01, 136.43it/s]\n",
      "INFO:TRAIN loss: 0.5821595771546746, acc: 70.16300576979262\n",
      "INFO:TRAIN loss: 0.5821595771546746, acc: 70.16300576979262\n",
      "INFO:TRAIN loss: 0.5821595771546746, acc: 70.16300576979262\n",
      "24it [00:00, 150.75it/s]\n",
      "INFO:VAL loss: 0.6405622772872448, acc: 66.1194816468254\n",
      "INFO:VAL loss: 0.6405622772872448, acc: 66.1194816468254\n",
      "INFO:VAL loss: 0.6405622772872448, acc: 66.1194816468254\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:01, 135.49it/s]\n",
      "INFO:TRAIN loss: 0.5814941059226637, acc: 70.26320113935152\n",
      "INFO:TRAIN loss: 0.5814941059226637, acc: 70.26320113935152\n",
      "INFO:TRAIN loss: 0.5814941059226637, acc: 70.26320113935152\n",
      "24it [00:00, 145.84it/s]\n",
      "INFO:VAL loss: 0.6379954367876053, acc: 65.79396081349208\n",
      "INFO:VAL loss: 0.6379954367876053, acc: 65.79396081349208\n",
      "INFO:VAL loss: 0.6379954367876053, acc: 65.79396081349208\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:01, 137.17it/s]\n",
      "INFO:TRAIN loss: 0.5821890373902817, acc: 70.21915169442009\n",
      "INFO:TRAIN loss: 0.5821890373902817, acc: 70.21915169442009\n",
      "INFO:TRAIN loss: 0.5821890373902817, acc: 70.21915169442009\n",
      "24it [00:00, 155.42it/s]\n",
      "INFO:VAL loss: 0.6405733488500119, acc: 65.5335441468254\n",
      "INFO:VAL loss: 0.6405733488500119, acc: 65.5335441468254\n",
      "INFO:VAL loss: 0.6405733488500119, acc: 65.5335441468254\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:01, 137.87it/s]\n",
      "INFO:TRAIN loss: 0.5816726845466289, acc: 70.25178936605317\n",
      "INFO:TRAIN loss: 0.5816726845466289, acc: 70.25178936605317\n",
      "INFO:TRAIN loss: 0.5816726845466289, acc: 70.25178936605317\n",
      "24it [00:00, 147.55it/s]\n",
      "INFO:VAL loss: 0.6417583748698235, acc: 65.92416914682539\n",
      "INFO:VAL loss: 0.6417583748698235, acc: 65.92416914682539\n",
      "INFO:VAL loss: 0.6417583748698235, acc: 65.92416914682539\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:01, 138.64it/s]\n",
      "INFO:TRAIN loss: 0.5814784194794167, acc: 70.33509531113057\n",
      "INFO:TRAIN loss: 0.5814784194794167, acc: 70.33509531113057\n",
      "INFO:TRAIN loss: 0.5814784194794167, acc: 70.33509531113057\n",
      "24it [00:00, 154.10it/s]\n",
      "INFO:VAL loss: 0.6446929996212322, acc: 65.66065228174604\n",
      "INFO:VAL loss: 0.6446929996212322, acc: 65.66065228174604\n",
      "INFO:VAL loss: 0.6446929996212322, acc: 65.66065228174604\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:01, 134.31it/s]\n",
      "INFO:TRAIN loss: 0.5820860520827991, acc: 70.19427402862992\n",
      "INFO:TRAIN loss: 0.5820860520827991, acc: 70.19427402862992\n",
      "INFO:TRAIN loss: 0.5820860520827991, acc: 70.19427402862992\n",
      "24it [00:00, 148.01it/s]\n",
      "INFO:VAL loss: 0.6417805130283039, acc: 65.63430059523809\n",
      "INFO:VAL loss: 0.6417805130283039, acc: 65.63430059523809\n",
      "INFO:VAL loss: 0.6417805130283039, acc: 65.63430059523809\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:01, 142.75it/s]\n",
      "INFO:TRAIN loss: 0.5818619534281865, acc: 70.2958388109845\n",
      "INFO:TRAIN loss: 0.5818619534281865, acc: 70.2958388109845\n",
      "INFO:TRAIN loss: 0.5818619534281865, acc: 70.2958388109845\n",
      "24it [00:00, 154.47it/s]\n",
      "INFO:VAL loss: 0.6420308786133926, acc: 65.4327876984127\n",
      "INFO:VAL loss: 0.6420308786133926, acc: 65.4327876984127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:VAL loss: 0.6420308786133926, acc: 65.4327876984127\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:01, 137.98it/s]\n",
      "INFO:TRAIN loss: 0.5815382526696098, acc: 70.15547399941575\n",
      "INFO:TRAIN loss: 0.5815382526696098, acc: 70.15547399941575\n",
      "INFO:TRAIN loss: 0.5815382526696098, acc: 70.15547399941575\n",
      "24it [00:00, 156.27it/s]\n",
      "INFO:VAL loss: 0.643623256434997, acc: 66.15203373015873\n",
      "INFO:VAL loss: 0.643623256434997, acc: 66.15203373015873\n",
      "INFO:VAL loss: 0.643623256434997, acc: 66.15203373015873\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:01, 139.78it/s]\n",
      "INFO:TRAIN loss: 0.5808183382625227, acc: 70.19473049956173\n",
      "INFO:TRAIN loss: 0.5808183382625227, acc: 70.19473049956173\n",
      "INFO:TRAIN loss: 0.5808183382625227, acc: 70.19473049956173\n",
      "24it [00:00, 158.02it/s]\n",
      "INFO:VAL loss: 0.6440234829982123, acc: 65.66685267857142\n",
      "INFO:VAL loss: 0.6440234829982123, acc: 65.66685267857142\n",
      "INFO:VAL loss: 0.6440234829982123, acc: 65.66685267857142\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:01, 137.00it/s]\n",
      "INFO:TRAIN loss: 0.5809474333297989, acc: 70.19381755769794\n",
      "INFO:TRAIN loss: 0.5809474333297989, acc: 70.19381755769794\n",
      "INFO:TRAIN loss: 0.5809474333297989, acc: 70.19381755769794\n",
      "24it [00:00, 148.39it/s]\n",
      "INFO:VAL loss: 0.6437774685521922, acc: 65.01271081349205\n",
      "INFO:VAL loss: 0.6437774685521922, acc: 65.01271081349205\n",
      "INFO:VAL loss: 0.6437774685521922, acc: 65.01271081349205\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:01, 137.51it/s]\n",
      "INFO:TRAIN loss: 0.5803936778402039, acc: 70.45971187554778\n",
      "INFO:TRAIN loss: 0.5803936778402039, acc: 70.45971187554778\n",
      "INFO:TRAIN loss: 0.5803936778402039, acc: 70.45971187554778\n",
      "24it [00:00, 153.57it/s]\n",
      "INFO:VAL loss: 0.649130215247472, acc: 65.43278769841271\n",
      "INFO:VAL loss: 0.649130215247472, acc: 65.43278769841271\n",
      "INFO:VAL loss: 0.649130215247472, acc: 65.43278769841271\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:01, 138.68it/s]\n",
      "INFO:TRAIN loss: 0.5812722598116823, acc: 70.0557351007888\n",
      "INFO:TRAIN loss: 0.5812722598116823, acc: 70.0557351007888\n",
      "INFO:TRAIN loss: 0.5812722598116823, acc: 70.0557351007888\n",
      "24it [00:00, 155.00it/s]\n",
      "INFO:VAL loss: 0.645144817729791, acc: 65.46843998015873\n",
      "INFO:VAL loss: 0.645144817729791, acc: 65.46843998015873\n",
      "INFO:VAL loss: 0.645144817729791, acc: 65.46843998015873\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:01, 140.78it/s]\n",
      "INFO:TRAIN loss: 0.5811237808019836, acc: 70.05048568507156\n",
      "INFO:TRAIN loss: 0.5811237808019836, acc: 70.05048568507156\n",
      "INFO:TRAIN loss: 0.5811237808019836, acc: 70.05048568507156\n",
      "24it [00:00, 150.73it/s]\n",
      "INFO:VAL loss: 0.6429272716244062, acc: 65.1072668650794\n",
      "INFO:VAL loss: 0.6429272716244062, acc: 65.1072668650794\n",
      "INFO:VAL loss: 0.6429272716244062, acc: 65.1072668650794\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:01, 140.48it/s]\n",
      "INFO:TRAIN loss: 0.5811676735892619, acc: 70.40037065439677\n",
      "INFO:TRAIN loss: 0.5811676735892619, acc: 70.40037065439677\n",
      "INFO:TRAIN loss: 0.5811676735892619, acc: 70.40037065439677\n",
      "24it [00:00, 153.19it/s]\n",
      "INFO:VAL loss: 0.6435846723616123, acc: 64.98015873015875\n",
      "INFO:VAL loss: 0.6435846723616123, acc: 64.98015873015875\n",
      "INFO:VAL loss: 0.6435846723616123, acc: 64.98015873015875\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:01, 142.33it/s]\n",
      "INFO:TRAIN loss: 0.5800587569643377, acc: 70.38302475898338\n",
      "INFO:TRAIN loss: 0.5800587569643377, acc: 70.38302475898338\n",
      "INFO:TRAIN loss: 0.5800587569643377, acc: 70.38302475898338\n",
      "24it [00:00, 151.25it/s]\n",
      "INFO:VAL loss: 0.6453766524791719, acc: 65.04526289682539\n",
      "INFO:VAL loss: 0.6453766524791719, acc: 65.04526289682539\n",
      "INFO:VAL loss: 0.6453766524791719, acc: 65.04526289682539\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:01, 143.11it/s]\n",
      "INFO:TRAIN loss: 0.5807661531161677, acc: 70.31546706105752\n",
      "INFO:TRAIN loss: 0.5807661531161677, acc: 70.31546706105752\n",
      "INFO:TRAIN loss: 0.5807661531161677, acc: 70.31546706105752\n",
      "24it [00:00, 153.52it/s]\n",
      "INFO:VAL loss: 0.6447876455883186, acc: 65.60174851190474\n",
      "INFO:VAL loss: 0.6447876455883186, acc: 65.60174851190474\n",
      "INFO:VAL loss: 0.6447876455883186, acc: 65.60174851190474\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:01, 143.71it/s]\n",
      "INFO:TRAIN loss: 0.580786198926118, acc: 70.36727651183173\n",
      "INFO:TRAIN loss: 0.580786198926118, acc: 70.36727651183173\n",
      "INFO:TRAIN loss: 0.580786198926118, acc: 70.36727651183173\n",
      "24it [00:00, 155.59it/s]\n",
      "INFO:VAL loss: 0.6398186994095643, acc: 65.4420882936508\n",
      "INFO:VAL loss: 0.6398186994095643, acc: 65.4420882936508\n",
      "INFO:VAL loss: 0.6398186994095643, acc: 65.4420882936508\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:01, 142.93it/s]\n",
      "INFO:TRAIN loss: 0.5807099528839256, acc: 70.20956580484957\n",
      "INFO:TRAIN loss: 0.5807099528839256, acc: 70.20956580484957\n",
      "INFO:TRAIN loss: 0.5807099528839256, acc: 70.20956580484957\n",
      "24it [00:00, 154.10it/s]\n",
      "INFO:VAL loss: 0.644272598127524, acc: 65.43588789682539\n",
      "INFO:VAL loss: 0.644272598127524, acc: 65.43588789682539\n",
      "INFO:VAL loss: 0.644272598127524, acc: 65.43588789682539\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:01, 133.05it/s]\n",
      "INFO:TRAIN loss: 0.5810507631009347, acc: 70.14155163599185\n",
      "INFO:TRAIN loss: 0.5810507631009347, acc: 70.14155163599185\n",
      "INFO:TRAIN loss: 0.5810507631009347, acc: 70.14155163599185\n",
      "24it [00:00, 153.17it/s]\n",
      "INFO:VAL loss: 0.6458690129220487, acc: 65.10726686507935\n",
      "INFO:VAL loss: 0.6458690129220487, acc: 65.10726686507935\n",
      "INFO:VAL loss: 0.6458690129220487, acc: 65.10726686507935\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:01, 141.96it/s]\n",
      "INFO:TRAIN loss: 0.5802155848295409, acc: 70.18560108092319\n",
      "INFO:TRAIN loss: 0.5802155848295409, acc: 70.18560108092319\n",
      "INFO:TRAIN loss: 0.5802155848295409, acc: 70.18560108092319\n",
      "24it [00:00, 132.39it/s]\n",
      "INFO:VAL loss: 0.6511546236773332, acc: 65.66065228174604\n",
      "INFO:VAL loss: 0.6511546236773332, acc: 65.66065228174604\n",
      "INFO:VAL loss: 0.6511546236773332, acc: 65.66065228174604\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:01, 140.61it/s]\n",
      "INFO:TRAIN loss: 0.5804068067688151, acc: 70.51585780017527\n",
      "INFO:TRAIN loss: 0.5804068067688151, acc: 70.51585780017527\n",
      "INFO:TRAIN loss: 0.5804068067688151, acc: 70.51585780017527\n",
      "24it [00:00, 154.70it/s]\n",
      "INFO:VAL loss: 0.6459353441993396, acc: 65.07471478174602\n",
      "INFO:VAL loss: 0.6459353441993396, acc: 65.07471478174602\n",
      "INFO:VAL loss: 0.6459353441993396, acc: 65.07471478174602\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:01, 142.62it/s]\n",
      "INFO:TRAIN loss: 0.581621293641307, acc: 70.179895194274\n",
      "INFO:TRAIN loss: 0.581621293641307, acc: 70.179895194274\n",
      "INFO:TRAIN loss: 0.581621293641307, acc: 70.179895194274\n",
      "24it [00:00, 154.62it/s]\n",
      "INFO:VAL loss: 0.6475948716203371, acc: 65.30567956349208\n",
      "INFO:VAL loss: 0.6475948716203371, acc: 65.30567956349208\n",
      "INFO:VAL loss: 0.6475948716203371, acc: 65.30567956349208\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:01, 143.22it/s]\n",
      "INFO:TRAIN loss: 0.580942138206739, acc: 70.3964906514753\n",
      "INFO:TRAIN loss: 0.580942138206739, acc: 70.3964906514753\n",
      "INFO:TRAIN loss: 0.580942138206739, acc: 70.3964906514753\n",
      "24it [00:00, 154.82it/s]\n",
      "INFO:VAL loss: 0.6463040076196193, acc: 64.81429811507937\n",
      "INFO:VAL loss: 0.6463040076196193, acc: 64.81429811507937\n",
      "INFO:VAL loss: 0.6463040076196193, acc: 64.81429811507937\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:01, 142.36it/s]\n",
      "INFO:TRAIN loss: 0.5813492083110693, acc: 70.3093047034765\n",
      "INFO:TRAIN loss: 0.5813492083110693, acc: 70.3093047034765\n",
      "INFO:TRAIN loss: 0.5813492083110693, acc: 70.3093047034765\n",
      "24it [00:00, 154.85it/s]\n",
      "INFO:VAL loss: 0.6457157085339228, acc: 65.04216269841271\n",
      "INFO:VAL loss: 0.6457157085339228, acc: 65.04216269841271\n",
      "INFO:VAL loss: 0.6457157085339228, acc: 65.04216269841271\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:01, 143.36it/s]\n",
      "INFO:TRAIN loss: 0.5813207549551513, acc: 70.12283632778261\n",
      "INFO:TRAIN loss: 0.5813207549551513, acc: 70.12283632778261\n",
      "INFO:TRAIN loss: 0.5813207549551513, acc: 70.12283632778261\n",
      "24it [00:00, 151.89it/s]\n",
      "INFO:VAL loss: 0.6453359338144462, acc: 64.74919394841268\n",
      "INFO:VAL loss: 0.6453359338144462, acc: 64.74919394841268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:VAL loss: 0.6453359338144462, acc: 64.74919394841268\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:01, 146.07it/s]\n",
      "INFO:TRAIN loss: 0.5809043572724231, acc: 70.35198473561205\n",
      "INFO:TRAIN loss: 0.5809043572724231, acc: 70.35198473561205\n",
      "INFO:TRAIN loss: 0.5809043572724231, acc: 70.35198473561205\n",
      "24it [00:00, 159.00it/s]\n",
      "INFO:VAL loss: 0.6488670222461225, acc: 64.78174603174601\n",
      "INFO:VAL loss: 0.6488670222461225, acc: 64.78174603174601\n",
      "INFO:VAL loss: 0.6488670222461225, acc: 64.78174603174601\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:01, 146.09it/s]\n",
      "INFO:TRAIN loss: 0.5806276077873135, acc: 70.15456105755183\n",
      "INFO:TRAIN loss: 0.5806276077873135, acc: 70.15456105755183\n",
      "INFO:TRAIN loss: 0.5806276077873135, acc: 70.15456105755183\n",
      "24it [00:00, 158.52it/s]\n",
      "INFO:VAL loss: 0.6501005490620931, acc: 65.56299603174604\n",
      "INFO:VAL loss: 0.6501005490620931, acc: 65.56299603174604\n",
      "INFO:VAL loss: 0.6501005490620931, acc: 65.56299603174604\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:01, 145.59it/s]\n",
      "INFO:TRAIN loss: 0.5805878673960095, acc: 70.1837751971954\n",
      "INFO:TRAIN loss: 0.5805878673960095, acc: 70.1837751971954\n",
      "INFO:TRAIN loss: 0.5805878673960095, acc: 70.1837751971954\n",
      "24it [00:00, 158.61it/s]\n",
      "INFO:VAL loss: 0.646274105956157, acc: 65.4358878968254\n",
      "INFO:VAL loss: 0.646274105956157, acc: 65.4358878968254\n",
      "INFO:VAL loss: 0.646274105956157, acc: 65.4358878968254\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:01, 145.57it/s]\n",
      "INFO:TRAIN loss: 0.5813642771331814, acc: 70.0644080484955\n",
      "INFO:TRAIN loss: 0.5813642771331814, acc: 70.0644080484955\n",
      "INFO:TRAIN loss: 0.5813642771331814, acc: 70.0644080484955\n",
      "24it [00:00, 157.99it/s]\n",
      "INFO:VAL loss: 0.6492510785659152, acc: 65.4684399801587\n",
      "INFO:VAL loss: 0.6492510785659152, acc: 65.4684399801587\n",
      "INFO:VAL loss: 0.6492510785659152, acc: 65.4684399801587\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:01, 142.90it/s]\n",
      "INFO:TRAIN loss: 0.580813099818727, acc: 70.40607654104588\n",
      "INFO:TRAIN loss: 0.580813099818727, acc: 70.40607654104588\n",
      "INFO:TRAIN loss: 0.580813099818727, acc: 70.40607654104588\n",
      "24it [00:00, 156.81it/s]\n",
      "INFO:VAL loss: 0.6460786263147988, acc: 64.98015873015873\n",
      "INFO:VAL loss: 0.6460786263147988, acc: 64.98015873015873\n",
      "INFO:VAL loss: 0.6460786263147988, acc: 64.98015873015873\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:01, 145.66it/s]\n",
      "INFO:TRAIN loss: 0.5810887586851063, acc: 70.30405528775928\n",
      "INFO:TRAIN loss: 0.5810887586851063, acc: 70.30405528775928\n",
      "INFO:TRAIN loss: 0.5810887586851063, acc: 70.30405528775928\n",
      "24it [00:00, 158.70it/s]\n",
      "INFO:VAL loss: 0.6483065274854501, acc: 65.10726686507934\n",
      "INFO:VAL loss: 0.6483065274854501, acc: 65.10726686507934\n",
      "INFO:VAL loss: 0.6483065274854501, acc: 65.10726686507934\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:01, 145.99it/s]\n",
      "INFO:TRAIN loss: 0.5815160656633555, acc: 70.30314234589541\n",
      "INFO:TRAIN loss: 0.5815160656633555, acc: 70.30314234589541\n",
      "INFO:TRAIN loss: 0.5815160656633555, acc: 70.30314234589541\n",
      "24it [00:00, 146.64it/s]\n",
      "INFO:VAL loss: 0.65005553389589, acc: 65.30257936507935\n",
      "INFO:VAL loss: 0.65005553389589, acc: 65.30257936507935\n",
      "INFO:VAL loss: 0.65005553389589, acc: 65.30257936507935\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:01, 145.81it/s]\n",
      "INFO:TRAIN loss: 0.5824367285140453, acc: 70.25863643003213\n",
      "INFO:TRAIN loss: 0.5824367285140453, acc: 70.25863643003213\n",
      "INFO:TRAIN loss: 0.5824367285140453, acc: 70.25863643003213\n",
      "24it [00:00, 158.50it/s]\n",
      "INFO:VAL loss: 0.6467728776236376, acc: 64.84995039682538\n",
      "INFO:VAL loss: 0.6467728776236376, acc: 64.84995039682538\n",
      "INFO:VAL loss: 0.6467728776236376, acc: 64.84995039682538\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:01, 145.68it/s]\n",
      "INFO:TRAIN loss: 0.5810875431891603, acc: 70.2139022787029\n",
      "INFO:TRAIN loss: 0.5810875431891603, acc: 70.2139022787029\n",
      "INFO:TRAIN loss: 0.5810875431891603, acc: 70.2139022787029\n",
      "24it [00:00, 156.60it/s]\n",
      "INFO:VAL loss: 0.6456460915505885, acc: 65.30257936507938\n",
      "INFO:VAL loss: 0.6456460915505885, acc: 65.30257936507938\n",
      "INFO:VAL loss: 0.6456460915505885, acc: 65.30257936507938\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:01, 145.74it/s]\n",
      "INFO:TRAIN loss: 0.5799511036624202, acc: 70.54895194274027\n",
      "INFO:TRAIN loss: 0.5799511036624202, acc: 70.54895194274027\n",
      "INFO:TRAIN loss: 0.5799511036624202, acc: 70.54895194274027\n",
      "24it [00:00, 157.73it/s]\n",
      "INFO:VAL loss: 0.6457186490297318, acc: 65.27622767857143\n",
      "INFO:VAL loss: 0.6457186490297318, acc: 65.27622767857143\n",
      "INFO:VAL loss: 0.6457186490297318, acc: 65.27622767857143\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:01, 145.08it/s]\n",
      "INFO:TRAIN loss: 0.5809232550530343, acc: 70.21869522348814\n",
      "INFO:TRAIN loss: 0.5809232550530343, acc: 70.21869522348814\n",
      "INFO:TRAIN loss: 0.5809232550530343, acc: 70.21869522348814\n",
      "24it [00:00, 157.95it/s]\n",
      "INFO:VAL loss: 0.6431941005090873, acc: 64.8499503968254\n",
      "INFO:VAL loss: 0.6431941005090873, acc: 64.8499503968254\n",
      "INFO:VAL loss: 0.6431941005090873, acc: 64.8499503968254\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:01, 145.17it/s]\n",
      "INFO:TRAIN loss: 0.580813287591642, acc: 70.39603418054338\n",
      "INFO:TRAIN loss: 0.580813287591642, acc: 70.39603418054338\n",
      "INFO:TRAIN loss: 0.580813287591642, acc: 70.39603418054338\n",
      "24it [00:00, 157.77it/s]\n",
      "INFO:VAL loss: 0.6491470423837503, acc: 65.53044394841271\n",
      "INFO:VAL loss: 0.6491470423837503, acc: 65.53044394841271\n",
      "INFO:VAL loss: 0.6491470423837503, acc: 65.53044394841271\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:01, 144.56it/s]\n",
      "INFO:TRAIN loss: 0.5802263917367153, acc: 70.50239190768333\n",
      "INFO:TRAIN loss: 0.5802263917367153, acc: 70.50239190768333\n",
      "INFO:TRAIN loss: 0.5802263917367153, acc: 70.50239190768333\n",
      "24it [00:00, 158.62it/s]\n",
      "INFO:VAL loss: 0.6459885003666084, acc: 65.82961309523809\n",
      "INFO:VAL loss: 0.6459885003666084, acc: 65.82961309523809\n",
      "INFO:VAL loss: 0.6459885003666084, acc: 65.82961309523809\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:01, 145.98it/s]\n",
      "INFO:TRAIN loss: 0.58042708276971, acc: 70.40698948290971\n",
      "INFO:TRAIN loss: 0.58042708276971, acc: 70.40698948290971\n",
      "INFO:TRAIN loss: 0.58042708276971, acc: 70.40698948290971\n",
      "24it [00:00, 157.53it/s]\n",
      "INFO:VAL loss: 0.646674541135629, acc: 65.2436755952381\n",
      "INFO:VAL loss: 0.646674541135629, acc: 65.2436755952381\n",
      "INFO:VAL loss: 0.646674541135629, acc: 65.2436755952381\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:01, 142.31it/s]\n",
      "INFO:TRAIN loss: 0.5808073139629478, acc: 70.21823875255625\n",
      "INFO:TRAIN loss: 0.5808073139629478, acc: 70.21823875255625\n",
      "INFO:TRAIN loss: 0.5808073139629478, acc: 70.21823875255625\n",
      "24it [00:00, 156.38it/s]\n",
      "INFO:VAL loss: 0.6448003016412259, acc: 65.2436755952381\n",
      "INFO:VAL loss: 0.6448003016412259, acc: 65.2436755952381\n",
      "INFO:VAL loss: 0.6448003016412259, acc: 65.2436755952381\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "163it [00:01, 144.18it/s]\n",
      "INFO:TRAIN loss: 0.5798722697547604, acc: 70.54073546596561\n",
      "INFO:TRAIN loss: 0.5798722697547604, acc: 70.54073546596561\n",
      "INFO:TRAIN loss: 0.5798722697547604, acc: 70.54073546596561\n",
      "24it [00:00, 157.88it/s]\n",
      "INFO:VAL loss: 0.6448410140971343, acc: 65.11036706349205\n",
      "INFO:VAL loss: 0.6448410140971343, acc: 65.11036706349205\n",
      "INFO:VAL loss: 0.6448410140971343, acc: 65.11036706349205\n",
      "47it [00:00, 156.72it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.6331552603143326, acc: 66.21131528046422\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.6331552603143326, acc: 66.21131528046422\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.6331552603143326, acc: 66.21131528046422\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.6318961484300579, 0.6042374752781869, 0.5958551647472968, 0.590458359820711, 0.590175021279809, 0.5865117307820932, 0.5851879054051968, 0.5838019114696175, 0.5839429697010412, 0.5821595771546746, 0.5814941059226637, 0.5821890373902817, 0.5816726845466289, 0.5814784194794167, 0.5820860520827991, 0.5818619534281865, 0.5815382526696098, 0.5808183382625227, 0.5809474333297989, 0.5803936778402039, 0.5812722598116823, 0.5811237808019836, 0.5811676735892619, 0.5800587569643377, 0.5807661531161677, 0.580786198926118, 0.5807099528839256, 0.5810507631009347, 0.5802155848295409, 0.5804068067688151, 0.581621293641307, 0.580942138206739, 0.5813492083110693, 0.5813207549551513, 0.5809043572724231, 0.5806276077873135, 0.5805878673960095, 0.5813642771331814, 0.580813099818727, 0.5810887586851063, 0.5815160656633555, 0.5824367285140453, 0.5810875431891603, 0.5799511036624202, 0.5809232550530343, 0.580813287591642, 0.5802263917367153, 0.58042708276971, 0.5808073139629478, 0.5798722697547604], 'train_acc': [66.11456507449607, 68.38299737072738, 68.92802366345309, 69.27973451650602, 69.50135115395854, 69.67617952088813, 70.1559304703477, 70.22485758106926, 70.09316571720714, 70.16300576979262, 70.26320113935152, 70.21915169442009, 70.25178936605317, 70.33509531113057, 70.19427402862992, 70.2958388109845, 70.15547399941575, 70.19473049956173, 70.19381755769794, 70.45971187554778, 70.0557351007888, 70.05048568507156, 70.40037065439677, 70.38302475898338, 70.31546706105752, 70.36727651183173, 70.20956580484957, 70.14155163599185, 70.18560108092319, 70.51585780017527, 70.179895194274, 70.3964906514753, 70.3093047034765, 70.12283632778261, 70.35198473561205, 70.15456105755183, 70.1837751971954, 70.0644080484955, 70.40607654104588, 70.30405528775928, 70.30314234589541, 70.25863643003213, 70.2139022787029, 70.54895194274027, 70.21869522348814, 70.39603418054338, 70.50239190768333, 70.40698948290971, 70.21823875255625, 70.54073546596561], 'val_loss': [0.6329316347837448, 0.6317886995772521, 0.6346244377394517, 0.6290393931170305, 0.6350352416435878, 0.6342972069978714, 0.6342929763098558, 0.6403080510596434, 0.6407949353257815, 0.6405622772872448, 0.6379954367876053, 0.6405733488500119, 0.6417583748698235, 0.6446929996212322, 0.6417805130283039, 0.6420308786133926, 0.643623256434997, 0.6440234829982123, 0.6437774685521922, 0.649130215247472, 0.645144817729791, 0.6429272716244062, 0.6435846723616123, 0.6453766524791719, 0.6447876455883186, 0.6398186994095643, 0.644272598127524, 0.6458690129220487, 0.6511546236773332, 0.6459353441993396, 0.6475948716203371, 0.6463040076196193, 0.6457157085339228, 0.6453359338144462, 0.6488670222461225, 0.6501005490620931, 0.646274105956157, 0.6492510785659152, 0.6460786263147988, 0.6483065274854501, 0.65005553389589, 0.6467728776236376, 0.6456460915505885, 0.6457186490297318, 0.6431941005090873, 0.6491470423837503, 0.6459885003666084, 0.646674541135629, 0.6448003016412259, 0.6448410140971343], 'val_acc': [65.29947916666667, 65.69320436507937, 65.27002728174602, 65.92106894841271, 65.66065228174604, 65.75830853174604, 65.69320436507935, 65.62810019841271, 65.4358878968254, 66.1194816468254, 65.79396081349208, 65.5335441468254, 65.92416914682539, 65.66065228174604, 65.63430059523809, 65.4327876984127, 66.15203373015873, 65.66685267857142, 65.01271081349205, 65.43278769841271, 65.46843998015873, 65.1072668650794, 64.98015873015875, 65.04526289682539, 65.60174851190474, 65.4420882936508, 65.43588789682539, 65.10726686507935, 65.66065228174604, 65.07471478174602, 65.30567956349208, 64.81429811507937, 65.04216269841271, 64.74919394841268, 64.78174603174601, 65.56299603174604, 65.4358878968254, 65.4684399801587, 64.98015873015873, 65.10726686507934, 65.30257936507935, 64.84995039682538, 65.30257936507938, 65.27622767857143, 64.8499503968254, 65.53044394841271, 65.82961309523809, 65.2436755952381, 65.2436755952381, 65.11036706349205], 'test_loss': 0.6331552603143326, 'test_acc': 66.21131528046422}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:{'epoch_index': 49, 'train_loss': [0.6318961484300579, 0.6042374752781869, 0.5958551647472968, 0.590458359820711, 0.590175021279809, 0.5865117307820932, 0.5851879054051968, 0.5838019114696175, 0.5839429697010412, 0.5821595771546746, 0.5814941059226637, 0.5821890373902817, 0.5816726845466289, 0.5814784194794167, 0.5820860520827991, 0.5818619534281865, 0.5815382526696098, 0.5808183382625227, 0.5809474333297989, 0.5803936778402039, 0.5812722598116823, 0.5811237808019836, 0.5811676735892619, 0.5800587569643377, 0.5807661531161677, 0.580786198926118, 0.5807099528839256, 0.5810507631009347, 0.5802155848295409, 0.5804068067688151, 0.581621293641307, 0.580942138206739, 0.5813492083110693, 0.5813207549551513, 0.5809043572724231, 0.5806276077873135, 0.5805878673960095, 0.5813642771331814, 0.580813099818727, 0.5810887586851063, 0.5815160656633555, 0.5824367285140453, 0.5810875431891603, 0.5799511036624202, 0.5809232550530343, 0.580813287591642, 0.5802263917367153, 0.58042708276971, 0.5808073139629478, 0.5798722697547604], 'train_acc': [66.11456507449607, 68.38299737072738, 68.92802366345309, 69.27973451650602, 69.50135115395854, 69.67617952088813, 70.1559304703477, 70.22485758106926, 70.09316571720714, 70.16300576979262, 70.26320113935152, 70.21915169442009, 70.25178936605317, 70.33509531113057, 70.19427402862992, 70.2958388109845, 70.15547399941575, 70.19473049956173, 70.19381755769794, 70.45971187554778, 70.0557351007888, 70.05048568507156, 70.40037065439677, 70.38302475898338, 70.31546706105752, 70.36727651183173, 70.20956580484957, 70.14155163599185, 70.18560108092319, 70.51585780017527, 70.179895194274, 70.3964906514753, 70.3093047034765, 70.12283632778261, 70.35198473561205, 70.15456105755183, 70.1837751971954, 70.0644080484955, 70.40607654104588, 70.30405528775928, 70.30314234589541, 70.25863643003213, 70.2139022787029, 70.54895194274027, 70.21869522348814, 70.39603418054338, 70.50239190768333, 70.40698948290971, 70.21823875255625, 70.54073546596561], 'val_loss': [0.6329316347837448, 0.6317886995772521, 0.6346244377394517, 0.6290393931170305, 0.6350352416435878, 0.6342972069978714, 0.6342929763098558, 0.6403080510596434, 0.6407949353257815, 0.6405622772872448, 0.6379954367876053, 0.6405733488500119, 0.6417583748698235, 0.6446929996212322, 0.6417805130283039, 0.6420308786133926, 0.643623256434997, 0.6440234829982123, 0.6437774685521922, 0.649130215247472, 0.645144817729791, 0.6429272716244062, 0.6435846723616123, 0.6453766524791719, 0.6447876455883186, 0.6398186994095643, 0.644272598127524, 0.6458690129220487, 0.6511546236773332, 0.6459353441993396, 0.6475948716203371, 0.6463040076196193, 0.6457157085339228, 0.6453359338144462, 0.6488670222461225, 0.6501005490620931, 0.646274105956157, 0.6492510785659152, 0.6460786263147988, 0.6483065274854501, 0.65005553389589, 0.6467728776236376, 0.6456460915505885, 0.6457186490297318, 0.6431941005090873, 0.6491470423837503, 0.6459885003666084, 0.646674541135629, 0.6448003016412259, 0.6448410140971343], 'val_acc': [65.29947916666667, 65.69320436507937, 65.27002728174602, 65.92106894841271, 65.66065228174604, 65.75830853174604, 65.69320436507935, 65.62810019841271, 65.4358878968254, 66.1194816468254, 65.79396081349208, 65.5335441468254, 65.92416914682539, 65.66065228174604, 65.63430059523809, 65.4327876984127, 66.15203373015873, 65.66685267857142, 65.01271081349205, 65.43278769841271, 65.46843998015873, 65.1072668650794, 64.98015873015875, 65.04526289682539, 65.60174851190474, 65.4420882936508, 65.43588789682539, 65.10726686507935, 65.66065228174604, 65.07471478174602, 65.30567956349208, 64.81429811507937, 65.04216269841271, 64.74919394841268, 64.78174603174601, 65.56299603174604, 65.4358878968254, 65.4684399801587, 64.98015873015873, 65.10726686507934, 65.30257936507935, 64.84995039682538, 65.30257936507938, 65.27622767857143, 64.8499503968254, 65.53044394841271, 65.82961309523809, 65.2436755952381, 65.2436755952381, 65.11036706349205], 'test_loss': 0.6331552603143326, 'test_acc': 66.21131528046422}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.6318961484300579, 0.6042374752781869, 0.5958551647472968, 0.590458359820711, 0.590175021279809, 0.5865117307820932, 0.5851879054051968, 0.5838019114696175, 0.5839429697010412, 0.5821595771546746, 0.5814941059226637, 0.5821890373902817, 0.5816726845466289, 0.5814784194794167, 0.5820860520827991, 0.5818619534281865, 0.5815382526696098, 0.5808183382625227, 0.5809474333297989, 0.5803936778402039, 0.5812722598116823, 0.5811237808019836, 0.5811676735892619, 0.5800587569643377, 0.5807661531161677, 0.580786198926118, 0.5807099528839256, 0.5810507631009347, 0.5802155848295409, 0.5804068067688151, 0.581621293641307, 0.580942138206739, 0.5813492083110693, 0.5813207549551513, 0.5809043572724231, 0.5806276077873135, 0.5805878673960095, 0.5813642771331814, 0.580813099818727, 0.5810887586851063, 0.5815160656633555, 0.5824367285140453, 0.5810875431891603, 0.5799511036624202, 0.5809232550530343, 0.580813287591642, 0.5802263917367153, 0.58042708276971, 0.5808073139629478, 0.5798722697547604], 'train_acc': [66.11456507449607, 68.38299737072738, 68.92802366345309, 69.27973451650602, 69.50135115395854, 69.67617952088813, 70.1559304703477, 70.22485758106926, 70.09316571720714, 70.16300576979262, 70.26320113935152, 70.21915169442009, 70.25178936605317, 70.33509531113057, 70.19427402862992, 70.2958388109845, 70.15547399941575, 70.19473049956173, 70.19381755769794, 70.45971187554778, 70.0557351007888, 70.05048568507156, 70.40037065439677, 70.38302475898338, 70.31546706105752, 70.36727651183173, 70.20956580484957, 70.14155163599185, 70.18560108092319, 70.51585780017527, 70.179895194274, 70.3964906514753, 70.3093047034765, 70.12283632778261, 70.35198473561205, 70.15456105755183, 70.1837751971954, 70.0644080484955, 70.40607654104588, 70.30405528775928, 70.30314234589541, 70.25863643003213, 70.2139022787029, 70.54895194274027, 70.21869522348814, 70.39603418054338, 70.50239190768333, 70.40698948290971, 70.21823875255625, 70.54073546596561], 'val_loss': [0.6329316347837448, 0.6317886995772521, 0.6346244377394517, 0.6290393931170305, 0.6350352416435878, 0.6342972069978714, 0.6342929763098558, 0.6403080510596434, 0.6407949353257815, 0.6405622772872448, 0.6379954367876053, 0.6405733488500119, 0.6417583748698235, 0.6446929996212322, 0.6417805130283039, 0.6420308786133926, 0.643623256434997, 0.6440234829982123, 0.6437774685521922, 0.649130215247472, 0.645144817729791, 0.6429272716244062, 0.6435846723616123, 0.6453766524791719, 0.6447876455883186, 0.6398186994095643, 0.644272598127524, 0.6458690129220487, 0.6511546236773332, 0.6459353441993396, 0.6475948716203371, 0.6463040076196193, 0.6457157085339228, 0.6453359338144462, 0.6488670222461225, 0.6501005490620931, 0.646274105956157, 0.6492510785659152, 0.6460786263147988, 0.6483065274854501, 0.65005553389589, 0.6467728776236376, 0.6456460915505885, 0.6457186490297318, 0.6431941005090873, 0.6491470423837503, 0.6459885003666084, 0.646674541135629, 0.6448003016412259, 0.6448410140971343], 'val_acc': [65.29947916666667, 65.69320436507937, 65.27002728174602, 65.92106894841271, 65.66065228174604, 65.75830853174604, 65.69320436507935, 65.62810019841271, 65.4358878968254, 66.1194816468254, 65.79396081349208, 65.5335441468254, 65.92416914682539, 65.66065228174604, 65.63430059523809, 65.4327876984127, 66.15203373015873, 65.66685267857142, 65.01271081349205, 65.43278769841271, 65.46843998015873, 65.1072668650794, 64.98015873015875, 65.04526289682539, 65.60174851190474, 65.4420882936508, 65.43588789682539, 65.10726686507935, 65.66065228174604, 65.07471478174602, 65.30567956349208, 64.81429811507937, 65.04216269841271, 64.74919394841268, 64.78174603174601, 65.56299603174604, 65.4358878968254, 65.4684399801587, 64.98015873015873, 65.10726686507934, 65.30257936507935, 64.84995039682538, 65.30257936507938, 65.27622767857143, 64.8499503968254, 65.53044394841271, 65.82961309523809, 65.2436755952381, 65.2436755952381, 65.11036706349205], 'test_loss': 0.6331552603143326, 'test_acc': 66.21131528046422}\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "args.model_id=3\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_pretrainembedding_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_pretrainembedding_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_pretrainembedding_test, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_FeedForward(num_features=10*100) \n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "args.logger.handlers.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84411fa",
   "metadata": {},
   "source": [
    "**`acc:66.21`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d125ece",
   "metadata": {},
   "source": [
    "Observe the results of models 2 and 3. There is almost no difference in the effect of the own-trained embedding and the pre-trained embedding in the forward propagation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e28524",
   "metadata": {},
   "source": [
    "## Conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efee168",
   "metadata": {},
   "source": [
    "**`model 4: text--10word, embedding--onehot, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4511aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=4, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=4, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=4, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=4, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=4, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=4, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=4, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:04, 35.42it/s]\n",
      "INFO:TRAIN loss: 0.5844922546594423, acc: 69.97722210049668\n",
      "INFO:TRAIN loss: 0.5844922546594423, acc: 69.97722210049668\n",
      "INFO:TRAIN loss: 0.5844922546594423, acc: 69.97722210049668\n",
      "INFO:TRAIN loss: 0.5844922546594423, acc: 69.97722210049668\n",
      "INFO:TRAIN loss: 0.5844922546594423, acc: 69.97722210049668\n",
      "INFO:TRAIN loss: 0.5844922546594423, acc: 69.97722210049668\n",
      "INFO:TRAIN loss: 0.5844922546594423, acc: 69.97722210049668\n",
      "24it [00:00, 43.90it/s]\n",
      "INFO:VAL loss: 0.559296291321516, acc: 72.21602182539682\n",
      "INFO:VAL loss: 0.559296291321516, acc: 72.21602182539682\n",
      "INFO:VAL loss: 0.559296291321516, acc: 72.21602182539682\n",
      "INFO:VAL loss: 0.559296291321516, acc: 72.21602182539682\n",
      "INFO:VAL loss: 0.559296291321516, acc: 72.21602182539682\n",
      "INFO:VAL loss: 0.559296291321516, acc: 72.21602182539682\n",
      "INFO:VAL loss: 0.559296291321516, acc: 72.21602182539682\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:04, 34.98it/s]\n",
      "INFO:TRAIN loss: 0.48890001916446557, acc: 76.48444347063982\n",
      "INFO:TRAIN loss: 0.48890001916446557, acc: 76.48444347063982\n",
      "INFO:TRAIN loss: 0.48890001916446557, acc: 76.48444347063982\n",
      "INFO:TRAIN loss: 0.48890001916446557, acc: 76.48444347063982\n",
      "INFO:TRAIN loss: 0.48890001916446557, acc: 76.48444347063982\n",
      "INFO:TRAIN loss: 0.48890001916446557, acc: 76.48444347063982\n",
      "INFO:TRAIN loss: 0.48890001916446557, acc: 76.48444347063982\n",
      "24it [00:00, 47.27it/s]\n",
      "INFO:VAL loss: 0.5571468925724427, acc: 72.93526785714286\n",
      "INFO:VAL loss: 0.5571468925724427, acc: 72.93526785714286\n",
      "INFO:VAL loss: 0.5571468925724427, acc: 72.93526785714286\n",
      "INFO:VAL loss: 0.5571468925724427, acc: 72.93526785714286\n",
      "INFO:VAL loss: 0.5571468925724427, acc: 72.93526785714286\n",
      "INFO:VAL loss: 0.5571468925724427, acc: 72.93526785714286\n",
      "INFO:VAL loss: 0.5571468925724427, acc: 72.93526785714286\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:04, 37.95it/s]\n",
      "INFO:TRAIN loss: 0.435949481520916, acc: 79.7657847648262\n",
      "INFO:TRAIN loss: 0.435949481520916, acc: 79.7657847648262\n",
      "INFO:TRAIN loss: 0.435949481520916, acc: 79.7657847648262\n",
      "INFO:TRAIN loss: 0.435949481520916, acc: 79.7657847648262\n",
      "INFO:TRAIN loss: 0.435949481520916, acc: 79.7657847648262\n",
      "INFO:TRAIN loss: 0.435949481520916, acc: 79.7657847648262\n",
      "INFO:TRAIN loss: 0.435949481520916, acc: 79.7657847648262\n",
      "24it [00:00, 48.43it/s]\n",
      "INFO:VAL loss: 0.55870641892155, acc: 74.14589533730158\n",
      "INFO:VAL loss: 0.55870641892155, acc: 74.14589533730158\n",
      "INFO:VAL loss: 0.55870641892155, acc: 74.14589533730158\n",
      "INFO:VAL loss: 0.55870641892155, acc: 74.14589533730158\n",
      "INFO:VAL loss: 0.55870641892155, acc: 74.14589533730158\n",
      "INFO:VAL loss: 0.55870641892155, acc: 74.14589533730158\n",
      "INFO:VAL loss: 0.55870641892155, acc: 74.14589533730158\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:04, 37.77it/s]\n",
      "INFO:TRAIN loss: 0.38943886702046054, acc: 82.58586218229625\n",
      "INFO:TRAIN loss: 0.38943886702046054, acc: 82.58586218229625\n",
      "INFO:TRAIN loss: 0.38943886702046054, acc: 82.58586218229625\n",
      "INFO:TRAIN loss: 0.38943886702046054, acc: 82.58586218229625\n",
      "INFO:TRAIN loss: 0.38943886702046054, acc: 82.58586218229625\n",
      "INFO:TRAIN loss: 0.38943886702046054, acc: 82.58586218229625\n",
      "INFO:TRAIN loss: 0.38943886702046054, acc: 82.58586218229625\n",
      "24it [00:00, 45.84it/s]\n",
      "INFO:VAL loss: 0.5637129123012224, acc: 75.19686259920634\n",
      "INFO:VAL loss: 0.5637129123012224, acc: 75.19686259920634\n",
      "INFO:VAL loss: 0.5637129123012224, acc: 75.19686259920634\n",
      "INFO:VAL loss: 0.5637129123012224, acc: 75.19686259920634\n",
      "INFO:VAL loss: 0.5637129123012224, acc: 75.19686259920634\n",
      "INFO:VAL loss: 0.5637129123012224, acc: 75.19686259920634\n",
      "INFO:VAL loss: 0.5637129123012224, acc: 75.19686259920634\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:04, 37.13it/s]\n",
      "INFO:TRAIN loss: 0.3399630057299797, acc: 85.56319383581653\n",
      "INFO:TRAIN loss: 0.3399630057299797, acc: 85.56319383581653\n",
      "INFO:TRAIN loss: 0.3399630057299797, acc: 85.56319383581653\n",
      "INFO:TRAIN loss: 0.3399630057299797, acc: 85.56319383581653\n",
      "INFO:TRAIN loss: 0.3399630057299797, acc: 85.56319383581653\n",
      "INFO:TRAIN loss: 0.3399630057299797, acc: 85.56319383581653\n",
      "INFO:TRAIN loss: 0.3399630057299797, acc: 85.56319383581653\n",
      "24it [00:00, 46.68it/s]\n",
      "INFO:VAL loss: 0.5908194333314895, acc: 75.164310515873\n",
      "INFO:VAL loss: 0.5908194333314895, acc: 75.164310515873\n",
      "INFO:VAL loss: 0.5908194333314895, acc: 75.164310515873\n",
      "INFO:VAL loss: 0.5908194333314895, acc: 75.164310515873\n",
      "INFO:VAL loss: 0.5908194333314895, acc: 75.164310515873\n",
      "INFO:VAL loss: 0.5908194333314895, acc: 75.164310515873\n",
      "INFO:VAL loss: 0.5908194333314895, acc: 75.164310515873\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:04, 37.33it/s]\n",
      "INFO:TRAIN loss: 0.2906636262049704, acc: 88.37665242477357\n",
      "INFO:TRAIN loss: 0.2906636262049704, acc: 88.37665242477357\n",
      "INFO:TRAIN loss: 0.2906636262049704, acc: 88.37665242477357\n",
      "INFO:TRAIN loss: 0.2906636262049704, acc: 88.37665242477357\n",
      "INFO:TRAIN loss: 0.2906636262049704, acc: 88.37665242477357\n",
      "INFO:TRAIN loss: 0.2906636262049704, acc: 88.37665242477357\n",
      "INFO:TRAIN loss: 0.2906636262049704, acc: 88.37665242477357\n",
      "24it [00:00, 43.62it/s]\n",
      "INFO:VAL loss: 0.611488209416469, acc: 75.85100446428572\n",
      "INFO:VAL loss: 0.611488209416469, acc: 75.85100446428572\n",
      "INFO:VAL loss: 0.611488209416469, acc: 75.85100446428572\n",
      "INFO:VAL loss: 0.611488209416469, acc: 75.85100446428572\n",
      "INFO:VAL loss: 0.611488209416469, acc: 75.85100446428572\n",
      "INFO:VAL loss: 0.611488209416469, acc: 75.85100446428572\n",
      "INFO:VAL loss: 0.611488209416469, acc: 75.85100446428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:04, 37.39it/s]\n",
      "INFO:TRAIN loss: 0.2507701683446673, acc: 90.38443981887234\n",
      "INFO:TRAIN loss: 0.2507701683446673, acc: 90.38443981887234\n",
      "INFO:TRAIN loss: 0.2507701683446673, acc: 90.38443981887234\n",
      "INFO:TRAIN loss: 0.2507701683446673, acc: 90.38443981887234\n",
      "INFO:TRAIN loss: 0.2507701683446673, acc: 90.38443981887234\n",
      "INFO:TRAIN loss: 0.2507701683446673, acc: 90.38443981887234\n",
      "INFO:TRAIN loss: 0.2507701683446673, acc: 90.38443981887234\n",
      "24it [00:00, 46.96it/s]\n",
      "INFO:VAL loss: 0.6403187215328217, acc: 75.32707093253968\n",
      "INFO:VAL loss: 0.6403187215328217, acc: 75.32707093253968\n",
      "INFO:VAL loss: 0.6403187215328217, acc: 75.32707093253968\n",
      "INFO:VAL loss: 0.6403187215328217, acc: 75.32707093253968\n",
      "INFO:VAL loss: 0.6403187215328217, acc: 75.32707093253968\n",
      "INFO:VAL loss: 0.6403187215328217, acc: 75.32707093253968\n",
      "INFO:VAL loss: 0.6403187215328217, acc: 75.32707093253968\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:04, 36.34it/s]\n",
      "INFO:TRAIN loss: 0.20844713273955276, acc: 92.73343923458957\n",
      "INFO:TRAIN loss: 0.20844713273955276, acc: 92.73343923458957\n",
      "INFO:TRAIN loss: 0.20844713273955276, acc: 92.73343923458957\n",
      "INFO:TRAIN loss: 0.20844713273955276, acc: 92.73343923458957\n",
      "INFO:TRAIN loss: 0.20844713273955276, acc: 92.73343923458957\n",
      "INFO:TRAIN loss: 0.20844713273955276, acc: 92.73343923458957\n",
      "INFO:TRAIN loss: 0.20844713273955276, acc: 92.73343923458957\n",
      "24it [00:00, 48.37it/s]\n",
      "INFO:VAL loss: 0.6766988107313714, acc: 75.38907490079364\n",
      "INFO:VAL loss: 0.6766988107313714, acc: 75.38907490079364\n",
      "INFO:VAL loss: 0.6766988107313714, acc: 75.38907490079364\n",
      "INFO:VAL loss: 0.6766988107313714, acc: 75.38907490079364\n",
      "INFO:VAL loss: 0.6766988107313714, acc: 75.38907490079364\n",
      "INFO:VAL loss: 0.6766988107313714, acc: 75.38907490079364\n",
      "INFO:VAL loss: 0.6766988107313714, acc: 75.38907490079364\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:04, 37.27it/s]\n",
      "INFO:TRAIN loss: 0.17704325237888496, acc: 93.74041411042947\n",
      "INFO:TRAIN loss: 0.17704325237888496, acc: 93.74041411042947\n",
      "INFO:TRAIN loss: 0.17704325237888496, acc: 93.74041411042947\n",
      "INFO:TRAIN loss: 0.17704325237888496, acc: 93.74041411042947\n",
      "INFO:TRAIN loss: 0.17704325237888496, acc: 93.74041411042947\n",
      "INFO:TRAIN loss: 0.17704325237888496, acc: 93.74041411042947\n",
      "INFO:TRAIN loss: 0.17704325237888496, acc: 93.74041411042947\n",
      "24it [00:00, 47.06it/s]\n",
      "INFO:VAL loss: 0.7013713556031386, acc: 75.55183531746032\n",
      "INFO:VAL loss: 0.7013713556031386, acc: 75.55183531746032\n",
      "INFO:VAL loss: 0.7013713556031386, acc: 75.55183531746032\n",
      "INFO:VAL loss: 0.7013713556031386, acc: 75.55183531746032\n",
      "INFO:VAL loss: 0.7013713556031386, acc: 75.55183531746032\n",
      "INFO:VAL loss: 0.7013713556031386, acc: 75.55183531746032\n",
      "INFO:VAL loss: 0.7013713556031386, acc: 75.55183531746032\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:04, 37.67it/s]\n",
      "INFO:TRAIN loss: 0.15158120254797436, acc: 95.05847392638029\n",
      "INFO:TRAIN loss: 0.15158120254797436, acc: 95.05847392638029\n",
      "INFO:TRAIN loss: 0.15158120254797436, acc: 95.05847392638029\n",
      "INFO:TRAIN loss: 0.15158120254797436, acc: 95.05847392638029\n",
      "INFO:TRAIN loss: 0.15158120254797436, acc: 95.05847392638029\n",
      "INFO:TRAIN loss: 0.15158120254797436, acc: 95.05847392638029\n",
      "INFO:TRAIN loss: 0.15158120254797436, acc: 95.05847392638029\n",
      "24it [00:00, 46.61it/s]\n",
      "INFO:VAL loss: 0.7362759858369827, acc: 74.93024553571428\n",
      "INFO:VAL loss: 0.7362759858369827, acc: 74.93024553571428\n",
      "INFO:VAL loss: 0.7362759858369827, acc: 74.93024553571428\n",
      "INFO:VAL loss: 0.7362759858369827, acc: 74.93024553571428\n",
      "INFO:VAL loss: 0.7362759858369827, acc: 74.93024553571428\n",
      "INFO:VAL loss: 0.7362759858369827, acc: 74.93024553571428\n",
      "INFO:VAL loss: 0.7362759858369827, acc: 74.93024553571428\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:04, 36.67it/s]\n",
      "INFO:TRAIN loss: 0.131700625426016, acc: 95.7726226993864\n",
      "INFO:TRAIN loss: 0.131700625426016, acc: 95.7726226993864\n",
      "INFO:TRAIN loss: 0.131700625426016, acc: 95.7726226993864\n",
      "INFO:TRAIN loss: 0.131700625426016, acc: 95.7726226993864\n",
      "INFO:TRAIN loss: 0.131700625426016, acc: 95.7726226993864\n",
      "INFO:TRAIN loss: 0.131700625426016, acc: 95.7726226993864\n",
      "INFO:TRAIN loss: 0.131700625426016, acc: 95.7726226993864\n",
      "24it [00:00, 48.10it/s]\n",
      "INFO:VAL loss: 0.7568644148608049, acc: 74.44196428571428\n",
      "INFO:VAL loss: 0.7568644148608049, acc: 74.44196428571428\n",
      "INFO:VAL loss: 0.7568644148608049, acc: 74.44196428571428\n",
      "INFO:VAL loss: 0.7568644148608049, acc: 74.44196428571428\n",
      "INFO:VAL loss: 0.7568644148608049, acc: 74.44196428571428\n",
      "INFO:VAL loss: 0.7568644148608049, acc: 74.44196428571428\n",
      "INFO:VAL loss: 0.7568644148608049, acc: 74.44196428571428\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:04, 36.32it/s]\n",
      "INFO:TRAIN loss: 0.1134038314314708, acc: 96.42400671925212\n",
      "INFO:TRAIN loss: 0.1134038314314708, acc: 96.42400671925212\n",
      "INFO:TRAIN loss: 0.1134038314314708, acc: 96.42400671925212\n",
      "INFO:TRAIN loss: 0.1134038314314708, acc: 96.42400671925212\n",
      "INFO:TRAIN loss: 0.1134038314314708, acc: 96.42400671925212\n",
      "INFO:TRAIN loss: 0.1134038314314708, acc: 96.42400671925212\n",
      "INFO:TRAIN loss: 0.1134038314314708, acc: 96.42400671925212\n",
      "24it [00:00, 44.91it/s]\n",
      "INFO:VAL loss: 0.7879717921217283, acc: 74.99224950396824\n",
      "INFO:VAL loss: 0.7879717921217283, acc: 74.99224950396824\n",
      "INFO:VAL loss: 0.7879717921217283, acc: 74.99224950396824\n",
      "INFO:VAL loss: 0.7879717921217283, acc: 74.99224950396824\n",
      "INFO:VAL loss: 0.7879717921217283, acc: 74.99224950396824\n",
      "INFO:VAL loss: 0.7879717921217283, acc: 74.99224950396824\n",
      "INFO:VAL loss: 0.7879717921217283, acc: 74.99224950396824\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:04, 35.65it/s]\n",
      "INFO:TRAIN loss: 0.0984821757244552, acc: 97.1050613496932\n",
      "INFO:TRAIN loss: 0.0984821757244552, acc: 97.1050613496932\n",
      "INFO:TRAIN loss: 0.0984821757244552, acc: 97.1050613496932\n",
      "INFO:TRAIN loss: 0.0984821757244552, acc: 97.1050613496932\n",
      "INFO:TRAIN loss: 0.0984821757244552, acc: 97.1050613496932\n",
      "INFO:TRAIN loss: 0.0984821757244552, acc: 97.1050613496932\n",
      "INFO:TRAIN loss: 0.0984821757244552, acc: 97.1050613496932\n",
      "24it [00:00, 45.35it/s]\n",
      "INFO:VAL loss: 0.8191735185682774, acc: 74.9627976190476\n",
      "INFO:VAL loss: 0.8191735185682774, acc: 74.9627976190476\n",
      "INFO:VAL loss: 0.8191735185682774, acc: 74.9627976190476\n",
      "INFO:VAL loss: 0.8191735185682774, acc: 74.9627976190476\n",
      "INFO:VAL loss: 0.8191735185682774, acc: 74.9627976190476\n",
      "INFO:VAL loss: 0.8191735185682774, acc: 74.9627976190476\n",
      "INFO:VAL loss: 0.8191735185682774, acc: 74.9627976190476\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:04, 36.00it/s]\n",
      "INFO:TRAIN loss: 0.09294591581254648, acc: 97.1233201869705\n",
      "INFO:TRAIN loss: 0.09294591581254648, acc: 97.1233201869705\n",
      "INFO:TRAIN loss: 0.09294591581254648, acc: 97.1233201869705\n",
      "INFO:TRAIN loss: 0.09294591581254648, acc: 97.1233201869705\n",
      "INFO:TRAIN loss: 0.09294591581254648, acc: 97.1233201869705\n",
      "INFO:TRAIN loss: 0.09294591581254648, acc: 97.1233201869705\n",
      "INFO:TRAIN loss: 0.09294591581254648, acc: 97.1233201869705\n",
      "24it [00:00, 45.70it/s]\n",
      "INFO:VAL loss: 0.8383389376103879, acc: 75.25886656746033\n",
      "INFO:VAL loss: 0.8383389376103879, acc: 75.25886656746033\n",
      "INFO:VAL loss: 0.8383389376103879, acc: 75.25886656746033\n",
      "INFO:VAL loss: 0.8383389376103879, acc: 75.25886656746033\n",
      "INFO:VAL loss: 0.8383389376103879, acc: 75.25886656746033\n",
      "INFO:VAL loss: 0.8383389376103879, acc: 75.25886656746033\n",
      "INFO:VAL loss: 0.8383389376103879, acc: 75.25886656746033\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:04, 37.19it/s]\n",
      "INFO:TRAIN loss: 0.08557747846092184, acc: 97.31595092024538\n",
      "INFO:TRAIN loss: 0.08557747846092184, acc: 97.31595092024538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN loss: 0.08557747846092184, acc: 97.31595092024538\n",
      "INFO:TRAIN loss: 0.08557747846092184, acc: 97.31595092024538\n",
      "INFO:TRAIN loss: 0.08557747846092184, acc: 97.31595092024538\n",
      "INFO:TRAIN loss: 0.08557747846092184, acc: 97.31595092024538\n",
      "INFO:TRAIN loss: 0.08557747846092184, acc: 97.31595092024538\n",
      "24it [00:00, 46.29it/s]\n",
      "INFO:VAL loss: 0.8717255455752214, acc: 74.933345734127\n",
      "INFO:VAL loss: 0.8717255455752214, acc: 74.933345734127\n",
      "INFO:VAL loss: 0.8717255455752214, acc: 74.933345734127\n",
      "INFO:VAL loss: 0.8717255455752214, acc: 74.933345734127\n",
      "INFO:VAL loss: 0.8717255455752214, acc: 74.933345734127\n",
      "INFO:VAL loss: 0.8717255455752214, acc: 74.933345734127\n",
      "INFO:VAL loss: 0.8717255455752214, acc: 74.933345734127\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:04, 36.50it/s]\n",
      "INFO:TRAIN loss: 0.07575621859290488, acc: 97.58914877300613\n",
      "INFO:TRAIN loss: 0.07575621859290488, acc: 97.58914877300613\n",
      "INFO:TRAIN loss: 0.07575621859290488, acc: 97.58914877300613\n",
      "INFO:TRAIN loss: 0.07575621859290488, acc: 97.58914877300613\n",
      "INFO:TRAIN loss: 0.07575621859290488, acc: 97.58914877300613\n",
      "INFO:TRAIN loss: 0.07575621859290488, acc: 97.58914877300613\n",
      "INFO:TRAIN loss: 0.07575621859290488, acc: 97.58914877300613\n",
      "24it [00:00, 48.21it/s]\n",
      "INFO:VAL loss: 0.8723654399315517, acc: 74.73183283730155\n",
      "INFO:VAL loss: 0.8723654399315517, acc: 74.73183283730155\n",
      "INFO:VAL loss: 0.8723654399315517, acc: 74.73183283730155\n",
      "INFO:VAL loss: 0.8723654399315517, acc: 74.73183283730155\n",
      "INFO:VAL loss: 0.8723654399315517, acc: 74.73183283730155\n",
      "INFO:VAL loss: 0.8723654399315517, acc: 74.73183283730155\n",
      "INFO:VAL loss: 0.8723654399315517, acc: 74.73183283730155\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:04, 36.22it/s]\n",
      "INFO:TRAIN loss: 0.07436768955156846, acc: 97.7276877008472\n",
      "INFO:TRAIN loss: 0.07436768955156846, acc: 97.7276877008472\n",
      "INFO:TRAIN loss: 0.07436768955156846, acc: 97.7276877008472\n",
      "INFO:TRAIN loss: 0.07436768955156846, acc: 97.7276877008472\n",
      "INFO:TRAIN loss: 0.07436768955156846, acc: 97.7276877008472\n",
      "INFO:TRAIN loss: 0.07436768955156846, acc: 97.7276877008472\n",
      "INFO:TRAIN loss: 0.07436768955156846, acc: 97.7276877008472\n",
      "24it [00:00, 44.46it/s]\n",
      "INFO:VAL loss: 0.8829102131227652, acc: 74.11024305555554\n",
      "INFO:VAL loss: 0.8829102131227652, acc: 74.11024305555554\n",
      "INFO:VAL loss: 0.8829102131227652, acc: 74.11024305555554\n",
      "INFO:VAL loss: 0.8829102131227652, acc: 74.11024305555554\n",
      "INFO:VAL loss: 0.8829102131227652, acc: 74.11024305555554\n",
      "INFO:VAL loss: 0.8829102131227652, acc: 74.11024305555554\n",
      "INFO:VAL loss: 0.8829102131227652, acc: 74.11024305555554\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:04, 37.03it/s]\n",
      "INFO:TRAIN loss: 0.0675547145467046, acc: 97.92419843704349\n",
      "INFO:TRAIN loss: 0.0675547145467046, acc: 97.92419843704349\n",
      "INFO:TRAIN loss: 0.0675547145467046, acc: 97.92419843704349\n",
      "INFO:TRAIN loss: 0.0675547145467046, acc: 97.92419843704349\n",
      "INFO:TRAIN loss: 0.0675547145467046, acc: 97.92419843704349\n",
      "INFO:TRAIN loss: 0.0675547145467046, acc: 97.92419843704349\n",
      "INFO:TRAIN loss: 0.0675547145467046, acc: 97.92419843704349\n",
      "24it [00:00, 48.30it/s]\n",
      "INFO:VAL loss: 0.9214135023454825, acc: 75.06045386904763\n",
      "INFO:VAL loss: 0.9214135023454825, acc: 75.06045386904763\n",
      "INFO:VAL loss: 0.9214135023454825, acc: 75.06045386904763\n",
      "INFO:VAL loss: 0.9214135023454825, acc: 75.06045386904763\n",
      "INFO:VAL loss: 0.9214135023454825, acc: 75.06045386904763\n",
      "INFO:VAL loss: 0.9214135023454825, acc: 75.06045386904763\n",
      "INFO:VAL loss: 0.9214135023454825, acc: 75.06045386904763\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:04, 37.74it/s]\n",
      "INFO:TRAIN loss: 0.06527294868751898, acc: 97.95341257668713\n",
      "INFO:TRAIN loss: 0.06527294868751898, acc: 97.95341257668713\n",
      "INFO:TRAIN loss: 0.06527294868751898, acc: 97.95341257668713\n",
      "INFO:TRAIN loss: 0.06527294868751898, acc: 97.95341257668713\n",
      "INFO:TRAIN loss: 0.06527294868751898, acc: 97.95341257668713\n",
      "INFO:TRAIN loss: 0.06527294868751898, acc: 97.95341257668713\n",
      "INFO:TRAIN loss: 0.06527294868751898, acc: 97.95341257668713\n",
      "24it [00:00, 46.94it/s]\n",
      "INFO:VAL loss: 0.9268764667212963, acc: 74.89769345238095\n",
      "INFO:VAL loss: 0.9268764667212963, acc: 74.89769345238095\n",
      "INFO:VAL loss: 0.9268764667212963, acc: 74.89769345238095\n",
      "INFO:VAL loss: 0.9268764667212963, acc: 74.89769345238095\n",
      "INFO:VAL loss: 0.9268764667212963, acc: 74.89769345238095\n",
      "INFO:VAL loss: 0.9268764667212963, acc: 74.89769345238095\n",
      "INFO:VAL loss: 0.9268764667212963, acc: 74.89769345238095\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:04, 35.05it/s]\n",
      "INFO:TRAIN loss: 0.057640234351249556, acc: 98.17388803680984\n",
      "INFO:TRAIN loss: 0.057640234351249556, acc: 98.17388803680984\n",
      "INFO:TRAIN loss: 0.057640234351249556, acc: 98.17388803680984\n",
      "INFO:TRAIN loss: 0.057640234351249556, acc: 98.17388803680984\n",
      "INFO:TRAIN loss: 0.057640234351249556, acc: 98.17388803680984\n",
      "INFO:TRAIN loss: 0.057640234351249556, acc: 98.17388803680984\n",
      "INFO:TRAIN loss: 0.057640234351249556, acc: 98.17388803680984\n",
      "24it [00:00, 45.09it/s]\n",
      "INFO:VAL loss: 0.9568007538715998, acc: 75.44797867063492\n",
      "INFO:VAL loss: 0.9568007538715998, acc: 75.44797867063492\n",
      "INFO:VAL loss: 0.9568007538715998, acc: 75.44797867063492\n",
      "INFO:VAL loss: 0.9568007538715998, acc: 75.44797867063492\n",
      "INFO:VAL loss: 0.9568007538715998, acc: 75.44797867063492\n",
      "INFO:VAL loss: 0.9568007538715998, acc: 75.44797867063492\n",
      "INFO:VAL loss: 0.9568007538715998, acc: 75.44797867063492\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:04, 36.60it/s]\n",
      "INFO:TRAIN loss: 0.05834140283472698, acc: 98.13075153374231\n",
      "INFO:TRAIN loss: 0.05834140283472698, acc: 98.13075153374231\n",
      "INFO:TRAIN loss: 0.05834140283472698, acc: 98.13075153374231\n",
      "INFO:TRAIN loss: 0.05834140283472698, acc: 98.13075153374231\n",
      "INFO:TRAIN loss: 0.05834140283472698, acc: 98.13075153374231\n",
      "INFO:TRAIN loss: 0.05834140283472698, acc: 98.13075153374231\n",
      "INFO:TRAIN loss: 0.05834140283472698, acc: 98.13075153374231\n",
      "24it [00:00, 45.30it/s]\n",
      "INFO:VAL loss: 0.9421886925896008, acc: 75.16121031746033\n",
      "INFO:VAL loss: 0.9421886925896008, acc: 75.16121031746033\n",
      "INFO:VAL loss: 0.9421886925896008, acc: 75.16121031746033\n",
      "INFO:VAL loss: 0.9421886925896008, acc: 75.16121031746033\n",
      "INFO:VAL loss: 0.9421886925896008, acc: 75.16121031746033\n",
      "INFO:VAL loss: 0.9421886925896008, acc: 75.16121031746033\n",
      "INFO:VAL loss: 0.9421886925896008, acc: 75.16121031746033\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:04, 36.10it/s]\n",
      "INFO:TRAIN loss: 0.05338610656148083, acc: 98.26974693251533\n",
      "INFO:TRAIN loss: 0.05338610656148083, acc: 98.26974693251533\n",
      "INFO:TRAIN loss: 0.05338610656148083, acc: 98.26974693251533\n",
      "INFO:TRAIN loss: 0.05338610656148083, acc: 98.26974693251533\n",
      "INFO:TRAIN loss: 0.05338610656148083, acc: 98.26974693251533\n",
      "INFO:TRAIN loss: 0.05338610656148083, acc: 98.26974693251533\n",
      "INFO:TRAIN loss: 0.05338610656148083, acc: 98.26974693251533\n",
      "24it [00:00, 45.09it/s]\n",
      "INFO:VAL loss: 0.9791459838549297, acc: 75.3534226190476\n",
      "INFO:VAL loss: 0.9791459838549297, acc: 75.3534226190476\n",
      "INFO:VAL loss: 0.9791459838549297, acc: 75.3534226190476\n",
      "INFO:VAL loss: 0.9791459838549297, acc: 75.3534226190476\n",
      "INFO:VAL loss: 0.9791459838549297, acc: 75.3534226190476\n",
      "INFO:VAL loss: 0.9791459838549297, acc: 75.3534226190476\n",
      "INFO:VAL loss: 0.9791459838549297, acc: 75.3534226190476\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:04, 35.71it/s]\n",
      "INFO:TRAIN loss: 0.05003838915309294, acc: 98.42266469471222\n",
      "INFO:TRAIN loss: 0.05003838915309294, acc: 98.42266469471222\n",
      "INFO:TRAIN loss: 0.05003838915309294, acc: 98.42266469471222\n",
      "INFO:TRAIN loss: 0.05003838915309294, acc: 98.42266469471222\n",
      "INFO:TRAIN loss: 0.05003838915309294, acc: 98.42266469471222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN loss: 0.05003838915309294, acc: 98.42266469471222\n",
      "INFO:TRAIN loss: 0.05003838915309294, acc: 98.42266469471222\n",
      "24it [00:00, 47.86it/s]\n",
      "INFO:VAL loss: 1.0068967404464881, acc: 75.41852678571426\n",
      "INFO:VAL loss: 1.0068967404464881, acc: 75.41852678571426\n",
      "INFO:VAL loss: 1.0068967404464881, acc: 75.41852678571426\n",
      "INFO:VAL loss: 1.0068967404464881, acc: 75.41852678571426\n",
      "INFO:VAL loss: 1.0068967404464881, acc: 75.41852678571426\n",
      "INFO:VAL loss: 1.0068967404464881, acc: 75.41852678571426\n",
      "INFO:VAL loss: 1.0068967404464881, acc: 75.41852678571426\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:04, 36.40it/s]\n",
      "INFO:TRAIN loss: 0.046544380180332016, acc: 98.47584355828229\n",
      "INFO:TRAIN loss: 0.046544380180332016, acc: 98.47584355828229\n",
      "INFO:TRAIN loss: 0.046544380180332016, acc: 98.47584355828229\n",
      "INFO:TRAIN loss: 0.046544380180332016, acc: 98.47584355828229\n",
      "INFO:TRAIN loss: 0.046544380180332016, acc: 98.47584355828229\n",
      "INFO:TRAIN loss: 0.046544380180332016, acc: 98.47584355828229\n",
      "INFO:TRAIN loss: 0.046544380180332016, acc: 98.47584355828229\n",
      "24it [00:00, 44.26it/s]\n",
      "INFO:VAL loss: 1.0077666727205117, acc: 75.06045386904763\n",
      "INFO:VAL loss: 1.0077666727205117, acc: 75.06045386904763\n",
      "INFO:VAL loss: 1.0077666727205117, acc: 75.06045386904763\n",
      "INFO:VAL loss: 1.0077666727205117, acc: 75.06045386904763\n",
      "INFO:VAL loss: 1.0077666727205117, acc: 75.06045386904763\n",
      "INFO:VAL loss: 1.0077666727205117, acc: 75.06045386904763\n",
      "INFO:VAL loss: 1.0077666727205117, acc: 75.06045386904763\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:04, 37.01it/s]\n",
      "INFO:TRAIN loss: 0.04531995455043082, acc: 98.57170245398774\n",
      "INFO:TRAIN loss: 0.04531995455043082, acc: 98.57170245398774\n",
      "INFO:TRAIN loss: 0.04531995455043082, acc: 98.57170245398774\n",
      "INFO:TRAIN loss: 0.04531995455043082, acc: 98.57170245398774\n",
      "INFO:TRAIN loss: 0.04531995455043082, acc: 98.57170245398774\n",
      "INFO:TRAIN loss: 0.04531995455043082, acc: 98.57170245398774\n",
      "INFO:TRAIN loss: 0.04531995455043082, acc: 98.57170245398774\n",
      "24it [00:00, 46.96it/s]\n",
      "INFO:VAL loss: 1.0282740208009877, acc: 75.61693948412697\n",
      "INFO:VAL loss: 1.0282740208009877, acc: 75.61693948412697\n",
      "INFO:VAL loss: 1.0282740208009877, acc: 75.61693948412697\n",
      "INFO:VAL loss: 1.0282740208009877, acc: 75.61693948412697\n",
      "INFO:VAL loss: 1.0282740208009877, acc: 75.61693948412697\n",
      "INFO:VAL loss: 1.0282740208009877, acc: 75.61693948412697\n",
      "INFO:VAL loss: 1.0282740208009877, acc: 75.61693948412697\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:04, 35.63it/s]\n",
      "INFO:TRAIN loss: 0.046758950487967625, acc: 98.45621530820915\n",
      "INFO:TRAIN loss: 0.046758950487967625, acc: 98.45621530820915\n",
      "INFO:TRAIN loss: 0.046758950487967625, acc: 98.45621530820915\n",
      "INFO:TRAIN loss: 0.046758950487967625, acc: 98.45621530820915\n",
      "INFO:TRAIN loss: 0.046758950487967625, acc: 98.45621530820915\n",
      "INFO:TRAIN loss: 0.046758950487967625, acc: 98.45621530820915\n",
      "INFO:TRAIN loss: 0.046758950487967625, acc: 98.45621530820915\n",
      "24it [00:00, 46.86it/s]\n",
      "INFO:VAL loss: 1.0254324146856864, acc: 75.55183531746032\n",
      "INFO:VAL loss: 1.0254324146856864, acc: 75.55183531746032\n",
      "INFO:VAL loss: 1.0254324146856864, acc: 75.55183531746032\n",
      "INFO:VAL loss: 1.0254324146856864, acc: 75.55183531746032\n",
      "INFO:VAL loss: 1.0254324146856864, acc: 75.55183531746032\n",
      "INFO:VAL loss: 1.0254324146856864, acc: 75.55183531746032\n",
      "INFO:VAL loss: 1.0254324146856864, acc: 75.55183531746032\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:04, 36.32it/s]\n",
      "INFO:TRAIN loss: 0.04424700040964446, acc: 98.5573236196318\n",
      "INFO:TRAIN loss: 0.04424700040964446, acc: 98.5573236196318\n",
      "INFO:TRAIN loss: 0.04424700040964446, acc: 98.5573236196318\n",
      "INFO:TRAIN loss: 0.04424700040964446, acc: 98.5573236196318\n",
      "INFO:TRAIN loss: 0.04424700040964446, acc: 98.5573236196318\n",
      "INFO:TRAIN loss: 0.04424700040964446, acc: 98.5573236196318\n",
      "INFO:TRAIN loss: 0.04424700040964446, acc: 98.5573236196318\n",
      "24it [00:00, 47.32it/s]\n",
      "INFO:VAL loss: 1.016402691602707, acc: 75.5518353174603\n",
      "INFO:VAL loss: 1.016402691602707, acc: 75.5518353174603\n",
      "INFO:VAL loss: 1.016402691602707, acc: 75.5518353174603\n",
      "INFO:VAL loss: 1.016402691602707, acc: 75.5518353174603\n",
      "INFO:VAL loss: 1.016402691602707, acc: 75.5518353174603\n",
      "INFO:VAL loss: 1.016402691602707, acc: 75.5518353174603\n",
      "INFO:VAL loss: 1.016402691602707, acc: 75.5518353174603\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:04, 36.76it/s]\n",
      "INFO:TRAIN loss: 0.042501830710155265, acc: 98.62442484662574\n",
      "INFO:TRAIN loss: 0.042501830710155265, acc: 98.62442484662574\n",
      "INFO:TRAIN loss: 0.042501830710155265, acc: 98.62442484662574\n",
      "INFO:TRAIN loss: 0.042501830710155265, acc: 98.62442484662574\n",
      "INFO:TRAIN loss: 0.042501830710155265, acc: 98.62442484662574\n",
      "INFO:TRAIN loss: 0.042501830710155265, acc: 98.62442484662574\n",
      "INFO:TRAIN loss: 0.042501830710155265, acc: 98.62442484662574\n",
      "24it [00:00, 47.66it/s]\n",
      "INFO:VAL loss: 1.0808157175779343, acc: 76.33618551587301\n",
      "INFO:VAL loss: 1.0808157175779343, acc: 76.33618551587301\n",
      "INFO:VAL loss: 1.0808157175779343, acc: 76.33618551587301\n",
      "INFO:VAL loss: 1.0808157175779343, acc: 76.33618551587301\n",
      "INFO:VAL loss: 1.0808157175779343, acc: 76.33618551587301\n",
      "INFO:VAL loss: 1.0808157175779343, acc: 76.33618551587301\n",
      "INFO:VAL loss: 1.0808157175779343, acc: 76.33618551587301\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:04, 36.13it/s]\n",
      "INFO:TRAIN loss: 0.04312918000951684, acc: 98.5812883435583\n",
      "INFO:TRAIN loss: 0.04312918000951684, acc: 98.5812883435583\n",
      "INFO:TRAIN loss: 0.04312918000951684, acc: 98.5812883435583\n",
      "INFO:TRAIN loss: 0.04312918000951684, acc: 98.5812883435583\n",
      "INFO:TRAIN loss: 0.04312918000951684, acc: 98.5812883435583\n",
      "INFO:TRAIN loss: 0.04312918000951684, acc: 98.5812883435583\n",
      "INFO:TRAIN loss: 0.04312918000951684, acc: 98.5812883435583\n",
      "24it [00:00, 43.49it/s]\n",
      "INFO:VAL loss: 1.056381958226363, acc: 75.18756200396824\n",
      "INFO:VAL loss: 1.056381958226363, acc: 75.18756200396824\n",
      "INFO:VAL loss: 1.056381958226363, acc: 75.18756200396824\n",
      "INFO:VAL loss: 1.056381958226363, acc: 75.18756200396824\n",
      "INFO:VAL loss: 1.056381958226363, acc: 75.18756200396824\n",
      "INFO:VAL loss: 1.056381958226363, acc: 75.18756200396824\n",
      "INFO:VAL loss: 1.056381958226363, acc: 75.18756200396824\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:04, 35.31it/s]\n",
      "INFO:TRAIN loss: 0.04070611976578464, acc: 98.63401073619629\n",
      "INFO:TRAIN loss: 0.04070611976578464, acc: 98.63401073619629\n",
      "INFO:TRAIN loss: 0.04070611976578464, acc: 98.63401073619629\n",
      "INFO:TRAIN loss: 0.04070611976578464, acc: 98.63401073619629\n",
      "INFO:TRAIN loss: 0.04070611976578464, acc: 98.63401073619629\n",
      "INFO:TRAIN loss: 0.04070611976578464, acc: 98.63401073619629\n",
      "INFO:TRAIN loss: 0.04070611976578464, acc: 98.63401073619629\n",
      "24it [00:00, 46.22it/s]\n",
      "INFO:VAL loss: 1.0462215977410476, acc: 75.68204365079366\n",
      "INFO:VAL loss: 1.0462215977410476, acc: 75.68204365079366\n",
      "INFO:VAL loss: 1.0462215977410476, acc: 75.68204365079366\n",
      "INFO:VAL loss: 1.0462215977410476, acc: 75.68204365079366\n",
      "INFO:VAL loss: 1.0462215977410476, acc: 75.68204365079366\n",
      "INFO:VAL loss: 1.0462215977410476, acc: 75.68204365079366\n",
      "INFO:VAL loss: 1.0462215977410476, acc: 75.68204365079366\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:04, 36.43it/s]\n",
      "INFO:TRAIN loss: 0.039634048475946745, acc: 98.70111196319016\n",
      "INFO:TRAIN loss: 0.039634048475946745, acc: 98.70111196319016\n",
      "INFO:TRAIN loss: 0.039634048475946745, acc: 98.70111196319016\n",
      "INFO:TRAIN loss: 0.039634048475946745, acc: 98.70111196319016\n",
      "INFO:TRAIN loss: 0.039634048475946745, acc: 98.70111196319016\n",
      "INFO:TRAIN loss: 0.039634048475946745, acc: 98.70111196319016\n",
      "INFO:TRAIN loss: 0.039634048475946745, acc: 98.70111196319016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 45.14it/s]\n",
      "INFO:VAL loss: 1.0771798330048719, acc: 75.847904265873\n",
      "INFO:VAL loss: 1.0771798330048719, acc: 75.847904265873\n",
      "INFO:VAL loss: 1.0771798330048719, acc: 75.847904265873\n",
      "INFO:VAL loss: 1.0771798330048719, acc: 75.847904265873\n",
      "INFO:VAL loss: 1.0771798330048719, acc: 75.847904265873\n",
      "INFO:VAL loss: 1.0771798330048719, acc: 75.847904265873\n",
      "INFO:VAL loss: 1.0771798330048719, acc: 75.847904265873\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:04, 36.26it/s]\n",
      "INFO:TRAIN loss: 0.04046271959079736, acc: 98.6531825153375\n",
      "INFO:TRAIN loss: 0.04046271959079736, acc: 98.6531825153375\n",
      "INFO:TRAIN loss: 0.04046271959079736, acc: 98.6531825153375\n",
      "INFO:TRAIN loss: 0.04046271959079736, acc: 98.6531825153375\n",
      "INFO:TRAIN loss: 0.04046271959079736, acc: 98.6531825153375\n",
      "INFO:TRAIN loss: 0.04046271959079736, acc: 98.6531825153375\n",
      "INFO:TRAIN loss: 0.04046271959079736, acc: 98.6531825153375\n",
      "24it [00:00, 44.64it/s]\n",
      "INFO:VAL loss: 1.1148701719939709, acc: 75.9068080357143\n",
      "INFO:VAL loss: 1.1148701719939709, acc: 75.9068080357143\n",
      "INFO:VAL loss: 1.1148701719939709, acc: 75.9068080357143\n",
      "INFO:VAL loss: 1.1148701719939709, acc: 75.9068080357143\n",
      "INFO:VAL loss: 1.1148701719939709, acc: 75.9068080357143\n",
      "INFO:VAL loss: 1.1148701719939709, acc: 75.9068080357143\n",
      "INFO:VAL loss: 1.1148701719939709, acc: 75.9068080357143\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:04, 35.21it/s]\n",
      "INFO:TRAIN loss: 0.03788157778740661, acc: 98.79697085889582\n",
      "INFO:TRAIN loss: 0.03788157778740661, acc: 98.79697085889582\n",
      "INFO:TRAIN loss: 0.03788157778740661, acc: 98.79697085889582\n",
      "INFO:TRAIN loss: 0.03788157778740661, acc: 98.79697085889582\n",
      "INFO:TRAIN loss: 0.03788157778740661, acc: 98.79697085889582\n",
      "INFO:TRAIN loss: 0.03788157778740661, acc: 98.79697085889582\n",
      "INFO:TRAIN loss: 0.03788157778740661, acc: 98.79697085889582\n",
      "24it [00:00, 47.22it/s]\n",
      "INFO:VAL loss: 1.1092806681990623, acc: 75.35652281746033\n",
      "INFO:VAL loss: 1.1092806681990623, acc: 75.35652281746033\n",
      "INFO:VAL loss: 1.1092806681990623, acc: 75.35652281746033\n",
      "INFO:VAL loss: 1.1092806681990623, acc: 75.35652281746033\n",
      "INFO:VAL loss: 1.1092806681990623, acc: 75.35652281746033\n",
      "INFO:VAL loss: 1.1092806681990623, acc: 75.35652281746033\n",
      "INFO:VAL loss: 1.1092806681990623, acc: 75.35652281746033\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:04, 36.12it/s]\n",
      "INFO:TRAIN loss: 0.03763377395647068, acc: 98.7298696319018\n",
      "INFO:TRAIN loss: 0.03763377395647068, acc: 98.7298696319018\n",
      "INFO:TRAIN loss: 0.03763377395647068, acc: 98.7298696319018\n",
      "INFO:TRAIN loss: 0.03763377395647068, acc: 98.7298696319018\n",
      "INFO:TRAIN loss: 0.03763377395647068, acc: 98.7298696319018\n",
      "INFO:TRAIN loss: 0.03763377395647068, acc: 98.7298696319018\n",
      "INFO:TRAIN loss: 0.03763377395647068, acc: 98.7298696319018\n",
      "24it [00:00, 42.58it/s]\n",
      "INFO:VAL loss: 1.1179165206849575, acc: 76.69425843253967\n",
      "INFO:VAL loss: 1.1179165206849575, acc: 76.69425843253967\n",
      "INFO:VAL loss: 1.1179165206849575, acc: 76.69425843253967\n",
      "INFO:VAL loss: 1.1179165206849575, acc: 76.69425843253967\n",
      "INFO:VAL loss: 1.1179165206849575, acc: 76.69425843253967\n",
      "INFO:VAL loss: 1.1179165206849575, acc: 76.69425843253967\n",
      "INFO:VAL loss: 1.1179165206849575, acc: 76.69425843253967\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:04, 35.97it/s]\n",
      "INFO:TRAIN loss: 0.03693101882214654, acc: 98.64359662576688\n",
      "INFO:TRAIN loss: 0.03693101882214654, acc: 98.64359662576688\n",
      "INFO:TRAIN loss: 0.03693101882214654, acc: 98.64359662576688\n",
      "INFO:TRAIN loss: 0.03693101882214654, acc: 98.64359662576688\n",
      "INFO:TRAIN loss: 0.03693101882214654, acc: 98.64359662576688\n",
      "INFO:TRAIN loss: 0.03693101882214654, acc: 98.64359662576688\n",
      "INFO:TRAIN loss: 0.03693101882214654, acc: 98.64359662576688\n",
      "24it [00:00, 44.51it/s]\n",
      "INFO:VAL loss: 1.1212959500650566, acc: 76.36563740079366\n",
      "INFO:VAL loss: 1.1212959500650566, acc: 76.36563740079366\n",
      "INFO:VAL loss: 1.1212959500650566, acc: 76.36563740079366\n",
      "INFO:VAL loss: 1.1212959500650566, acc: 76.36563740079366\n",
      "INFO:VAL loss: 1.1212959500650566, acc: 76.36563740079366\n",
      "INFO:VAL loss: 1.1212959500650566, acc: 76.36563740079366\n",
      "INFO:VAL loss: 1.1212959500650566, acc: 76.36563740079366\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:04, 35.73it/s]\n",
      "INFO:TRAIN loss: 0.034238205851267085, acc: 98.88803680981596\n",
      "INFO:TRAIN loss: 0.034238205851267085, acc: 98.88803680981596\n",
      "INFO:TRAIN loss: 0.034238205851267085, acc: 98.88803680981596\n",
      "INFO:TRAIN loss: 0.034238205851267085, acc: 98.88803680981596\n",
      "INFO:TRAIN loss: 0.034238205851267085, acc: 98.88803680981596\n",
      "INFO:TRAIN loss: 0.034238205851267085, acc: 98.88803680981596\n",
      "INFO:TRAIN loss: 0.034238205851267085, acc: 98.88803680981596\n",
      "24it [00:00, 46.33it/s]\n",
      "INFO:VAL loss: 1.1410293895751238, acc: 76.00136408730155\n",
      "INFO:VAL loss: 1.1410293895751238, acc: 76.00136408730155\n",
      "INFO:VAL loss: 1.1410293895751238, acc: 76.00136408730155\n",
      "INFO:VAL loss: 1.1410293895751238, acc: 76.00136408730155\n",
      "INFO:VAL loss: 1.1410293895751238, acc: 76.00136408730155\n",
      "INFO:VAL loss: 1.1410293895751238, acc: 76.00136408730155\n",
      "INFO:VAL loss: 1.1410293895751238, acc: 76.00136408730155\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:04, 36.36it/s]\n",
      "INFO:TRAIN loss: 0.033985941436575955, acc: 98.84444383581653\n",
      "INFO:TRAIN loss: 0.033985941436575955, acc: 98.84444383581653\n",
      "INFO:TRAIN loss: 0.033985941436575955, acc: 98.84444383581653\n",
      "INFO:TRAIN loss: 0.033985941436575955, acc: 98.84444383581653\n",
      "INFO:TRAIN loss: 0.033985941436575955, acc: 98.84444383581653\n",
      "INFO:TRAIN loss: 0.033985941436575955, acc: 98.84444383581653\n",
      "INFO:TRAIN loss: 0.033985941436575955, acc: 98.84444383581653\n",
      "24it [00:00, 46.30it/s]\n",
      "INFO:VAL loss: 1.1310319639742374, acc: 76.30053323412699\n",
      "INFO:VAL loss: 1.1310319639742374, acc: 76.30053323412699\n",
      "INFO:VAL loss: 1.1310319639742374, acc: 76.30053323412699\n",
      "INFO:VAL loss: 1.1310319639742374, acc: 76.30053323412699\n",
      "INFO:VAL loss: 1.1310319639742374, acc: 76.30053323412699\n",
      "INFO:VAL loss: 1.1310319639742374, acc: 76.30053323412699\n",
      "INFO:VAL loss: 1.1310319639742374, acc: 76.30053323412699\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:04, 37.23it/s]\n",
      "INFO:TRAIN loss: 0.03775204697543859, acc: 98.68673312883436\n",
      "INFO:TRAIN loss: 0.03775204697543859, acc: 98.68673312883436\n",
      "INFO:TRAIN loss: 0.03775204697543859, acc: 98.68673312883436\n",
      "INFO:TRAIN loss: 0.03775204697543859, acc: 98.68673312883436\n",
      "INFO:TRAIN loss: 0.03775204697543859, acc: 98.68673312883436\n",
      "INFO:TRAIN loss: 0.03775204697543859, acc: 98.68673312883436\n",
      "INFO:TRAIN loss: 0.03775204697543859, acc: 98.68673312883436\n",
      "24it [00:00, 47.90it/s]\n",
      "INFO:VAL loss: 1.1222946122288704, acc: 76.495845734127\n",
      "INFO:VAL loss: 1.1222946122288704, acc: 76.495845734127\n",
      "INFO:VAL loss: 1.1222946122288704, acc: 76.495845734127\n",
      "INFO:VAL loss: 1.1222946122288704, acc: 76.495845734127\n",
      "INFO:VAL loss: 1.1222946122288704, acc: 76.495845734127\n",
      "INFO:VAL loss: 1.1222946122288704, acc: 76.495845734127\n",
      "INFO:VAL loss: 1.1222946122288704, acc: 76.495845734127\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:04, 35.86it/s]\n",
      "INFO:TRAIN loss: 0.034170697513179284, acc: 98.90241564417182\n",
      "INFO:TRAIN loss: 0.034170697513179284, acc: 98.90241564417182\n",
      "INFO:TRAIN loss: 0.034170697513179284, acc: 98.90241564417182\n",
      "INFO:TRAIN loss: 0.034170697513179284, acc: 98.90241564417182\n",
      "INFO:TRAIN loss: 0.034170697513179284, acc: 98.90241564417182\n",
      "INFO:TRAIN loss: 0.034170697513179284, acc: 98.90241564417182\n",
      "INFO:TRAIN loss: 0.034170697513179284, acc: 98.90241564417182\n",
      "24it [00:00, 44.78it/s]\n",
      "INFO:VAL loss: 1.151241660118103, acc: 74.99844990079364\n",
      "INFO:VAL loss: 1.151241660118103, acc: 74.99844990079364\n",
      "INFO:VAL loss: 1.151241660118103, acc: 74.99844990079364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:VAL loss: 1.151241660118103, acc: 74.99844990079364\n",
      "INFO:VAL loss: 1.151241660118103, acc: 74.99844990079364\n",
      "INFO:VAL loss: 1.151241660118103, acc: 74.99844990079364\n",
      "INFO:VAL loss: 1.151241660118103, acc: 74.99844990079364\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:04, 34.84it/s]\n",
      "INFO:TRAIN loss: 0.037553199758307516, acc: 98.68673312883435\n",
      "INFO:TRAIN loss: 0.037553199758307516, acc: 98.68673312883435\n",
      "INFO:TRAIN loss: 0.037553199758307516, acc: 98.68673312883435\n",
      "INFO:TRAIN loss: 0.037553199758307516, acc: 98.68673312883435\n",
      "INFO:TRAIN loss: 0.037553199758307516, acc: 98.68673312883435\n",
      "INFO:TRAIN loss: 0.037553199758307516, acc: 98.68673312883435\n",
      "INFO:TRAIN loss: 0.037553199758307516, acc: 98.68673312883435\n",
      "24it [00:00, 46.53it/s]\n",
      "INFO:VAL loss: 1.1635462331275144, acc: 75.38907490079364\n",
      "INFO:VAL loss: 1.1635462331275144, acc: 75.38907490079364\n",
      "INFO:VAL loss: 1.1635462331275144, acc: 75.38907490079364\n",
      "INFO:VAL loss: 1.1635462331275144, acc: 75.38907490079364\n",
      "INFO:VAL loss: 1.1635462331275144, acc: 75.38907490079364\n",
      "INFO:VAL loss: 1.1635462331275144, acc: 75.38907490079364\n",
      "INFO:VAL loss: 1.1635462331275144, acc: 75.38907490079364\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:04, 36.18it/s]\n",
      "INFO:TRAIN loss: 0.03368123925570968, acc: 98.78259202453987\n",
      "INFO:TRAIN loss: 0.03368123925570968, acc: 98.78259202453987\n",
      "INFO:TRAIN loss: 0.03368123925570968, acc: 98.78259202453987\n",
      "INFO:TRAIN loss: 0.03368123925570968, acc: 98.78259202453987\n",
      "INFO:TRAIN loss: 0.03368123925570968, acc: 98.78259202453987\n",
      "INFO:TRAIN loss: 0.03368123925570968, acc: 98.78259202453987\n",
      "INFO:TRAIN loss: 0.03368123925570968, acc: 98.78259202453987\n",
      "24it [00:00, 45.12it/s]\n",
      "INFO:VAL loss: 1.177414880444606, acc: 75.81225198412699\n",
      "INFO:VAL loss: 1.177414880444606, acc: 75.81225198412699\n",
      "INFO:VAL loss: 1.177414880444606, acc: 75.81225198412699\n",
      "INFO:VAL loss: 1.177414880444606, acc: 75.81225198412699\n",
      "INFO:VAL loss: 1.177414880444606, acc: 75.81225198412699\n",
      "INFO:VAL loss: 1.177414880444606, acc: 75.81225198412699\n",
      "INFO:VAL loss: 1.177414880444606, acc: 75.81225198412699\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:04, 35.41it/s]\n",
      "INFO:TRAIN loss: 0.030859243383265435, acc: 98.90241564417178\n",
      "INFO:TRAIN loss: 0.030859243383265435, acc: 98.90241564417178\n",
      "INFO:TRAIN loss: 0.030859243383265435, acc: 98.90241564417178\n",
      "INFO:TRAIN loss: 0.030859243383265435, acc: 98.90241564417178\n",
      "INFO:TRAIN loss: 0.030859243383265435, acc: 98.90241564417178\n",
      "INFO:TRAIN loss: 0.030859243383265435, acc: 98.90241564417178\n",
      "INFO:TRAIN loss: 0.030859243383265435, acc: 98.90241564417178\n",
      "24it [00:00, 46.41it/s]\n",
      "INFO:VAL loss: 1.185952658454577, acc: 76.72991071428574\n",
      "INFO:VAL loss: 1.185952658454577, acc: 76.72991071428574\n",
      "INFO:VAL loss: 1.185952658454577, acc: 76.72991071428574\n",
      "INFO:VAL loss: 1.185952658454577, acc: 76.72991071428574\n",
      "INFO:VAL loss: 1.185952658454577, acc: 76.72991071428574\n",
      "INFO:VAL loss: 1.185952658454577, acc: 76.72991071428574\n",
      "INFO:VAL loss: 1.185952658454577, acc: 76.72991071428574\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:04, 35.12it/s]\n",
      "INFO:TRAIN loss: 0.030944809964658013, acc: 98.87845092024546\n",
      "INFO:TRAIN loss: 0.030944809964658013, acc: 98.87845092024546\n",
      "INFO:TRAIN loss: 0.030944809964658013, acc: 98.87845092024546\n",
      "INFO:TRAIN loss: 0.030944809964658013, acc: 98.87845092024546\n",
      "INFO:TRAIN loss: 0.030944809964658013, acc: 98.87845092024546\n",
      "INFO:TRAIN loss: 0.030944809964658013, acc: 98.87845092024546\n",
      "INFO:TRAIN loss: 0.030944809964658013, acc: 98.87845092024546\n",
      "24it [00:00, 47.70it/s]\n",
      "INFO:VAL loss: 1.19902915507555, acc: 76.6322544642857\n",
      "INFO:VAL loss: 1.19902915507555, acc: 76.6322544642857\n",
      "INFO:VAL loss: 1.19902915507555, acc: 76.6322544642857\n",
      "INFO:VAL loss: 1.19902915507555, acc: 76.6322544642857\n",
      "INFO:VAL loss: 1.19902915507555, acc: 76.6322544642857\n",
      "INFO:VAL loss: 1.19902915507555, acc: 76.6322544642857\n",
      "INFO:VAL loss: 1.19902915507555, acc: 76.6322544642857\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:04, 36.95it/s]\n",
      "INFO:TRAIN loss: 0.03031147143980659, acc: 98.86886503067487\n",
      "INFO:TRAIN loss: 0.03031147143980659, acc: 98.86886503067487\n",
      "INFO:TRAIN loss: 0.03031147143980659, acc: 98.86886503067487\n",
      "INFO:TRAIN loss: 0.03031147143980659, acc: 98.86886503067487\n",
      "INFO:TRAIN loss: 0.03031147143980659, acc: 98.86886503067487\n",
      "INFO:TRAIN loss: 0.03031147143980659, acc: 98.86886503067487\n",
      "INFO:TRAIN loss: 0.03031147143980659, acc: 98.86886503067487\n",
      "24it [00:00, 45.94it/s]\n",
      "INFO:VAL loss: 1.1838532090187073, acc: 75.64949156746032\n",
      "INFO:VAL loss: 1.1838532090187073, acc: 75.64949156746032\n",
      "INFO:VAL loss: 1.1838532090187073, acc: 75.64949156746032\n",
      "INFO:VAL loss: 1.1838532090187073, acc: 75.64949156746032\n",
      "INFO:VAL loss: 1.1838532090187073, acc: 75.64949156746032\n",
      "INFO:VAL loss: 1.1838532090187073, acc: 75.64949156746032\n",
      "INFO:VAL loss: 1.1838532090187073, acc: 75.64949156746032\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:04, 36.83it/s]\n",
      "INFO:TRAIN loss: 0.02783491295630947, acc: 98.98389570552152\n",
      "INFO:TRAIN loss: 0.02783491295630947, acc: 98.98389570552152\n",
      "INFO:TRAIN loss: 0.02783491295630947, acc: 98.98389570552152\n",
      "INFO:TRAIN loss: 0.02783491295630947, acc: 98.98389570552152\n",
      "INFO:TRAIN loss: 0.02783491295630947, acc: 98.98389570552152\n",
      "INFO:TRAIN loss: 0.02783491295630947, acc: 98.98389570552152\n",
      "INFO:TRAIN loss: 0.02783491295630947, acc: 98.98389570552152\n",
      "24it [00:00, 48.08it/s]\n",
      "INFO:VAL loss: 1.2176454613606134, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2176454613606134, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2176454613606134, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2176454613606134, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2176454613606134, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2176454613606134, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2176454613606134, acc: 75.32397073412699\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:04, 37.98it/s]\n",
      "INFO:TRAIN loss: 0.02743426585667109, acc: 99.02703220858893\n",
      "INFO:TRAIN loss: 0.02743426585667109, acc: 99.02703220858893\n",
      "INFO:TRAIN loss: 0.02743426585667109, acc: 99.02703220858893\n",
      "INFO:TRAIN loss: 0.02743426585667109, acc: 99.02703220858893\n",
      "INFO:TRAIN loss: 0.02743426585667109, acc: 99.02703220858893\n",
      "INFO:TRAIN loss: 0.02743426585667109, acc: 99.02703220858893\n",
      "INFO:TRAIN loss: 0.02743426585667109, acc: 99.02703220858893\n",
      "24it [00:00, 48.15it/s]\n",
      "INFO:VAL loss: 1.2324561638136704, acc: 75.41852678571428\n",
      "INFO:VAL loss: 1.2324561638136704, acc: 75.41852678571428\n",
      "INFO:VAL loss: 1.2324561638136704, acc: 75.41852678571428\n",
      "INFO:VAL loss: 1.2324561638136704, acc: 75.41852678571428\n",
      "INFO:VAL loss: 1.2324561638136704, acc: 75.41852678571428\n",
      "INFO:VAL loss: 1.2324561638136704, acc: 75.41852678571428\n",
      "INFO:VAL loss: 1.2324561638136704, acc: 75.41852678571428\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:04, 38.05it/s]\n",
      "INFO:TRAIN loss: 0.03291175514173927, acc: 98.85927914110425\n",
      "INFO:TRAIN loss: 0.03291175514173927, acc: 98.85927914110425\n",
      "INFO:TRAIN loss: 0.03291175514173927, acc: 98.85927914110425\n",
      "INFO:TRAIN loss: 0.03291175514173927, acc: 98.85927914110425\n",
      "INFO:TRAIN loss: 0.03291175514173927, acc: 98.85927914110425\n",
      "INFO:TRAIN loss: 0.03291175514173927, acc: 98.85927914110425\n",
      "INFO:TRAIN loss: 0.03291175514173927, acc: 98.85927914110425\n",
      "24it [00:00, 48.64it/s]\n",
      "INFO:VAL loss: 1.2760142485300698, acc: 75.3177703373016\n",
      "INFO:VAL loss: 1.2760142485300698, acc: 75.3177703373016\n",
      "INFO:VAL loss: 1.2760142485300698, acc: 75.3177703373016\n",
      "INFO:VAL loss: 1.2760142485300698, acc: 75.3177703373016\n",
      "INFO:VAL loss: 1.2760142485300698, acc: 75.3177703373016\n",
      "INFO:VAL loss: 1.2760142485300698, acc: 75.3177703373016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:VAL loss: 1.2760142485300698, acc: 75.3177703373016\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:04, 38.00it/s]\n",
      "INFO:TRAIN loss: 0.02913666240002481, acc: 98.94075920245399\n",
      "INFO:TRAIN loss: 0.02913666240002481, acc: 98.94075920245399\n",
      "INFO:TRAIN loss: 0.02913666240002481, acc: 98.94075920245399\n",
      "INFO:TRAIN loss: 0.02913666240002481, acc: 98.94075920245399\n",
      "INFO:TRAIN loss: 0.02913666240002481, acc: 98.94075920245399\n",
      "INFO:TRAIN loss: 0.02913666240002481, acc: 98.94075920245399\n",
      "INFO:TRAIN loss: 0.02913666240002481, acc: 98.94075920245399\n",
      "24it [00:00, 48.40it/s]\n",
      "INFO:VAL loss: 1.2462165243923664, acc: 75.68204365079364\n",
      "INFO:VAL loss: 1.2462165243923664, acc: 75.68204365079364\n",
      "INFO:VAL loss: 1.2462165243923664, acc: 75.68204365079364\n",
      "INFO:VAL loss: 1.2462165243923664, acc: 75.68204365079364\n",
      "INFO:VAL loss: 1.2462165243923664, acc: 75.68204365079364\n",
      "INFO:VAL loss: 1.2462165243923664, acc: 75.68204365079364\n",
      "INFO:VAL loss: 1.2462165243923664, acc: 75.68204365079364\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:04, 38.08it/s]\n",
      "INFO:TRAIN loss: 0.03015775425199625, acc: 99.01744631901835\n",
      "INFO:TRAIN loss: 0.03015775425199625, acc: 99.01744631901835\n",
      "INFO:TRAIN loss: 0.03015775425199625, acc: 99.01744631901835\n",
      "INFO:TRAIN loss: 0.03015775425199625, acc: 99.01744631901835\n",
      "INFO:TRAIN loss: 0.03015775425199625, acc: 99.01744631901835\n",
      "INFO:TRAIN loss: 0.03015775425199625, acc: 99.01744631901835\n",
      "INFO:TRAIN loss: 0.03015775425199625, acc: 99.01744631901835\n",
      "24it [00:00, 45.11it/s]\n",
      "INFO:VAL loss: 1.2330947356919448, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2330947356919448, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2330947356919448, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2330947356919448, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2330947356919448, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2330947356919448, acc: 75.32397073412699\n",
      "INFO:VAL loss: 1.2330947356919448, acc: 75.32397073412699\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "163it [00:04, 37.91it/s]\n",
      "INFO:TRAIN loss: 0.028601328600048034, acc: 98.95513803680986\n",
      "INFO:TRAIN loss: 0.028601328600048034, acc: 98.95513803680986\n",
      "INFO:TRAIN loss: 0.028601328600048034, acc: 98.95513803680986\n",
      "INFO:TRAIN loss: 0.028601328600048034, acc: 98.95513803680986\n",
      "INFO:TRAIN loss: 0.028601328600048034, acc: 98.95513803680986\n",
      "INFO:TRAIN loss: 0.028601328600048034, acc: 98.95513803680986\n",
      "INFO:TRAIN loss: 0.028601328600048034, acc: 98.95513803680986\n",
      "24it [00:00, 48.45it/s]\n",
      "INFO:VAL loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:VAL loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:VAL loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:VAL loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:VAL loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:VAL loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:VAL loss: 1.23216741407911, acc: 74.93334573412699\n",
      "24it [00:00, 48.36it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:\n",
      "\n",
      "TEST loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:\n",
      "\n",
      "TEST loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:\n",
      "\n",
      "TEST loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:\n",
      "\n",
      "TEST loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:\n",
      "\n",
      "TEST loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:\n",
      "\n",
      "TEST loss: 1.23216741407911, acc: 74.93334573412699\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.5844922546594423, 0.48890001916446557, 0.435949481520916, 0.38943886702046054, 0.3399630057299797, 0.2906636262049704, 0.2507701683446673, 0.20844713273955276, 0.17704325237888496, 0.15158120254797436, 0.131700625426016, 0.1134038314314708, 0.0984821757244552, 0.09294591581254648, 0.08557747846092184, 0.07575621859290488, 0.07436768955156846, 0.0675547145467046, 0.06527294868751898, 0.057640234351249556, 0.05834140283472698, 0.05338610656148083, 0.05003838915309294, 0.046544380180332016, 0.04531995455043082, 0.046758950487967625, 0.04424700040964446, 0.042501830710155265, 0.04312918000951684, 0.04070611976578464, 0.039634048475946745, 0.04046271959079736, 0.03788157778740661, 0.03763377395647068, 0.03693101882214654, 0.034238205851267085, 0.033985941436575955, 0.03775204697543859, 0.034170697513179284, 0.037553199758307516, 0.03368123925570968, 0.030859243383265435, 0.030944809964658013, 0.03031147143980659, 0.02783491295630947, 0.02743426585667109, 0.03291175514173927, 0.02913666240002481, 0.03015775425199625, 0.028601328600048034], 'train_acc': [69.97722210049668, 76.48444347063982, 79.7657847648262, 82.58586218229625, 85.56319383581653, 88.37665242477357, 90.38443981887234, 92.73343923458957, 93.74041411042947, 95.05847392638029, 95.7726226993864, 96.42400671925212, 97.1050613496932, 97.1233201869705, 97.31595092024538, 97.58914877300613, 97.7276877008472, 97.92419843704349, 97.95341257668713, 98.17388803680984, 98.13075153374231, 98.26974693251533, 98.42266469471222, 98.47584355828229, 98.57170245398774, 98.45621530820915, 98.5573236196318, 98.62442484662574, 98.5812883435583, 98.63401073619629, 98.70111196319016, 98.6531825153375, 98.79697085889582, 98.7298696319018, 98.64359662576688, 98.88803680981596, 98.84444383581653, 98.68673312883436, 98.90241564417182, 98.68673312883435, 98.78259202453987, 98.90241564417178, 98.87845092024546, 98.86886503067487, 98.98389570552152, 99.02703220858893, 98.85927914110425, 98.94075920245399, 99.01744631901835, 98.95513803680986], 'val_loss': [0.559296291321516, 0.5571468925724427, 0.55870641892155, 0.5637129123012224, 0.5908194333314895, 0.611488209416469, 0.6403187215328217, 0.6766988107313714, 0.7013713556031386, 0.7362759858369827, 0.7568644148608049, 0.7879717921217283, 0.8191735185682774, 0.8383389376103879, 0.8717255455752214, 0.8723654399315517, 0.8829102131227652, 0.9214135023454825, 0.9268764667212963, 0.9568007538715998, 0.9421886925896008, 0.9791459838549297, 1.0068967404464881, 1.0077666727205117, 1.0282740208009877, 1.0254324146856864, 1.016402691602707, 1.0808157175779343, 1.056381958226363, 1.0462215977410476, 1.0771798330048719, 1.1148701719939709, 1.1092806681990623, 1.1179165206849575, 1.1212959500650566, 1.1410293895751238, 1.1310319639742374, 1.1222946122288704, 1.151241660118103, 1.1635462331275144, 1.177414880444606, 1.185952658454577, 1.19902915507555, 1.1838532090187073, 1.2176454613606134, 1.2324561638136704, 1.2760142485300698, 1.2462165243923664, 1.2330947356919448, 1.23216741407911], 'val_acc': [72.21602182539682, 72.93526785714286, 74.14589533730158, 75.19686259920634, 75.164310515873, 75.85100446428572, 75.32707093253968, 75.38907490079364, 75.55183531746032, 74.93024553571428, 74.44196428571428, 74.99224950396824, 74.9627976190476, 75.25886656746033, 74.933345734127, 74.73183283730155, 74.11024305555554, 75.06045386904763, 74.89769345238095, 75.44797867063492, 75.16121031746033, 75.3534226190476, 75.41852678571426, 75.06045386904763, 75.61693948412697, 75.55183531746032, 75.5518353174603, 76.33618551587301, 75.18756200396824, 75.68204365079366, 75.847904265873, 75.9068080357143, 75.35652281746033, 76.69425843253967, 76.36563740079366, 76.00136408730155, 76.30053323412699, 76.495845734127, 74.99844990079364, 75.38907490079364, 75.81225198412699, 76.72991071428574, 76.6322544642857, 75.64949156746032, 75.32397073412699, 75.41852678571428, 75.3177703373016, 75.68204365079364, 75.32397073412699, 74.93334573412699], 'test_loss': 1.23216741407911, 'test_acc': 74.93334573412699}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.5844922546594423, 0.48890001916446557, 0.435949481520916, 0.38943886702046054, 0.3399630057299797, 0.2906636262049704, 0.2507701683446673, 0.20844713273955276, 0.17704325237888496, 0.15158120254797436, 0.131700625426016, 0.1134038314314708, 0.0984821757244552, 0.09294591581254648, 0.08557747846092184, 0.07575621859290488, 0.07436768955156846, 0.0675547145467046, 0.06527294868751898, 0.057640234351249556, 0.05834140283472698, 0.05338610656148083, 0.05003838915309294, 0.046544380180332016, 0.04531995455043082, 0.046758950487967625, 0.04424700040964446, 0.042501830710155265, 0.04312918000951684, 0.04070611976578464, 0.039634048475946745, 0.04046271959079736, 0.03788157778740661, 0.03763377395647068, 0.03693101882214654, 0.034238205851267085, 0.033985941436575955, 0.03775204697543859, 0.034170697513179284, 0.037553199758307516, 0.03368123925570968, 0.030859243383265435, 0.030944809964658013, 0.03031147143980659, 0.02783491295630947, 0.02743426585667109, 0.03291175514173927, 0.02913666240002481, 0.03015775425199625, 0.028601328600048034], 'train_acc': [69.97722210049668, 76.48444347063982, 79.7657847648262, 82.58586218229625, 85.56319383581653, 88.37665242477357, 90.38443981887234, 92.73343923458957, 93.74041411042947, 95.05847392638029, 95.7726226993864, 96.42400671925212, 97.1050613496932, 97.1233201869705, 97.31595092024538, 97.58914877300613, 97.7276877008472, 97.92419843704349, 97.95341257668713, 98.17388803680984, 98.13075153374231, 98.26974693251533, 98.42266469471222, 98.47584355828229, 98.57170245398774, 98.45621530820915, 98.5573236196318, 98.62442484662574, 98.5812883435583, 98.63401073619629, 98.70111196319016, 98.6531825153375, 98.79697085889582, 98.7298696319018, 98.64359662576688, 98.88803680981596, 98.84444383581653, 98.68673312883436, 98.90241564417182, 98.68673312883435, 98.78259202453987, 98.90241564417178, 98.87845092024546, 98.86886503067487, 98.98389570552152, 99.02703220858893, 98.85927914110425, 98.94075920245399, 99.01744631901835, 98.95513803680986], 'val_loss': [0.559296291321516, 0.5571468925724427, 0.55870641892155, 0.5637129123012224, 0.5908194333314895, 0.611488209416469, 0.6403187215328217, 0.6766988107313714, 0.7013713556031386, 0.7362759858369827, 0.7568644148608049, 0.7879717921217283, 0.8191735185682774, 0.8383389376103879, 0.8717255455752214, 0.8723654399315517, 0.8829102131227652, 0.9214135023454825, 0.9268764667212963, 0.9568007538715998, 0.9421886925896008, 0.9791459838549297, 1.0068967404464881, 1.0077666727205117, 1.0282740208009877, 1.0254324146856864, 1.016402691602707, 1.0808157175779343, 1.056381958226363, 1.0462215977410476, 1.0771798330048719, 1.1148701719939709, 1.1092806681990623, 1.1179165206849575, 1.1212959500650566, 1.1410293895751238, 1.1310319639742374, 1.1222946122288704, 1.151241660118103, 1.1635462331275144, 1.177414880444606, 1.185952658454577, 1.19902915507555, 1.1838532090187073, 1.2176454613606134, 1.2324561638136704, 1.2760142485300698, 1.2462165243923664, 1.2330947356919448, 1.23216741407911], 'val_acc': [72.21602182539682, 72.93526785714286, 74.14589533730158, 75.19686259920634, 75.164310515873, 75.85100446428572, 75.32707093253968, 75.38907490079364, 75.55183531746032, 74.93024553571428, 74.44196428571428, 74.99224950396824, 74.9627976190476, 75.25886656746033, 74.933345734127, 74.73183283730155, 74.11024305555554, 75.06045386904763, 74.89769345238095, 75.44797867063492, 75.16121031746033, 75.3534226190476, 75.41852678571426, 75.06045386904763, 75.61693948412697, 75.55183531746032, 75.5518353174603, 76.33618551587301, 75.18756200396824, 75.68204365079366, 75.847904265873, 75.9068080357143, 75.35652281746033, 76.69425843253967, 76.36563740079366, 76.00136408730155, 76.30053323412699, 76.495845734127, 74.99844990079364, 75.38907490079364, 75.81225198412699, 76.72991071428574, 76.6322544642857, 75.64949156746032, 75.32397073412699, 75.41852678571428, 75.3177703373016, 75.68204365079364, 75.32397073412699, 74.93334573412699], 'test_loss': 1.23216741407911, 'test_acc': 74.93334573412699}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:{'epoch_index': 49, 'train_loss': [0.5844922546594423, 0.48890001916446557, 0.435949481520916, 0.38943886702046054, 0.3399630057299797, 0.2906636262049704, 0.2507701683446673, 0.20844713273955276, 0.17704325237888496, 0.15158120254797436, 0.131700625426016, 0.1134038314314708, 0.0984821757244552, 0.09294591581254648, 0.08557747846092184, 0.07575621859290488, 0.07436768955156846, 0.0675547145467046, 0.06527294868751898, 0.057640234351249556, 0.05834140283472698, 0.05338610656148083, 0.05003838915309294, 0.046544380180332016, 0.04531995455043082, 0.046758950487967625, 0.04424700040964446, 0.042501830710155265, 0.04312918000951684, 0.04070611976578464, 0.039634048475946745, 0.04046271959079736, 0.03788157778740661, 0.03763377395647068, 0.03693101882214654, 0.034238205851267085, 0.033985941436575955, 0.03775204697543859, 0.034170697513179284, 0.037553199758307516, 0.03368123925570968, 0.030859243383265435, 0.030944809964658013, 0.03031147143980659, 0.02783491295630947, 0.02743426585667109, 0.03291175514173927, 0.02913666240002481, 0.03015775425199625, 0.028601328600048034], 'train_acc': [69.97722210049668, 76.48444347063982, 79.7657847648262, 82.58586218229625, 85.56319383581653, 88.37665242477357, 90.38443981887234, 92.73343923458957, 93.74041411042947, 95.05847392638029, 95.7726226993864, 96.42400671925212, 97.1050613496932, 97.1233201869705, 97.31595092024538, 97.58914877300613, 97.7276877008472, 97.92419843704349, 97.95341257668713, 98.17388803680984, 98.13075153374231, 98.26974693251533, 98.42266469471222, 98.47584355828229, 98.57170245398774, 98.45621530820915, 98.5573236196318, 98.62442484662574, 98.5812883435583, 98.63401073619629, 98.70111196319016, 98.6531825153375, 98.79697085889582, 98.7298696319018, 98.64359662576688, 98.88803680981596, 98.84444383581653, 98.68673312883436, 98.90241564417182, 98.68673312883435, 98.78259202453987, 98.90241564417178, 98.87845092024546, 98.86886503067487, 98.98389570552152, 99.02703220858893, 98.85927914110425, 98.94075920245399, 99.01744631901835, 98.95513803680986], 'val_loss': [0.559296291321516, 0.5571468925724427, 0.55870641892155, 0.5637129123012224, 0.5908194333314895, 0.611488209416469, 0.6403187215328217, 0.6766988107313714, 0.7013713556031386, 0.7362759858369827, 0.7568644148608049, 0.7879717921217283, 0.8191735185682774, 0.8383389376103879, 0.8717255455752214, 0.8723654399315517, 0.8829102131227652, 0.9214135023454825, 0.9268764667212963, 0.9568007538715998, 0.9421886925896008, 0.9791459838549297, 1.0068967404464881, 1.0077666727205117, 1.0282740208009877, 1.0254324146856864, 1.016402691602707, 1.0808157175779343, 1.056381958226363, 1.0462215977410476, 1.0771798330048719, 1.1148701719939709, 1.1092806681990623, 1.1179165206849575, 1.1212959500650566, 1.1410293895751238, 1.1310319639742374, 1.1222946122288704, 1.151241660118103, 1.1635462331275144, 1.177414880444606, 1.185952658454577, 1.19902915507555, 1.1838532090187073, 1.2176454613606134, 1.2324561638136704, 1.2760142485300698, 1.2462165243923664, 1.2330947356919448, 1.23216741407911], 'val_acc': [72.21602182539682, 72.93526785714286, 74.14589533730158, 75.19686259920634, 75.164310515873, 75.85100446428572, 75.32707093253968, 75.38907490079364, 75.55183531746032, 74.93024553571428, 74.44196428571428, 74.99224950396824, 74.9627976190476, 75.25886656746033, 74.933345734127, 74.73183283730155, 74.11024305555554, 75.06045386904763, 74.89769345238095, 75.44797867063492, 75.16121031746033, 75.3534226190476, 75.41852678571426, 75.06045386904763, 75.61693948412697, 75.55183531746032, 75.5518353174603, 76.33618551587301, 75.18756200396824, 75.68204365079366, 75.847904265873, 75.9068080357143, 75.35652281746033, 76.69425843253967, 76.36563740079366, 76.00136408730155, 76.30053323412699, 76.495845734127, 74.99844990079364, 75.38907490079364, 75.81225198412699, 76.72991071428574, 76.6322544642857, 75.64949156746032, 75.32397073412699, 75.41852678571428, 75.3177703373016, 75.68204365079364, 75.32397073412699, 74.93334573412699], 'test_loss': 1.23216741407911, 'test_acc': 74.93334573412699}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.5844922546594423, 0.48890001916446557, 0.435949481520916, 0.38943886702046054, 0.3399630057299797, 0.2906636262049704, 0.2507701683446673, 0.20844713273955276, 0.17704325237888496, 0.15158120254797436, 0.131700625426016, 0.1134038314314708, 0.0984821757244552, 0.09294591581254648, 0.08557747846092184, 0.07575621859290488, 0.07436768955156846, 0.0675547145467046, 0.06527294868751898, 0.057640234351249556, 0.05834140283472698, 0.05338610656148083, 0.05003838915309294, 0.046544380180332016, 0.04531995455043082, 0.046758950487967625, 0.04424700040964446, 0.042501830710155265, 0.04312918000951684, 0.04070611976578464, 0.039634048475946745, 0.04046271959079736, 0.03788157778740661, 0.03763377395647068, 0.03693101882214654, 0.034238205851267085, 0.033985941436575955, 0.03775204697543859, 0.034170697513179284, 0.037553199758307516, 0.03368123925570968, 0.030859243383265435, 0.030944809964658013, 0.03031147143980659, 0.02783491295630947, 0.02743426585667109, 0.03291175514173927, 0.02913666240002481, 0.03015775425199625, 0.028601328600048034], 'train_acc': [69.97722210049668, 76.48444347063982, 79.7657847648262, 82.58586218229625, 85.56319383581653, 88.37665242477357, 90.38443981887234, 92.73343923458957, 93.74041411042947, 95.05847392638029, 95.7726226993864, 96.42400671925212, 97.1050613496932, 97.1233201869705, 97.31595092024538, 97.58914877300613, 97.7276877008472, 97.92419843704349, 97.95341257668713, 98.17388803680984, 98.13075153374231, 98.26974693251533, 98.42266469471222, 98.47584355828229, 98.57170245398774, 98.45621530820915, 98.5573236196318, 98.62442484662574, 98.5812883435583, 98.63401073619629, 98.70111196319016, 98.6531825153375, 98.79697085889582, 98.7298696319018, 98.64359662576688, 98.88803680981596, 98.84444383581653, 98.68673312883436, 98.90241564417182, 98.68673312883435, 98.78259202453987, 98.90241564417178, 98.87845092024546, 98.86886503067487, 98.98389570552152, 99.02703220858893, 98.85927914110425, 98.94075920245399, 99.01744631901835, 98.95513803680986], 'val_loss': [0.559296291321516, 0.5571468925724427, 0.55870641892155, 0.5637129123012224, 0.5908194333314895, 0.611488209416469, 0.6403187215328217, 0.6766988107313714, 0.7013713556031386, 0.7362759858369827, 0.7568644148608049, 0.7879717921217283, 0.8191735185682774, 0.8383389376103879, 0.8717255455752214, 0.8723654399315517, 0.8829102131227652, 0.9214135023454825, 0.9268764667212963, 0.9568007538715998, 0.9421886925896008, 0.9791459838549297, 1.0068967404464881, 1.0077666727205117, 1.0282740208009877, 1.0254324146856864, 1.016402691602707, 1.0808157175779343, 1.056381958226363, 1.0462215977410476, 1.0771798330048719, 1.1148701719939709, 1.1092806681990623, 1.1179165206849575, 1.1212959500650566, 1.1410293895751238, 1.1310319639742374, 1.1222946122288704, 1.151241660118103, 1.1635462331275144, 1.177414880444606, 1.185952658454577, 1.19902915507555, 1.1838532090187073, 1.2176454613606134, 1.2324561638136704, 1.2760142485300698, 1.2462165243923664, 1.2330947356919448, 1.23216741407911], 'val_acc': [72.21602182539682, 72.93526785714286, 74.14589533730158, 75.19686259920634, 75.164310515873, 75.85100446428572, 75.32707093253968, 75.38907490079364, 75.55183531746032, 74.93024553571428, 74.44196428571428, 74.99224950396824, 74.9627976190476, 75.25886656746033, 74.933345734127, 74.73183283730155, 74.11024305555554, 75.06045386904763, 74.89769345238095, 75.44797867063492, 75.16121031746033, 75.3534226190476, 75.41852678571426, 75.06045386904763, 75.61693948412697, 75.55183531746032, 75.5518353174603, 76.33618551587301, 75.18756200396824, 75.68204365079366, 75.847904265873, 75.9068080357143, 75.35652281746033, 76.69425843253967, 76.36563740079366, 76.00136408730155, 76.30053323412699, 76.495845734127, 74.99844990079364, 75.38907490079364, 75.81225198412699, 76.72991071428574, 76.6322544642857, 75.64949156746032, 75.32397073412699, 75.41852678571428, 75.3177703373016, 75.68204365079364, 75.32397073412699, 74.93334573412699], 'test_loss': 1.23216741407911, 'test_acc': 74.93334573412699}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.5844922546594423, 0.48890001916446557, 0.435949481520916, 0.38943886702046054, 0.3399630057299797, 0.2906636262049704, 0.2507701683446673, 0.20844713273955276, 0.17704325237888496, 0.15158120254797436, 0.131700625426016, 0.1134038314314708, 0.0984821757244552, 0.09294591581254648, 0.08557747846092184, 0.07575621859290488, 0.07436768955156846, 0.0675547145467046, 0.06527294868751898, 0.057640234351249556, 0.05834140283472698, 0.05338610656148083, 0.05003838915309294, 0.046544380180332016, 0.04531995455043082, 0.046758950487967625, 0.04424700040964446, 0.042501830710155265, 0.04312918000951684, 0.04070611976578464, 0.039634048475946745, 0.04046271959079736, 0.03788157778740661, 0.03763377395647068, 0.03693101882214654, 0.034238205851267085, 0.033985941436575955, 0.03775204697543859, 0.034170697513179284, 0.037553199758307516, 0.03368123925570968, 0.030859243383265435, 0.030944809964658013, 0.03031147143980659, 0.02783491295630947, 0.02743426585667109, 0.03291175514173927, 0.02913666240002481, 0.03015775425199625, 0.028601328600048034], 'train_acc': [69.97722210049668, 76.48444347063982, 79.7657847648262, 82.58586218229625, 85.56319383581653, 88.37665242477357, 90.38443981887234, 92.73343923458957, 93.74041411042947, 95.05847392638029, 95.7726226993864, 96.42400671925212, 97.1050613496932, 97.1233201869705, 97.31595092024538, 97.58914877300613, 97.7276877008472, 97.92419843704349, 97.95341257668713, 98.17388803680984, 98.13075153374231, 98.26974693251533, 98.42266469471222, 98.47584355828229, 98.57170245398774, 98.45621530820915, 98.5573236196318, 98.62442484662574, 98.5812883435583, 98.63401073619629, 98.70111196319016, 98.6531825153375, 98.79697085889582, 98.7298696319018, 98.64359662576688, 98.88803680981596, 98.84444383581653, 98.68673312883436, 98.90241564417182, 98.68673312883435, 98.78259202453987, 98.90241564417178, 98.87845092024546, 98.86886503067487, 98.98389570552152, 99.02703220858893, 98.85927914110425, 98.94075920245399, 99.01744631901835, 98.95513803680986], 'val_loss': [0.559296291321516, 0.5571468925724427, 0.55870641892155, 0.5637129123012224, 0.5908194333314895, 0.611488209416469, 0.6403187215328217, 0.6766988107313714, 0.7013713556031386, 0.7362759858369827, 0.7568644148608049, 0.7879717921217283, 0.8191735185682774, 0.8383389376103879, 0.8717255455752214, 0.8723654399315517, 0.8829102131227652, 0.9214135023454825, 0.9268764667212963, 0.9568007538715998, 0.9421886925896008, 0.9791459838549297, 1.0068967404464881, 1.0077666727205117, 1.0282740208009877, 1.0254324146856864, 1.016402691602707, 1.0808157175779343, 1.056381958226363, 1.0462215977410476, 1.0771798330048719, 1.1148701719939709, 1.1092806681990623, 1.1179165206849575, 1.1212959500650566, 1.1410293895751238, 1.1310319639742374, 1.1222946122288704, 1.151241660118103, 1.1635462331275144, 1.177414880444606, 1.185952658454577, 1.19902915507555, 1.1838532090187073, 1.2176454613606134, 1.2324561638136704, 1.2760142485300698, 1.2462165243923664, 1.2330947356919448, 1.23216741407911], 'val_acc': [72.21602182539682, 72.93526785714286, 74.14589533730158, 75.19686259920634, 75.164310515873, 75.85100446428572, 75.32707093253968, 75.38907490079364, 75.55183531746032, 74.93024553571428, 74.44196428571428, 74.99224950396824, 74.9627976190476, 75.25886656746033, 74.933345734127, 74.73183283730155, 74.11024305555554, 75.06045386904763, 74.89769345238095, 75.44797867063492, 75.16121031746033, 75.3534226190476, 75.41852678571426, 75.06045386904763, 75.61693948412697, 75.55183531746032, 75.5518353174603, 76.33618551587301, 75.18756200396824, 75.68204365079366, 75.847904265873, 75.9068080357143, 75.35652281746033, 76.69425843253967, 76.36563740079366, 76.00136408730155, 76.30053323412699, 76.495845734127, 74.99844990079364, 75.38907490079364, 75.81225198412699, 76.72991071428574, 76.6322544642857, 75.64949156746032, 75.32397073412699, 75.41852678571428, 75.3177703373016, 75.68204365079364, 75.32397073412699, 74.93334573412699], 'test_loss': 1.23216741407911, 'test_acc': 74.93334573412699}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:{'epoch_index': 49, 'train_loss': [0.5844922546594423, 0.48890001916446557, 0.435949481520916, 0.38943886702046054, 0.3399630057299797, 0.2906636262049704, 0.2507701683446673, 0.20844713273955276, 0.17704325237888496, 0.15158120254797436, 0.131700625426016, 0.1134038314314708, 0.0984821757244552, 0.09294591581254648, 0.08557747846092184, 0.07575621859290488, 0.07436768955156846, 0.0675547145467046, 0.06527294868751898, 0.057640234351249556, 0.05834140283472698, 0.05338610656148083, 0.05003838915309294, 0.046544380180332016, 0.04531995455043082, 0.046758950487967625, 0.04424700040964446, 0.042501830710155265, 0.04312918000951684, 0.04070611976578464, 0.039634048475946745, 0.04046271959079736, 0.03788157778740661, 0.03763377395647068, 0.03693101882214654, 0.034238205851267085, 0.033985941436575955, 0.03775204697543859, 0.034170697513179284, 0.037553199758307516, 0.03368123925570968, 0.030859243383265435, 0.030944809964658013, 0.03031147143980659, 0.02783491295630947, 0.02743426585667109, 0.03291175514173927, 0.02913666240002481, 0.03015775425199625, 0.028601328600048034], 'train_acc': [69.97722210049668, 76.48444347063982, 79.7657847648262, 82.58586218229625, 85.56319383581653, 88.37665242477357, 90.38443981887234, 92.73343923458957, 93.74041411042947, 95.05847392638029, 95.7726226993864, 96.42400671925212, 97.1050613496932, 97.1233201869705, 97.31595092024538, 97.58914877300613, 97.7276877008472, 97.92419843704349, 97.95341257668713, 98.17388803680984, 98.13075153374231, 98.26974693251533, 98.42266469471222, 98.47584355828229, 98.57170245398774, 98.45621530820915, 98.5573236196318, 98.62442484662574, 98.5812883435583, 98.63401073619629, 98.70111196319016, 98.6531825153375, 98.79697085889582, 98.7298696319018, 98.64359662576688, 98.88803680981596, 98.84444383581653, 98.68673312883436, 98.90241564417182, 98.68673312883435, 98.78259202453987, 98.90241564417178, 98.87845092024546, 98.86886503067487, 98.98389570552152, 99.02703220858893, 98.85927914110425, 98.94075920245399, 99.01744631901835, 98.95513803680986], 'val_loss': [0.559296291321516, 0.5571468925724427, 0.55870641892155, 0.5637129123012224, 0.5908194333314895, 0.611488209416469, 0.6403187215328217, 0.6766988107313714, 0.7013713556031386, 0.7362759858369827, 0.7568644148608049, 0.7879717921217283, 0.8191735185682774, 0.8383389376103879, 0.8717255455752214, 0.8723654399315517, 0.8829102131227652, 0.9214135023454825, 0.9268764667212963, 0.9568007538715998, 0.9421886925896008, 0.9791459838549297, 1.0068967404464881, 1.0077666727205117, 1.0282740208009877, 1.0254324146856864, 1.016402691602707, 1.0808157175779343, 1.056381958226363, 1.0462215977410476, 1.0771798330048719, 1.1148701719939709, 1.1092806681990623, 1.1179165206849575, 1.1212959500650566, 1.1410293895751238, 1.1310319639742374, 1.1222946122288704, 1.151241660118103, 1.1635462331275144, 1.177414880444606, 1.185952658454577, 1.19902915507555, 1.1838532090187073, 1.2176454613606134, 1.2324561638136704, 1.2760142485300698, 1.2462165243923664, 1.2330947356919448, 1.23216741407911], 'val_acc': [72.21602182539682, 72.93526785714286, 74.14589533730158, 75.19686259920634, 75.164310515873, 75.85100446428572, 75.32707093253968, 75.38907490079364, 75.55183531746032, 74.93024553571428, 74.44196428571428, 74.99224950396824, 74.9627976190476, 75.25886656746033, 74.933345734127, 74.73183283730155, 74.11024305555554, 75.06045386904763, 74.89769345238095, 75.44797867063492, 75.16121031746033, 75.3534226190476, 75.41852678571426, 75.06045386904763, 75.61693948412697, 75.55183531746032, 75.5518353174603, 76.33618551587301, 75.18756200396824, 75.68204365079366, 75.847904265873, 75.9068080357143, 75.35652281746033, 76.69425843253967, 76.36563740079366, 76.00136408730155, 76.30053323412699, 76.495845734127, 74.99844990079364, 75.38907490079364, 75.81225198412699, 76.72991071428574, 76.6322544642857, 75.64949156746032, 75.32397073412699, 75.41852678571428, 75.3177703373016, 75.68204365079364, 75.32397073412699, 74.93334573412699], 'test_loss': 1.23216741407911, 'test_acc': 74.93334573412699}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.5844922546594423, 0.48890001916446557, 0.435949481520916, 0.38943886702046054, 0.3399630057299797, 0.2906636262049704, 0.2507701683446673, 0.20844713273955276, 0.17704325237888496, 0.15158120254797436, 0.131700625426016, 0.1134038314314708, 0.0984821757244552, 0.09294591581254648, 0.08557747846092184, 0.07575621859290488, 0.07436768955156846, 0.0675547145467046, 0.06527294868751898, 0.057640234351249556, 0.05834140283472698, 0.05338610656148083, 0.05003838915309294, 0.046544380180332016, 0.04531995455043082, 0.046758950487967625, 0.04424700040964446, 0.042501830710155265, 0.04312918000951684, 0.04070611976578464, 0.039634048475946745, 0.04046271959079736, 0.03788157778740661, 0.03763377395647068, 0.03693101882214654, 0.034238205851267085, 0.033985941436575955, 0.03775204697543859, 0.034170697513179284, 0.037553199758307516, 0.03368123925570968, 0.030859243383265435, 0.030944809964658013, 0.03031147143980659, 0.02783491295630947, 0.02743426585667109, 0.03291175514173927, 0.02913666240002481, 0.03015775425199625, 0.028601328600048034], 'train_acc': [69.97722210049668, 76.48444347063982, 79.7657847648262, 82.58586218229625, 85.56319383581653, 88.37665242477357, 90.38443981887234, 92.73343923458957, 93.74041411042947, 95.05847392638029, 95.7726226993864, 96.42400671925212, 97.1050613496932, 97.1233201869705, 97.31595092024538, 97.58914877300613, 97.7276877008472, 97.92419843704349, 97.95341257668713, 98.17388803680984, 98.13075153374231, 98.26974693251533, 98.42266469471222, 98.47584355828229, 98.57170245398774, 98.45621530820915, 98.5573236196318, 98.62442484662574, 98.5812883435583, 98.63401073619629, 98.70111196319016, 98.6531825153375, 98.79697085889582, 98.7298696319018, 98.64359662576688, 98.88803680981596, 98.84444383581653, 98.68673312883436, 98.90241564417182, 98.68673312883435, 98.78259202453987, 98.90241564417178, 98.87845092024546, 98.86886503067487, 98.98389570552152, 99.02703220858893, 98.85927914110425, 98.94075920245399, 99.01744631901835, 98.95513803680986], 'val_loss': [0.559296291321516, 0.5571468925724427, 0.55870641892155, 0.5637129123012224, 0.5908194333314895, 0.611488209416469, 0.6403187215328217, 0.6766988107313714, 0.7013713556031386, 0.7362759858369827, 0.7568644148608049, 0.7879717921217283, 0.8191735185682774, 0.8383389376103879, 0.8717255455752214, 0.8723654399315517, 0.8829102131227652, 0.9214135023454825, 0.9268764667212963, 0.9568007538715998, 0.9421886925896008, 0.9791459838549297, 1.0068967404464881, 1.0077666727205117, 1.0282740208009877, 1.0254324146856864, 1.016402691602707, 1.0808157175779343, 1.056381958226363, 1.0462215977410476, 1.0771798330048719, 1.1148701719939709, 1.1092806681990623, 1.1179165206849575, 1.1212959500650566, 1.1410293895751238, 1.1310319639742374, 1.1222946122288704, 1.151241660118103, 1.1635462331275144, 1.177414880444606, 1.185952658454577, 1.19902915507555, 1.1838532090187073, 1.2176454613606134, 1.2324561638136704, 1.2760142485300698, 1.2462165243923664, 1.2330947356919448, 1.23216741407911], 'val_acc': [72.21602182539682, 72.93526785714286, 74.14589533730158, 75.19686259920634, 75.164310515873, 75.85100446428572, 75.32707093253968, 75.38907490079364, 75.55183531746032, 74.93024553571428, 74.44196428571428, 74.99224950396824, 74.9627976190476, 75.25886656746033, 74.933345734127, 74.73183283730155, 74.11024305555554, 75.06045386904763, 74.89769345238095, 75.44797867063492, 75.16121031746033, 75.3534226190476, 75.41852678571426, 75.06045386904763, 75.61693948412697, 75.55183531746032, 75.5518353174603, 76.33618551587301, 75.18756200396824, 75.68204365079366, 75.847904265873, 75.9068080357143, 75.35652281746033, 76.69425843253967, 76.36563740079366, 76.00136408730155, 76.30053323412699, 76.495845734127, 74.99844990079364, 75.38907490079364, 75.81225198412699, 76.72991071428574, 76.6322544642857, 75.64949156746032, 75.32397073412699, 75.41852678571428, 75.3177703373016, 75.68204365079364, 75.32397073412699, 74.93334573412699], 'test_loss': 1.23216741407911, 'test_acc': 74.93334573412699}\n"
     ]
    }
   ],
   "source": [
    "# Model 4\n",
    "args.model_id=4\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_onehot_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_onehot_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_onehot_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_Conv1d(embedding_size=1, num_channels=3954, hidden_dim=128, label_nums=label_nums, dropout_p=0.1)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "args.logger.handlers.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d8920",
   "metadata": {},
   "source": [
    "**acc: 74.93**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973cd36",
   "metadata": {},
   "source": [
    "We can see that observation model 4, is a forward propagation model preceded by a layer of conv1d. But the effect in ont-hot embedding is not much improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7976f185",
   "metadata": {},
   "source": [
    "**`model 5: text--10word, embedding--my_embedding, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d50e55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=5, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:02, 77.90it/s]\n",
      "INFO:TRAIN loss: 0.6161152373062319, acc: 66.30331580484962\n",
      "24it [00:00, 117.80it/s]\n",
      "INFO:VAL loss: 0.6137542103727659, acc: 66.37369791666667\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:01, 83.57it/s]\n",
      "INFO:TRAIN loss: 0.5839604534254486, acc: 69.61615359333913\n",
      "24it [00:00, 119.14it/s]\n",
      "INFO:VAL loss: 0.6053479736049969, acc: 68.24156746031747\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:01, 82.83it/s]\n",
      "INFO:TRAIN loss: 0.5696957877442878, acc: 70.5633307770961\n",
      "24it [00:00, 116.97it/s]\n",
      "INFO:VAL loss: 0.5989865536491076, acc: 67.92534722222223\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:01, 83.68it/s]\n",
      "INFO:TRAIN loss: 0.5579417048056434, acc: 71.57509859772128\n",
      "24it [00:00, 117.81it/s]\n",
      "INFO:VAL loss: 0.5981337502598763, acc: 68.8600570436508\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:01, 82.78it/s]\n",
      "INFO:TRAIN loss: 0.5463560477721909, acc: 72.58640994741458\n",
      "24it [00:00, 116.89it/s]\n",
      "INFO:VAL loss: 0.5943284568687279, acc: 68.63219246031747\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:01, 83.84it/s]\n",
      "INFO:TRAIN loss: 0.5348448031153417, acc: 73.62739190768329\n",
      "24it [00:00, 117.63it/s]\n",
      "INFO:VAL loss: 0.594827717791001, acc: 68.99336557539681\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:01, 84.05it/s]\n",
      "INFO:TRAIN loss: 0.5247476185026346, acc: 74.39471954425943\n",
      "24it [00:00, 118.41it/s]\n",
      "INFO:VAL loss: 0.5967821404337883, acc: 69.14682539682539\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:01, 83.83it/s]\n",
      "INFO:TRAIN loss: 0.5163099513463447, acc: 74.9084775781478\n",
      "24it [00:00, 119.21it/s]\n",
      "INFO:VAL loss: 0.5940908019741377, acc: 68.91896081349206\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:01, 84.00it/s]\n",
      "INFO:TRAIN loss: 0.5088532272657735, acc: 75.4286262050833\n",
      "24it [00:00, 119.18it/s]\n",
      "INFO:VAL loss: 0.6072333641350269, acc: 69.70021081349206\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:01, 83.81it/s]\n",
      "INFO:TRAIN loss: 0.505319605758585, acc: 75.7057040607654\n",
      "24it [00:00, 118.68it/s]\n",
      "INFO:VAL loss: 0.5947041151424248, acc: 68.9050099206349\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:01, 83.79it/s]\n",
      "INFO:TRAIN loss: 0.4956960963325266, acc: 76.62777534326614\n",
      "24it [00:00, 116.85it/s]\n",
      "INFO:VAL loss: 0.6044654759267966, acc: 69.2599826388889\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:01, 83.50it/s]\n",
      "INFO:TRAIN loss: 0.4894833359981609, acc: 76.96465089103127\n",
      "24it [00:00, 117.77it/s]\n",
      "INFO:VAL loss: 0.6118064547578494, acc: 69.15612599206351\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:01, 82.84it/s]\n",
      "INFO:TRAIN loss: 0.4871222565144849, acc: 77.0002556237219\n",
      "24it [00:00, 117.55it/s]\n",
      "INFO:VAL loss: 0.5946337394416332, acc: 70.36365327380953\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:01, 83.83it/s]\n",
      "INFO:TRAIN loss: 0.48037272326054015, acc: 77.35881354075376\n",
      "24it [00:00, 119.15it/s]\n",
      "INFO:VAL loss: 0.6023965924978256, acc: 69.13597470238096\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:01, 83.92it/s]\n",
      "INFO:TRAIN loss: 0.4770904214469933, acc: 77.72969617294765\n",
      "24it [00:00, 119.34it/s]\n",
      "INFO:VAL loss: 0.611320880552133, acc: 69.31888640873017\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:01, 83.93it/s]\n",
      "INFO:TRAIN loss: 0.4684704002792849, acc: 78.15626825883726\n",
      "24it [00:00, 119.38it/s]\n",
      "INFO:VAL loss: 0.6132879480719566, acc: 69.15922619047618\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:01, 83.85it/s]\n",
      "INFO:TRAIN loss: 0.4654651198284757, acc: 78.32265191352622\n",
      "24it [00:00, 117.49it/s]\n",
      "INFO:VAL loss: 0.6055898504952589, acc: 69.49094742063494\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:01, 83.88it/s]\n",
      "INFO:TRAIN loss: 0.4592473508755856, acc: 78.87087350277534\n",
      "24it [00:00, 117.15it/s]\n",
      "INFO:VAL loss: 0.62870562945803, acc: 69.29563492063492\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:01, 83.03it/s]\n",
      "INFO:TRAIN loss: 0.45651126730661445, acc: 79.06829718083554\n",
      "24it [00:00, 117.93it/s]\n",
      "INFO:VAL loss: 0.6247240615387758, acc: 70.14818948412699\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:01, 83.96it/s]\n",
      "INFO:TRAIN loss: 0.4534484104144795, acc: 78.99069712240718\n",
      "24it [00:00, 118.61it/s]\n",
      "INFO:VAL loss: 0.6287933699786663, acc: 69.5886036706349\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:01, 83.81it/s]\n",
      "INFO:TRAIN loss: 0.4508642440924615, acc: 79.10435838445808\n",
      "24it [00:00, 118.82it/s]\n",
      "INFO:VAL loss: 0.6292938850820065, acc: 69.45219494047618\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:01, 83.87it/s]\n",
      "INFO:TRAIN loss: 0.4463396353955649, acc: 79.78062007011391\n",
      "24it [00:00, 119.00it/s]\n",
      "INFO:VAL loss: 0.6320266574621202, acc: 70.21329365079366\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:01, 83.38it/s]\n",
      "INFO:TRAIN loss: 0.4435607403333933, acc: 79.78107654104589\n",
      "24it [00:00, 118.89it/s]\n",
      "INFO:VAL loss: 0.6334086693823336, acc: 69.94357638888889\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:01, 83.76it/s]\n",
      "INFO:TRAIN loss: 0.43995168859973277, acc: 80.08120617879054\n",
      "24it [00:00, 116.83it/s]\n",
      "INFO:VAL loss: 0.6361246667802334, acc: 69.39329117063492\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:01, 83.77it/s]\n",
      "INFO:TRAIN loss: 0.43661742305463075, acc: 80.41990761028343\n",
      "24it [00:00, 117.02it/s]\n",
      "INFO:VAL loss: 0.649938421944777, acc: 69.75136408730158\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:01, 82.78it/s]\n",
      "INFO:TRAIN loss: 0.4320465874818205, acc: 80.55844653812443\n",
      "24it [00:00, 117.24it/s]\n",
      "INFO:VAL loss: 0.6490655615925788, acc: 70.11563740079366\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:01, 83.54it/s]\n",
      "INFO:TRAIN loss: 0.42911841286106356, acc: 80.79900671925208\n",
      "24it [00:00, 118.46it/s]\n",
      "INFO:VAL loss: 0.6434849550326666, acc: 69.7870163690476\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:01, 83.82it/s]\n",
      "INFO:TRAIN loss: 0.4253452186204175, acc: 81.071291630149\n",
      "24it [00:00, 119.01it/s]\n",
      "INFO:VAL loss: 0.665817288060983, acc: 69.62425595238096\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:01, 83.79it/s]\n",
      "INFO:TRAIN loss: 0.42557969067725665, acc: 80.82502556237218\n",
      "24it [00:00, 118.93it/s]\n",
      "INFO:VAL loss: 0.6632057850559554, acc: 70.04743303571429\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:01, 83.77it/s]\n",
      "INFO:TRAIN loss: 0.4211645089775506, acc: 81.097766944201\n",
      "24it [00:00, 118.95it/s]\n",
      "INFO:VAL loss: 0.6697211811939876, acc: 69.9466765873016\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:01, 84.02it/s]\n",
      "INFO:TRAIN loss: 0.4167575971480529, acc: 81.31344945953845\n",
      "24it [00:00, 117.08it/s]\n",
      "INFO:VAL loss: 0.6492914520204067, acc: 69.65680803571428\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:01, 83.56it/s]\n",
      "INFO:TRAIN loss: 0.4155416806782682, acc: 81.61243791995327\n",
      "24it [00:00, 115.25it/s]\n",
      "INFO:VAL loss: 0.6820812659958999, acc: 69.88157242063491\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:01, 82.81it/s]\n",
      "INFO:TRAIN loss: 0.4126743707188799, acc: 81.58984260882276\n",
      "24it [00:00, 116.92it/s]\n",
      "INFO:VAL loss: 0.7025761790573597, acc: 69.25998263888889\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:01, 83.97it/s]\n",
      "INFO:TRAIN loss: 0.411482037027921, acc: 81.92306638913234\n",
      "24it [00:00, 119.00it/s]\n",
      "INFO:VAL loss: 0.6949964488546053, acc: 70.2396453373016\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:01, 83.46it/s]\n",
      "INFO:TRAIN loss: 0.40542277968002954, acc: 82.24077015775636\n",
      "24it [00:00, 119.31it/s]\n",
      "INFO:VAL loss: 0.6912315624455612, acc: 69.65370783730158\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:01, 83.81it/s]\n",
      "INFO:TRAIN loss: 0.4052501697481775, acc: 82.07347356120361\n",
      "24it [00:00, 117.54it/s]\n",
      "INFO:VAL loss: 0.7033378841976324, acc: 69.62115575396824\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:01, 83.89it/s]\n",
      "INFO:TRAIN loss: 0.40213731242103806, acc: 82.14057478819747\n",
      "24it [00:00, 117.92it/s]\n",
      "INFO:VAL loss: 0.6924914109210174, acc: 69.55605158730158\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:01, 83.76it/s]\n",
      "INFO:TRAIN loss: 0.4003427282798509, acc: 82.54135626643296\n",
      "24it [00:00, 116.82it/s]\n",
      "INFO:VAL loss: 0.7098297638197739, acc: 69.65370783730161\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:01, 83.66it/s]\n",
      "INFO:TRAIN loss: 0.40079167558371676, acc: 82.2891560765411\n",
      "24it [00:00, 116.95it/s]\n",
      "INFO:VAL loss: 0.6922105029225348, acc: 69.78391617063491\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:01, 83.93it/s]\n",
      "INFO:TRAIN loss: 0.39490188411408417, acc: 82.63858457493421\n",
      "24it [00:00, 117.82it/s]\n",
      "INFO:VAL loss: 0.7222961050768694, acc: 69.65680803571428\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:01, 82.33it/s]\n",
      "INFO:TRAIN loss: 0.3939028109875193, acc: 82.82984589541338\n",
      "24it [00:00, 117.88it/s]\n",
      "INFO:VAL loss: 0.7134707557658354, acc: 69.58860367063492\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:01, 83.77it/s]\n",
      "INFO:TRAIN loss: 0.3944786942443962, acc: 82.62329279871453\n",
      "24it [00:00, 119.23it/s]\n",
      "INFO:VAL loss: 0.70890108247598, acc: 69.78391617063492\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:01, 83.55it/s]\n",
      "INFO:TRAIN loss: 0.38944905127850044, acc: 82.99759896289804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 118.45it/s]\n",
      "INFO:VAL loss: 0.7537932172417641, acc: 69.52349950396824\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:01, 83.81it/s]\n",
      "INFO:TRAIN loss: 0.38847203598432034, acc: 83.2242367806018\n",
      "24it [00:00, 118.45it/s]\n",
      "INFO:VAL loss: 0.7502475306391716, acc: 69.94357638888889\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:01, 83.65it/s]\n",
      "INFO:TRAIN loss: 0.38778674620792164, acc: 83.1418437773883\n",
      "24it [00:00, 117.79it/s]\n",
      "INFO:VAL loss: 0.7527127104500929, acc: 69.42274305555553\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:01, 83.60it/s]\n",
      "INFO:TRAIN loss: 0.3834857145335777, acc: 83.26166739702012\n",
      "24it [00:00, 114.14it/s]\n",
      "INFO:VAL loss: 0.7699574679136276, acc: 69.26308283730158\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:01, 83.78it/s]\n",
      "INFO:TRAIN loss: 0.3810685492732044, acc: 83.3527333479404\n",
      "24it [00:00, 117.94it/s]\n",
      "INFO:VAL loss: 0.7905701932807764, acc: 69.32508680555557\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:01, 83.95it/s]\n",
      "INFO:TRAIN loss: 0.38184082325250834, acc: 83.3465709903593\n",
      "24it [00:00, 117.91it/s]\n",
      "INFO:VAL loss: 0.7773753503958384, acc: 69.81646825396824\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:01, 83.44it/s]\n",
      "INFO:TRAIN loss: 0.3813649390372761, acc: 83.40499926964651\n",
      "24it [00:00, 118.92it/s]\n",
      "INFO:VAL loss: 0.7579961630205313, acc: 69.88157242063492\n",
      "INFO:TRAIN: 49|50\n",
      "163it [00:01, 83.64it/s]\n",
      "INFO:TRAIN loss: 0.3786697384038587, acc: 83.81810546304413\n",
      "24it [00:00, 118.66it/s]\n",
      "INFO:VAL loss: 0.7600673101842405, acc: 69.84902033730158\n",
      "47it [00:00, 111.68it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.7547156829783258, acc: 69.9996977756286\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.6161152373062319, 0.5839604534254486, 0.5696957877442878, 0.5579417048056434, 0.5463560477721909, 0.5348448031153417, 0.5247476185026346, 0.5163099513463447, 0.5088532272657735, 0.505319605758585, 0.4956960963325266, 0.4894833359981609, 0.4871222565144849, 0.48037272326054015, 0.4770904214469933, 0.4684704002792849, 0.4654651198284757, 0.4592473508755856, 0.45651126730661445, 0.4534484104144795, 0.4508642440924615, 0.4463396353955649, 0.4435607403333933, 0.43995168859973277, 0.43661742305463075, 0.4320465874818205, 0.42911841286106356, 0.4253452186204175, 0.42557969067725665, 0.4211645089775506, 0.4167575971480529, 0.4155416806782682, 0.4126743707188799, 0.411482037027921, 0.40542277968002954, 0.4052501697481775, 0.40213731242103806, 0.4003427282798509, 0.40079167558371676, 0.39490188411408417, 0.3939028109875193, 0.3944786942443962, 0.38944905127850044, 0.38847203598432034, 0.38778674620792164, 0.3834857145335777, 0.3810685492732044, 0.38184082325250834, 0.3813649390372761, 0.3786697384038587], 'train_acc': [66.30331580484962, 69.61615359333913, 70.5633307770961, 71.57509859772128, 72.58640994741458, 73.62739190768329, 74.39471954425943, 74.9084775781478, 75.4286262050833, 75.7057040607654, 76.62777534326614, 76.96465089103127, 77.0002556237219, 77.35881354075376, 77.72969617294765, 78.15626825883726, 78.32265191352622, 78.87087350277534, 79.06829718083554, 78.99069712240718, 79.10435838445808, 79.78062007011391, 79.78107654104589, 80.08120617879054, 80.41990761028343, 80.55844653812443, 80.79900671925208, 81.071291630149, 80.82502556237218, 81.097766944201, 81.31344945953845, 81.61243791995327, 81.58984260882276, 81.92306638913234, 82.24077015775636, 82.07347356120361, 82.14057478819747, 82.54135626643296, 82.2891560765411, 82.63858457493421, 82.82984589541338, 82.62329279871453, 82.99759896289804, 83.2242367806018, 83.1418437773883, 83.26166739702012, 83.3527333479404, 83.3465709903593, 83.40499926964651, 83.81810546304413], 'val_loss': [0.6137542103727659, 0.6053479736049969, 0.5989865536491076, 0.5981337502598763, 0.5943284568687279, 0.594827717791001, 0.5967821404337883, 0.5940908019741377, 0.6072333641350269, 0.5947041151424248, 0.6044654759267966, 0.6118064547578494, 0.5946337394416332, 0.6023965924978256, 0.611320880552133, 0.6132879480719566, 0.6055898504952589, 0.62870562945803, 0.6247240615387758, 0.6287933699786663, 0.6292938850820065, 0.6320266574621202, 0.6334086693823336, 0.6361246667802334, 0.649938421944777, 0.6490655615925788, 0.6434849550326666, 0.665817288060983, 0.6632057850559554, 0.6697211811939876, 0.6492914520204067, 0.6820812659958999, 0.7025761790573597, 0.6949964488546053, 0.6912315624455612, 0.7033378841976324, 0.6924914109210174, 0.7098297638197739, 0.6922105029225348, 0.7222961050768694, 0.7134707557658354, 0.70890108247598, 0.7537932172417641, 0.7502475306391716, 0.7527127104500929, 0.7699574679136276, 0.7905701932807764, 0.7773753503958384, 0.7579961630205313, 0.7600673101842405], 'val_acc': [66.37369791666667, 68.24156746031747, 67.92534722222223, 68.8600570436508, 68.63219246031747, 68.99336557539681, 69.14682539682539, 68.91896081349206, 69.70021081349206, 68.9050099206349, 69.2599826388889, 69.15612599206351, 70.36365327380953, 69.13597470238096, 69.31888640873017, 69.15922619047618, 69.49094742063494, 69.29563492063492, 70.14818948412699, 69.5886036706349, 69.45219494047618, 70.21329365079366, 69.94357638888889, 69.39329117063492, 69.75136408730158, 70.11563740079366, 69.7870163690476, 69.62425595238096, 70.04743303571429, 69.9466765873016, 69.65680803571428, 69.88157242063491, 69.25998263888889, 70.2396453373016, 69.65370783730158, 69.62115575396824, 69.55605158730158, 69.65370783730161, 69.78391617063491, 69.65680803571428, 69.58860367063492, 69.78391617063492, 69.52349950396824, 69.94357638888889, 69.42274305555553, 69.26308283730158, 69.32508680555557, 69.81646825396824, 69.88157242063492, 69.84902033730158], 'test_loss': 0.7547156829783258, 'test_acc': 69.9996977756286}\n"
     ]
    }
   ],
   "source": [
    "# Model 5\n",
    "args.model_id=5\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_myembedding_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_myembedding_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_myembedding_test, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_Conv1d(embedding_size=100, num_channels=10, hidden_dim=100, label_nums=label_nums, dropout_p=0.1)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "args.logger.handlers.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d885084",
   "metadata": {},
   "source": [
    "**`acc:69.99`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c97304",
   "metadata": {},
   "source": [
    "We can see that model 5 is a slight but insignificant improvement over model 2. This is because the text used in model 5 is the top ten words of the tf-idf. There is no connection between the words themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13c52b",
   "metadata": {},
   "source": [
    "**`model 6: text--10word, embedding--pretrain embedding, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a18536c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=6, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=6, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:01, 83.45it/s]\n",
      "INFO:TRAIN loss: 0.6284085599922697, acc: 67.45453549517973\n",
      "INFO:TRAIN loss: 0.6284085599922697, acc: 67.45453549517973\n",
      "24it [00:00, 121.55it/s]\n",
      "INFO:VAL loss: 0.6327876734236877, acc: 65.16927083333336\n",
      "INFO:VAL loss: 0.6327876734236877, acc: 65.16927083333336\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:01, 84.25it/s]\n",
      "INFO:TRAIN loss: 0.6058234729649833, acc: 68.27709611451944\n",
      "INFO:TRAIN loss: 0.6058234729649833, acc: 68.27709611451944\n",
      "24it [00:00, 111.78it/s]\n",
      "INFO:VAL loss: 0.6203747813900312, acc: 66.5070064484127\n",
      "INFO:VAL loss: 0.6203747813900312, acc: 66.5070064484127\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:01, 83.63it/s]\n",
      "INFO:TRAIN loss: 0.5955017018903251, acc: 69.27357215892492\n",
      "INFO:TRAIN loss: 0.5955017018903251, acc: 69.27357215892492\n",
      "24it [00:00, 112.96it/s]\n",
      "INFO:VAL loss: 0.623059673855702, acc: 66.24348958333331\n",
      "INFO:VAL loss: 0.623059673855702, acc: 66.24348958333331\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:01, 85.95it/s]\n",
      "INFO:TRAIN loss: 0.5855808380556986, acc: 70.07969982471516\n",
      "INFO:TRAIN loss: 0.5855808380556986, acc: 70.07969982471516\n",
      "24it [00:00, 113.10it/s]\n",
      "INFO:VAL loss: 0.6191651386519275, acc: 66.91003224206351\n",
      "INFO:VAL loss: 0.6191651386519275, acc: 66.91003224206351\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:02, 81.14it/s]\n",
      "INFO:TRAIN loss: 0.5778923703848948, acc: 70.44396362839616\n",
      "INFO:TRAIN loss: 0.5778923703848948, acc: 70.44396362839616\n",
      "24it [00:00, 119.44it/s]\n",
      "INFO:VAL loss: 0.6176578899224601, acc: 66.54575892857143\n",
      "INFO:VAL loss: 0.6176578899224601, acc: 66.54575892857143\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:01, 85.36it/s]\n",
      "INFO:TRAIN loss: 0.5722528972143042, acc: 70.98031697341511\n",
      "INFO:TRAIN loss: 0.5722528972143042, acc: 70.98031697341511\n",
      "24it [00:00, 120.51it/s]\n",
      "INFO:VAL loss: 0.623863261193037, acc: 67.16734871031746\n",
      "INFO:VAL loss: 0.623863261193037, acc: 67.16734871031746\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:01, 84.77it/s]\n",
      "INFO:TRAIN loss: 0.5645554201003234, acc: 71.66182807478819\n",
      "INFO:TRAIN loss: 0.5645554201003234, acc: 71.66182807478819\n",
      "24it [00:00, 124.76it/s]\n",
      "INFO:VAL loss: 0.6290256790816784, acc: 67.06349206349208\n",
      "INFO:VAL loss: 0.6290256790816784, acc: 67.06349206349208\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:01, 88.08it/s]\n",
      "INFO:TRAIN loss: 0.5587901833232926, acc: 72.10711546888695\n",
      "INFO:TRAIN loss: 0.5587901833232926, acc: 72.10711546888695\n",
      "24it [00:00, 125.94it/s]\n",
      "INFO:VAL loss: 0.6228831137220064, acc: 67.43086557539684\n",
      "INFO:VAL loss: 0.6228831137220064, acc: 67.43086557539684\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:01, 87.89it/s]\n",
      "INFO:TRAIN loss: 0.5528062870897399, acc: 72.72928534910898\n",
      "INFO:TRAIN loss: 0.5528062870897399, acc: 72.72928534910898\n",
      "24it [00:00, 126.30it/s]\n",
      "INFO:VAL loss: 0.6293566698829335, acc: 67.23555307539682\n",
      "INFO:VAL loss: 0.6293566698829335, acc: 67.23555307539682\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:01, 84.17it/s]\n",
      "INFO:TRAIN loss: 0.5456798544690646, acc: 73.19557040607656\n",
      "INFO:TRAIN loss: 0.5456798544690646, acc: 73.19557040607656\n",
      "24it [00:00, 126.84it/s]\n",
      "INFO:VAL loss: 0.6274413901070754, acc: 67.33940972222221\n",
      "INFO:VAL loss: 0.6274413901070754, acc: 67.33940972222221\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:01, 85.07it/s]\n",
      "INFO:TRAIN loss: 0.5394232240191269, acc: 73.84307442302074\n",
      "INFO:TRAIN loss: 0.5394232240191269, acc: 73.84307442302074\n",
      "24it [00:00, 115.96it/s]\n",
      "INFO:VAL loss: 0.6396884309748808, acc: 67.33320932539684\n",
      "INFO:VAL loss: 0.6396884309748808, acc: 67.33320932539684\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:02, 81.48it/s]\n",
      "INFO:TRAIN loss: 0.5358472576170613, acc: 73.99553571428571\n",
      "INFO:TRAIN loss: 0.5358472576170613, acc: 73.99553571428571\n",
      "24it [00:00, 118.91it/s]\n",
      "INFO:VAL loss: 0.63722246636947, acc: 67.49596974206351\n",
      "INFO:VAL loss: 0.63722246636947, acc: 67.49596974206351\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:01, 84.50it/s]\n",
      "INFO:TRAIN loss: 0.5306646386904219, acc: 74.22034764826178\n",
      "INFO:TRAIN loss: 0.5306646386904219, acc: 74.22034764826178\n",
      "24it [00:00, 123.12it/s]\n",
      "INFO:VAL loss: 0.6414092853665354, acc: 67.29755704365078\n",
      "INFO:VAL loss: 0.6414092853665354, acc: 67.29755704365078\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:01, 87.69it/s]\n",
      "INFO:TRAIN loss: 0.5250034480372818, acc: 74.71835743499852\n",
      "INFO:TRAIN loss: 0.5250034480372818, acc: 74.71835743499852\n",
      "24it [00:00, 125.93it/s]\n",
      "INFO:VAL loss: 0.6528103624780973, acc: 66.94258432539682\n",
      "INFO:VAL loss: 0.6528103624780973, acc: 66.94258432539682\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:01, 85.66it/s]\n",
      "INFO:TRAIN loss: 0.5196043441266374, acc: 75.10704243353781\n",
      "INFO:TRAIN loss: 0.5196043441266374, acc: 75.10704243353781\n",
      "24it [00:00, 123.13it/s]\n",
      "INFO:VAL loss: 0.6604943486551443, acc: 67.10534474206351\n",
      "INFO:VAL loss: 0.6604943486551443, acc: 67.10534474206351\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:01, 86.95it/s]\n",
      "INFO:TRAIN loss: 0.5171216739101644, acc: 75.2369084136722\n",
      "INFO:TRAIN loss: 0.5171216739101644, acc: 75.2369084136722\n",
      "24it [00:00, 125.58it/s]\n",
      "INFO:VAL loss: 0.6686105467379093, acc: 67.04024057539681\n",
      "INFO:VAL loss: 0.6686105467379093, acc: 67.04024057539681\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:01, 85.92it/s]\n",
      "INFO:TRAIN loss: 0.50870421492249, acc: 75.83739592462754\n",
      "INFO:TRAIN loss: 0.50870421492249, acc: 75.83739592462754\n",
      "24it [00:00, 113.34it/s]\n",
      "INFO:VAL loss: 0.6693987064063549, acc: 67.23555307539681\n",
      "INFO:VAL loss: 0.6693987064063549, acc: 67.23555307539681\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:01, 85.63it/s]\n",
      "INFO:TRAIN loss: 0.5069142318576391, acc: 76.1480243938066\n",
      "INFO:TRAIN loss: 0.5069142318576391, acc: 76.1480243938066\n",
      "24it [00:00, 125.97it/s]\n",
      "INFO:VAL loss: 0.6756401273111502, acc: 66.19388640873017\n",
      "INFO:VAL loss: 0.6756401273111502, acc: 66.19388640873017\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:01, 82.74it/s]\n",
      "INFO:TRAIN loss: 0.5046390426670849, acc: 76.20941973415128\n",
      "INFO:TRAIN loss: 0.5046390426670849, acc: 76.20941973415128\n",
      "24it [00:00, 120.54it/s]\n",
      "INFO:VAL loss: 0.6715414971113205, acc: 67.26810515873017\n",
      "INFO:VAL loss: 0.6715414971113205, acc: 67.26810515873017\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:01, 83.58it/s]\n",
      "INFO:TRAIN loss: 0.5002887077126766, acc: 76.42030930470354\n",
      "INFO:TRAIN loss: 0.5002887077126766, acc: 76.42030930470354\n",
      "24it [00:00, 121.31it/s]\n",
      "INFO:VAL loss: 0.6855788019796212, acc: 66.35664682539682\n",
      "INFO:VAL loss: 0.6855788019796212, acc: 66.35664682539682\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:01, 85.58it/s]\n",
      "INFO:TRAIN loss: 0.49512454903930236, acc: 76.9379473415133\n",
      "INFO:TRAIN loss: 0.49512454903930236, acc: 76.9379473415133\n",
      "24it [00:00, 125.55it/s]\n",
      "INFO:VAL loss: 0.6917219671110312, acc: 66.81237599206348\n",
      "INFO:VAL loss: 0.6917219671110312, acc: 66.81237599206348\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:01, 87.07it/s]\n",
      "INFO:TRAIN loss: 0.4913731813430787, acc: 77.09269098743789\n",
      "INFO:TRAIN loss: 0.4913731813430787, acc: 77.09269098743789\n",
      "24it [00:00, 121.72it/s]\n",
      "INFO:VAL loss: 0.6879500932991504, acc: 66.84182787698411\n",
      "INFO:VAL loss: 0.6879500932991504, acc: 66.84182787698411\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:01, 86.18it/s]\n",
      "INFO:TRAIN loss: 0.4904365724215479, acc: 77.37501825883726\n",
      "INFO:TRAIN loss: 0.4904365724215479, acc: 77.37501825883726\n",
      "24it [00:00, 120.34it/s]\n",
      "INFO:VAL loss: 0.6911984086036682, acc: 67.26810515873015\n",
      "INFO:VAL loss: 0.6911984086036682, acc: 67.26810515873015\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:01, 84.93it/s]\n",
      "INFO:TRAIN loss: 0.4844111121870989, acc: 77.22643697049374\n",
      "INFO:TRAIN loss: 0.4844111121870989, acc: 77.22643697049374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 116.91it/s]\n",
      "INFO:VAL loss: 0.7109988369047642, acc: 66.6170634920635\n",
      "INFO:VAL loss: 0.7109988369047642, acc: 66.6170634920635\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:01, 87.76it/s]\n",
      "INFO:TRAIN loss: 0.48298027361828877, acc: 77.72581617002632\n",
      "INFO:TRAIN loss: 0.48298027361828877, acc: 77.72581617002632\n",
      "24it [00:00, 124.08it/s]\n",
      "INFO:VAL loss: 0.696648276100556, acc: 67.3983134920635\n",
      "INFO:VAL loss: 0.696648276100556, acc: 67.3983134920635\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:01, 87.78it/s]\n",
      "INFO:TRAIN loss: 0.48009796486310435, acc: 77.75457383873793\n",
      "INFO:TRAIN loss: 0.48009796486310435, acc: 77.75457383873793\n",
      "24it [00:00, 125.69it/s]\n",
      "INFO:VAL loss: 0.7138313030203183, acc: 67.36576140873018\n",
      "INFO:VAL loss: 0.7138313030203183, acc: 67.36576140873018\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:01, 87.84it/s]\n",
      "INFO:TRAIN loss: 0.476972323619515, acc: 77.80159034472689\n",
      "INFO:TRAIN loss: 0.476972323619515, acc: 77.80159034472689\n",
      "24it [00:00, 127.50it/s]\n",
      "INFO:VAL loss: 0.7185144312679769, acc: 67.43396577380952\n",
      "INFO:VAL loss: 0.7185144312679769, acc: 67.43396577380952\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:01, 83.01it/s]\n",
      "INFO:TRAIN loss: 0.4741880573743691, acc: 77.90703513000294\n",
      "INFO:TRAIN loss: 0.4741880573743691, acc: 77.90703513000294\n",
      "24it [00:00, 117.19it/s]\n",
      "INFO:VAL loss: 0.7057313434779644, acc: 67.20300099206348\n",
      "INFO:VAL loss: 0.7057313434779644, acc: 67.20300099206348\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:01, 86.85it/s]\n",
      "INFO:TRAIN loss: 0.47068681307365556, acc: 78.24299773590415\n",
      "INFO:TRAIN loss: 0.47068681307365556, acc: 78.24299773590415\n",
      "24it [00:00, 128.02it/s]\n",
      "INFO:VAL loss: 0.7222657923897108, acc: 67.27120535714285\n",
      "INFO:VAL loss: 0.7222657923897108, acc: 67.27120535714285\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:01, 88.54it/s]\n",
      "INFO:TRAIN loss: 0.4673548609566835, acc: 78.57234151329246\n",
      "INFO:TRAIN loss: 0.4673548609566835, acc: 78.57234151329246\n",
      "24it [00:00, 122.85it/s]\n",
      "INFO:VAL loss: 0.7108053639531138, acc: 67.75638640873014\n",
      "INFO:VAL loss: 0.7108053639531138, acc: 67.75638640873014\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:01, 84.57it/s]\n",
      "INFO:TRAIN loss: 0.4630008127791751, acc: 78.82385699678645\n",
      "INFO:TRAIN loss: 0.4630008127791751, acc: 78.82385699678645\n",
      "24it [00:00, 124.03it/s]\n",
      "INFO:VAL loss: 0.7379015001157919, acc: 66.4574032738095\n",
      "INFO:VAL loss: 0.7379015001157919, acc: 66.4574032738095\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:01, 85.46it/s]\n",
      "INFO:TRAIN loss: 0.4649722667559525, acc: 78.53491089687412\n",
      "INFO:TRAIN loss: 0.4649722667559525, acc: 78.53491089687412\n",
      "24it [00:00, 121.19it/s]\n",
      "INFO:VAL loss: 0.7227218374609947, acc: 67.10224454365081\n",
      "INFO:VAL loss: 0.7227218374609947, acc: 67.10224454365081\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:01, 84.57it/s]\n",
      "INFO:TRAIN loss: 0.461284935108723, acc: 78.77980755185511\n",
      "INFO:TRAIN loss: 0.461284935108723, acc: 78.77980755185511\n",
      "24it [00:00, 111.71it/s]\n",
      "INFO:VAL loss: 0.7357808897892635, acc: 67.04024057539684\n",
      "INFO:VAL loss: 0.7357808897892635, acc: 67.04024057539684\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:01, 85.02it/s]\n",
      "INFO:TRAIN loss: 0.45788586925875197, acc: 78.94664767747592\n",
      "INFO:TRAIN loss: 0.45788586925875197, acc: 78.94664767747592\n",
      "24it [00:00, 121.42it/s]\n",
      "INFO:VAL loss: 0.7416096664965152, acc: 67.26810515873014\n",
      "INFO:VAL loss: 0.7416096664965152, acc: 67.26810515873014\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:01, 84.69it/s]\n",
      "INFO:TRAIN loss: 0.45739509814355994, acc: 78.93888767163307\n",
      "INFO:TRAIN loss: 0.45739509814355994, acc: 78.93888767163307\n",
      "24it [00:00, 125.57it/s]\n",
      "INFO:VAL loss: 0.7392639704048634, acc: 66.84492807539681\n",
      "INFO:VAL loss: 0.7392639704048634, acc: 66.84492807539681\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:01, 84.81it/s]\n",
      "INFO:TRAIN loss: 0.4531017490691202, acc: 79.32665972830847\n",
      "INFO:TRAIN loss: 0.4531017490691202, acc: 79.32665972830847\n",
      "24it [00:00, 122.10it/s]\n",
      "INFO:VAL loss: 0.7522769048810005, acc: 67.13789682539682\n",
      "INFO:VAL loss: 0.7522769048810005, acc: 67.13789682539682\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:01, 85.33it/s]\n",
      "INFO:TRAIN loss: 0.4542480447540985, acc: 79.32049737072748\n",
      "INFO:TRAIN loss: 0.4542480447540985, acc: 79.32049737072748\n",
      "24it [00:00, 120.44it/s]\n",
      "INFO:VAL loss: 0.7675111417969067, acc: 67.26810515873014\n",
      "INFO:VAL loss: 0.7675111417969067, acc: 67.26810515873014\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:01, 84.86it/s]\n",
      "INFO:TRAIN loss: 0.4517243098627568, acc: 79.11348780309673\n",
      "INFO:TRAIN loss: 0.4517243098627568, acc: 79.11348780309673\n",
      "24it [00:00, 122.90it/s]\n",
      "INFO:VAL loss: 0.7674737970034282, acc: 67.17044890873017\n",
      "INFO:VAL loss: 0.7674737970034282, acc: 67.17044890873017\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:01, 87.68it/s]\n",
      "INFO:TRAIN loss: 0.44634498061577965, acc: 79.84201541045867\n",
      "INFO:TRAIN loss: 0.44634498061577965, acc: 79.84201541045867\n",
      "24it [00:00, 128.58it/s]\n",
      "INFO:VAL loss: 0.7759547382593156, acc: 67.3006572420635\n",
      "INFO:VAL loss: 0.7759547382593156, acc: 67.3006572420635\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:01, 87.88it/s]\n",
      "INFO:TRAIN loss: 0.4449289704393023, acc: 79.61286700262922\n",
      "INFO:TRAIN loss: 0.4449289704393023, acc: 79.61286700262922\n",
      "24it [00:00, 120.58it/s]\n",
      "INFO:VAL loss: 0.7708526986340682, acc: 67.2030009920635\n",
      "INFO:VAL loss: 0.7708526986340682, acc: 67.2030009920635\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:01, 84.15it/s]\n",
      "INFO:TRAIN loss: 0.4463483848454762, acc: 79.56836108676599\n",
      "INFO:TRAIN loss: 0.4463483848454762, acc: 79.56836108676599\n",
      "24it [00:00, 122.25it/s]\n",
      "INFO:VAL loss: 0.7849361412227154, acc: 67.17044890873015\n",
      "INFO:VAL loss: 0.7849361412227154, acc: 67.17044890873015\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:01, 87.31it/s]\n",
      "INFO:TRAIN loss: 0.4439400514942006, acc: 79.80070479111895\n",
      "INFO:TRAIN loss: 0.4439400514942006, acc: 79.80070479111895\n",
      "24it [00:00, 120.74it/s]\n",
      "INFO:VAL loss: 0.7980241601665814, acc: 66.77982390873017\n",
      "INFO:VAL loss: 0.7980241601665814, acc: 66.77982390873017\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:01, 85.98it/s]\n",
      "INFO:TRAIN loss: 0.43951451979531825, acc: 79.89222721297114\n",
      "INFO:TRAIN loss: 0.43951451979531825, acc: 79.89222721297114\n",
      "24it [00:00, 126.17it/s]\n",
      "INFO:VAL loss: 0.8120329864323141, acc: 66.19388640873017\n",
      "INFO:VAL loss: 0.8120329864323141, acc: 66.19388640873017\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:01, 85.89it/s]\n",
      "INFO:TRAIN loss: 0.4384741166983644, acc: 80.13141798130293\n",
      "INFO:TRAIN loss: 0.4384741166983644, acc: 80.13141798130293\n",
      "24it [00:00, 119.20it/s]\n",
      "INFO:VAL loss: 0.8007314043740432, acc: 66.94258432539685\n",
      "INFO:VAL loss: 0.8007314043740432, acc: 66.94258432539685\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:01, 84.93it/s]\n",
      "INFO:TRAIN loss: 0.4394947670720107, acc: 79.69822706690037\n",
      "INFO:TRAIN loss: 0.4394947670720107, acc: 79.69822706690037\n",
      "24it [00:00, 122.94it/s]\n",
      "INFO:VAL loss: 0.7866789276401202, acc: 66.55195932539682\n",
      "INFO:VAL loss: 0.7866789276401202, acc: 66.55195932539682\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:01, 83.29it/s]\n",
      "INFO:TRAIN loss: 0.43852650625574074, acc: 79.88606485539005\n",
      "INFO:TRAIN loss: 0.43852650625574074, acc: 79.88606485539005\n",
      "24it [00:00, 118.17it/s]\n",
      "INFO:VAL loss: 0.7972381971776487, acc: 66.71161954365078\n",
      "INFO:VAL loss: 0.7972381971776487, acc: 66.71161954365078\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:01, 82.19it/s]\n",
      "INFO:TRAIN loss: 0.43540168101070853, acc: 80.05039439088516\n",
      "INFO:TRAIN loss: 0.43540168101070853, acc: 80.05039439088516\n",
      "24it [00:00, 115.46it/s]\n",
      "INFO:VAL loss: 0.8000379279255866, acc: 67.13789682539681\n",
      "INFO:VAL loss: 0.8000379279255866, acc: 67.13789682539681\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:01, 83.63it/s]\n",
      "INFO:TRAIN loss: 0.4316758773078217, acc: 80.05998028045572\n",
      "INFO:TRAIN loss: 0.4316758773078217, acc: 80.05998028045572\n",
      "24it [00:00, 119.55it/s]\n",
      "INFO:VAL loss: 0.8283398834367593, acc: 66.9100322420635\n",
      "INFO:VAL loss: 0.8283398834367593, acc: 66.9100322420635\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:01, 83.60it/s]\n",
      "INFO:TRAIN loss: 0.4317996790804014, acc: 80.12434268185804\n",
      "INFO:TRAIN loss: 0.4317996790804014, acc: 80.12434268185804\n",
      "24it [00:00, 125.17it/s]\n",
      "INFO:VAL loss: 0.8088889072338741, acc: 66.55195932539682\n",
      "INFO:VAL loss: 0.8088889072338741, acc: 66.55195932539682\n",
      "INFO:TRAIN: 49|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN: 49|50\n",
      "163it [00:01, 85.47it/s]\n",
      "INFO:TRAIN loss: 0.4310009241835472, acc: 80.15492623429742\n",
      "INFO:TRAIN loss: 0.4310009241835472, acc: 80.15492623429742\n",
      "24it [00:00, 124.08it/s]\n",
      "INFO:VAL loss: 0.8172386772930624, acc: 66.84492807539682\n",
      "INFO:VAL loss: 0.8172386772930624, acc: 66.84492807539682\n",
      "47it [00:00, 118.97it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.7838192487016636, acc: 67.13612185686654\n",
      "INFO:\n",
      "\n",
      "TEST loss: 0.7838192487016636, acc: 67.13612185686654\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.6284085599922697, 0.6058234729649833, 0.5955017018903251, 0.5855808380556986, 0.5778923703848948, 0.5722528972143042, 0.5645554201003234, 0.5587901833232926, 0.5528062870897399, 0.5456798544690646, 0.5394232240191269, 0.5358472576170613, 0.5306646386904219, 0.5250034480372818, 0.5196043441266374, 0.5171216739101644, 0.50870421492249, 0.5069142318576391, 0.5046390426670849, 0.5002887077126766, 0.49512454903930236, 0.4913731813430787, 0.4904365724215479, 0.4844111121870989, 0.48298027361828877, 0.48009796486310435, 0.476972323619515, 0.4741880573743691, 0.47068681307365556, 0.4673548609566835, 0.4630008127791751, 0.4649722667559525, 0.461284935108723, 0.45788586925875197, 0.45739509814355994, 0.4531017490691202, 0.4542480447540985, 0.4517243098627568, 0.44634498061577965, 0.4449289704393023, 0.4463483848454762, 0.4439400514942006, 0.43951451979531825, 0.4384741166983644, 0.4394947670720107, 0.43852650625574074, 0.43540168101070853, 0.4316758773078217, 0.4317996790804014, 0.4310009241835472], 'train_acc': [67.45453549517973, 68.27709611451944, 69.27357215892492, 70.07969982471516, 70.44396362839616, 70.98031697341511, 71.66182807478819, 72.10711546888695, 72.72928534910898, 73.19557040607656, 73.84307442302074, 73.99553571428571, 74.22034764826178, 74.71835743499852, 75.10704243353781, 75.2369084136722, 75.83739592462754, 76.1480243938066, 76.20941973415128, 76.42030930470354, 76.9379473415133, 77.09269098743789, 77.37501825883726, 77.22643697049374, 77.72581617002632, 77.75457383873793, 77.80159034472689, 77.90703513000294, 78.24299773590415, 78.57234151329246, 78.82385699678645, 78.53491089687412, 78.77980755185511, 78.94664767747592, 78.93888767163307, 79.32665972830847, 79.32049737072748, 79.11348780309673, 79.84201541045867, 79.61286700262922, 79.56836108676599, 79.80070479111895, 79.89222721297114, 80.13141798130293, 79.69822706690037, 79.88606485539005, 80.05039439088516, 80.05998028045572, 80.12434268185804, 80.15492623429742], 'val_loss': [0.6327876734236877, 0.6203747813900312, 0.623059673855702, 0.6191651386519275, 0.6176578899224601, 0.623863261193037, 0.6290256790816784, 0.6228831137220064, 0.6293566698829335, 0.6274413901070754, 0.6396884309748808, 0.63722246636947, 0.6414092853665354, 0.6528103624780973, 0.6604943486551443, 0.6686105467379093, 0.6693987064063549, 0.6756401273111502, 0.6715414971113205, 0.6855788019796212, 0.6917219671110312, 0.6879500932991504, 0.6911984086036682, 0.7109988369047642, 0.696648276100556, 0.7138313030203183, 0.7185144312679769, 0.7057313434779644, 0.7222657923897108, 0.7108053639531138, 0.7379015001157919, 0.7227218374609947, 0.7357808897892635, 0.7416096664965152, 0.7392639704048634, 0.7522769048810005, 0.7675111417969067, 0.7674737970034282, 0.7759547382593156, 0.7708526986340682, 0.7849361412227154, 0.7980241601665814, 0.8120329864323141, 0.8007314043740432, 0.7866789276401202, 0.7972381971776487, 0.8000379279255866, 0.8283398834367593, 0.8088889072338741, 0.8172386772930624], 'val_acc': [65.16927083333336, 66.5070064484127, 66.24348958333331, 66.91003224206351, 66.54575892857143, 67.16734871031746, 67.06349206349208, 67.43086557539684, 67.23555307539682, 67.33940972222221, 67.33320932539684, 67.49596974206351, 67.29755704365078, 66.94258432539682, 67.10534474206351, 67.04024057539681, 67.23555307539681, 66.19388640873017, 67.26810515873017, 66.35664682539682, 66.81237599206348, 66.84182787698411, 67.26810515873015, 66.6170634920635, 67.3983134920635, 67.36576140873018, 67.43396577380952, 67.20300099206348, 67.27120535714285, 67.75638640873014, 66.4574032738095, 67.10224454365081, 67.04024057539684, 67.26810515873014, 66.84492807539681, 67.13789682539682, 67.26810515873014, 67.17044890873017, 67.3006572420635, 67.2030009920635, 67.17044890873015, 66.77982390873017, 66.19388640873017, 66.94258432539685, 66.55195932539682, 66.71161954365078, 67.13789682539681, 66.9100322420635, 66.55195932539682, 66.84492807539682], 'test_loss': 0.7838192487016636, 'test_acc': 67.13612185686654}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [0.6284085599922697, 0.6058234729649833, 0.5955017018903251, 0.5855808380556986, 0.5778923703848948, 0.5722528972143042, 0.5645554201003234, 0.5587901833232926, 0.5528062870897399, 0.5456798544690646, 0.5394232240191269, 0.5358472576170613, 0.5306646386904219, 0.5250034480372818, 0.5196043441266374, 0.5171216739101644, 0.50870421492249, 0.5069142318576391, 0.5046390426670849, 0.5002887077126766, 0.49512454903930236, 0.4913731813430787, 0.4904365724215479, 0.4844111121870989, 0.48298027361828877, 0.48009796486310435, 0.476972323619515, 0.4741880573743691, 0.47068681307365556, 0.4673548609566835, 0.4630008127791751, 0.4649722667559525, 0.461284935108723, 0.45788586925875197, 0.45739509814355994, 0.4531017490691202, 0.4542480447540985, 0.4517243098627568, 0.44634498061577965, 0.4449289704393023, 0.4463483848454762, 0.4439400514942006, 0.43951451979531825, 0.4384741166983644, 0.4394947670720107, 0.43852650625574074, 0.43540168101070853, 0.4316758773078217, 0.4317996790804014, 0.4310009241835472], 'train_acc': [67.45453549517973, 68.27709611451944, 69.27357215892492, 70.07969982471516, 70.44396362839616, 70.98031697341511, 71.66182807478819, 72.10711546888695, 72.72928534910898, 73.19557040607656, 73.84307442302074, 73.99553571428571, 74.22034764826178, 74.71835743499852, 75.10704243353781, 75.2369084136722, 75.83739592462754, 76.1480243938066, 76.20941973415128, 76.42030930470354, 76.9379473415133, 77.09269098743789, 77.37501825883726, 77.22643697049374, 77.72581617002632, 77.75457383873793, 77.80159034472689, 77.90703513000294, 78.24299773590415, 78.57234151329246, 78.82385699678645, 78.53491089687412, 78.77980755185511, 78.94664767747592, 78.93888767163307, 79.32665972830847, 79.32049737072748, 79.11348780309673, 79.84201541045867, 79.61286700262922, 79.56836108676599, 79.80070479111895, 79.89222721297114, 80.13141798130293, 79.69822706690037, 79.88606485539005, 80.05039439088516, 80.05998028045572, 80.12434268185804, 80.15492623429742], 'val_loss': [0.6327876734236877, 0.6203747813900312, 0.623059673855702, 0.6191651386519275, 0.6176578899224601, 0.623863261193037, 0.6290256790816784, 0.6228831137220064, 0.6293566698829335, 0.6274413901070754, 0.6396884309748808, 0.63722246636947, 0.6414092853665354, 0.6528103624780973, 0.6604943486551443, 0.6686105467379093, 0.6693987064063549, 0.6756401273111502, 0.6715414971113205, 0.6855788019796212, 0.6917219671110312, 0.6879500932991504, 0.6911984086036682, 0.7109988369047642, 0.696648276100556, 0.7138313030203183, 0.7185144312679769, 0.7057313434779644, 0.7222657923897108, 0.7108053639531138, 0.7379015001157919, 0.7227218374609947, 0.7357808897892635, 0.7416096664965152, 0.7392639704048634, 0.7522769048810005, 0.7675111417969067, 0.7674737970034282, 0.7759547382593156, 0.7708526986340682, 0.7849361412227154, 0.7980241601665814, 0.8120329864323141, 0.8007314043740432, 0.7866789276401202, 0.7972381971776487, 0.8000379279255866, 0.8283398834367593, 0.8088889072338741, 0.8172386772930624], 'val_acc': [65.16927083333336, 66.5070064484127, 66.24348958333331, 66.91003224206351, 66.54575892857143, 67.16734871031746, 67.06349206349208, 67.43086557539684, 67.23555307539682, 67.33940972222221, 67.33320932539684, 67.49596974206351, 67.29755704365078, 66.94258432539682, 67.10534474206351, 67.04024057539681, 67.23555307539681, 66.19388640873017, 67.26810515873017, 66.35664682539682, 66.81237599206348, 66.84182787698411, 67.26810515873015, 66.6170634920635, 67.3983134920635, 67.36576140873018, 67.43396577380952, 67.20300099206348, 67.27120535714285, 67.75638640873014, 66.4574032738095, 67.10224454365081, 67.04024057539684, 67.26810515873014, 66.84492807539681, 67.13789682539682, 67.26810515873014, 67.17044890873017, 67.3006572420635, 67.2030009920635, 67.17044890873015, 66.77982390873017, 66.19388640873017, 66.94258432539685, 66.55195932539682, 66.71161954365078, 67.13789682539681, 66.9100322420635, 66.55195932539682, 66.84492807539682], 'test_loss': 0.7838192487016636, 'test_acc': 67.13612185686654}\n"
     ]
    }
   ],
   "source": [
    "# Model 6\n",
    "args.model_id=6\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_pretrainembedding_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_pretrainembedding_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_pretrainembedding_test, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_Conv1d(embedding_size=100, num_channels=10, hidden_dim=100, label_nums=label_nums, dropout_p=0.1)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "args.logger.handlers.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be86bc",
   "metadata": {},
   "source": [
    "**`acc:67.13`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b2606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03d7886",
   "metadata": {},
   "source": [
    "**`model 7: text--job_description, embedding--onehot, model--feed_forward`** can not achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd9b41a",
   "metadata": {},
   "source": [
    "**`model 8: text--job_description, embedding--my_embedding, model--feed_forward`** can not achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ecde6",
   "metadata": {},
   "source": [
    "**`model 9: text--job_description, embedding--pretrain embedding, model--feed_forward`** can not achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c30b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7e93ce8",
   "metadata": {},
   "source": [
    "## Full Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0240ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dataset\n",
    "jobvectorizer = JobVectorizer.from_dataframe(df, text_column=\"job_description\", cutoff=10)\n",
    "\n",
    "jobtype_onehot_train_full = JobDatasetOnehot(train_df, vectorizer=jobvectorizer, text_column=\"job_description\", label_column=label_column)\n",
    "jobtype_onehot_val_full = JobDatasetOnehot(val_df, vectorizer=jobvectorizer, text_column=\"job_description\", label_column=label_column)\n",
    "jobtype_onehot_test_full = JobDatasetOnehot(test_df, vectorizer=jobvectorizer, text_column=\"job_description\", label_column=label_column)\n",
    "\n",
    "\n",
    "jobtype_myembedding_train_full = JobDatasetMyembedding(train_df, embedding=my_embedding.wv, text_column=\"job_description\", label_column=label_column, words_len=128)\n",
    "jobtype_myembedding_val_full = JobDatasetMyembedding(val_df, embedding=my_embedding.wv, text_column=\"job_description\", label_column=label_column, words_len=128)\n",
    "jobtype_myembedding_test_full = JobDatasetMyembedding(test_df, embedding=my_embedding.wv, text_column=\"job_description\", label_column=label_column, words_len=128)\n",
    "\n",
    "jobtype_prainembedding_train_full = JobDatasetPretrainembedding(train_df, text_column=\"job_description\", label_column=label_column, words_len=128)\n",
    "jobtype_prainembedding_val_full = JobDatasetPretrainembedding(val_df, text_column=\"job_description\", label_column=label_column, words_len=128)\n",
    "jobtype_prainembedding_test_full = JobDatasetPretrainembedding(test_df, text_column=\"job_description\", label_column=label_column, words_len=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34881faf",
   "metadata": {},
   "source": [
    "**`model 10: text--job_description, embedding--onehot, model--conv1d`** can not achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ac5c18c",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'max_pool_size' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(jobtype_onehot_val_full, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m      8\u001b[0m state \u001b[38;5;241m=\u001b[39m make_train_state() \n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mJobtypeClassifier_Conv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10646\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_nums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_nums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m args\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m     11\u001b[0m args\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m get_logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./log\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(args\u001b[38;5;241m.\u001b[39mmodel_id)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtrain_dataloader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/OneDrive - The University of Western Australia/2022 sem1/CITS4012 NLP/project2/models.py:56\u001b[0m, in \u001b[0;36mJobtypeClassifier_Conv1d.__init__\u001b[0;34m(self, embedding_size, num_channels, hidden_dim, label_nums, dropout_p)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m num_channels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3954\u001b[39m:\n\u001b[1;32m     54\u001b[0m     max_pool_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMaxPool1d(\u001b[43mmax_pool_size\u001b[49m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrlue \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_channels, hidden_dim)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'max_pool_size' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Model 10\n",
    "args.model_id=10\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_onehot_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_onehot_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_onehot_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_Conv1d(embedding_size=1, num_channels=10646, hidden_dim=128, label_nums=label_nums, dropout_p=0.1)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "args.logger.handlers.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8707f1",
   "metadata": {},
   "source": [
    "**acc：82.00**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f05fa36",
   "metadata": {},
   "source": [
    "Suddenly there is a higher acc, consider the overfitting phenomenon,may need to adjust the dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e233267",
   "metadata": {},
   "source": [
    "**`model 11: text--job_description, embedding--my_embedding, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b98c856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=11, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=11, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=11, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:40,  4.05it/s]\n",
      "INFO:TRAIN loss: 2.0522606321639083, acc: 40.264387963774475\n",
      "INFO:TRAIN loss: 2.0522606321639083, acc: 40.264387963774475\n",
      "INFO:TRAIN loss: 2.0522606321639083, acc: 40.264387963774475\n",
      "24it [00:02,  8.04it/s]\n",
      "INFO:VAL loss: 1.4663044313589733, acc: 57.34126984126985\n",
      "INFO:VAL loss: 1.4663044313589733, acc: 57.34126984126985\n",
      "INFO:VAL loss: 1.4663044313589733, acc: 57.34126984126985\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:40,  4.05it/s]\n",
      "INFO:TRAIN loss: 1.390689462240488, acc: 58.878587861524984\n",
      "INFO:TRAIN loss: 1.390689462240488, acc: 58.878587861524984\n",
      "INFO:TRAIN loss: 1.390689462240488, acc: 58.878587861524984\n",
      "24it [00:02,  8.10it/s]\n",
      "INFO:VAL loss: 1.2536193778117497, acc: 63.06733630952381\n",
      "INFO:VAL loss: 1.2536193778117497, acc: 63.06733630952381\n",
      "INFO:VAL loss: 1.2536193778117497, acc: 63.06733630952381\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:40,  4.05it/s]\n",
      "INFO:TRAIN loss: 1.1889687915521163, acc: 64.49066973415135\n",
      "INFO:TRAIN loss: 1.1889687915521163, acc: 64.49066973415135\n",
      "INFO:TRAIN loss: 1.1889687915521163, acc: 64.49066973415135\n",
      "24it [00:03,  7.87it/s]\n",
      "INFO:VAL loss: 1.1591115072369573, acc: 65.47929067460318\n",
      "INFO:VAL loss: 1.1591115072369573, acc: 65.47929067460318\n",
      "INFO:VAL loss: 1.1591115072369573, acc: 65.47929067460318\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:40,  4.07it/s]\n",
      "INFO:TRAIN loss: 1.0685461477999316, acc: 68.17028191644758\n",
      "INFO:TRAIN loss: 1.0685461477999316, acc: 68.17028191644758\n",
      "INFO:TRAIN loss: 1.0685461477999316, acc: 68.17028191644758\n",
      "24it [00:02,  8.32it/s]\n",
      "INFO:VAL loss: 1.0579699724912643, acc: 68.90035962301587\n",
      "INFO:VAL loss: 1.0579699724912643, acc: 68.90035962301587\n",
      "INFO:VAL loss: 1.0579699724912643, acc: 68.90035962301587\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:39,  4.17it/s]\n",
      "INFO:TRAIN loss: 0.97834705136305, acc: 70.70141323400526\n",
      "INFO:TRAIN loss: 0.97834705136305, acc: 70.70141323400526\n",
      "INFO:TRAIN loss: 0.97834705136305, acc: 70.70141323400526\n",
      "24it [00:02,  8.35it/s]\n",
      "INFO:VAL loss: 1.0687980900208156, acc: 69.06312003968253\n",
      "INFO:VAL loss: 1.0687980900208156, acc: 69.06312003968253\n",
      "INFO:VAL loss: 1.0687980900208156, acc: 69.06312003968253\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:40,  3.98it/s]\n",
      "INFO:TRAIN loss: 0.8967736889979592, acc: 72.57203111305871\n",
      "INFO:TRAIN loss: 0.8967736889979592, acc: 72.57203111305871\n",
      "INFO:TRAIN loss: 0.8967736889979592, acc: 72.57203111305871\n",
      "24it [00:02,  8.07it/s]\n",
      "INFO:VAL loss: 1.0498034159342449, acc: 69.94202628968253\n",
      "INFO:VAL loss: 1.0498034159342449, acc: 69.94202628968253\n",
      "INFO:VAL loss: 1.0498034159342449, acc: 69.94202628968253\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:40,  4.05it/s]\n",
      "INFO:TRAIN loss: 0.828635947470285, acc: 74.3938066023956\n",
      "INFO:TRAIN loss: 0.828635947470285, acc: 74.3938066023956\n",
      "INFO:TRAIN loss: 0.828635947470285, acc: 74.3938066023956\n",
      "24it [00:03,  7.68it/s]\n",
      "INFO:VAL loss: 1.0370397120714183, acc: 70.13733878968254\n",
      "INFO:VAL loss: 1.0370397120714183, acc: 70.13733878968254\n",
      "INFO:VAL loss: 1.0370397120714183, acc: 70.13733878968254\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:41,  3.94it/s]\n",
      "INFO:TRAIN loss: 0.751125992075797, acc: 76.6325682880514\n",
      "INFO:TRAIN loss: 0.751125992075797, acc: 76.6325682880514\n",
      "INFO:TRAIN loss: 0.751125992075797, acc: 76.6325682880514\n",
      "24it [00:03,  7.79it/s]\n",
      "INFO:VAL loss: 1.043759753306707, acc: 69.8800223214286\n",
      "INFO:VAL loss: 1.043759753306707, acc: 69.8800223214286\n",
      "INFO:VAL loss: 1.043759753306707, acc: 69.8800223214286\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:41,  3.97it/s]\n",
      "INFO:TRAIN loss: 0.697122481154518, acc: 77.81505623721883\n",
      "INFO:TRAIN loss: 0.697122481154518, acc: 77.81505623721883\n",
      "INFO:TRAIN loss: 0.697122481154518, acc: 77.81505623721883\n",
      "24it [00:03,  7.87it/s]\n",
      "INFO:VAL loss: 1.053704485297203, acc: 70.23499503968253\n",
      "INFO:VAL loss: 1.053704485297203, acc: 70.23499503968253\n",
      "INFO:VAL loss: 1.053704485297203, acc: 70.23499503968253\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:41,  3.97it/s]\n",
      "INFO:TRAIN loss: 0.6358302072878995, acc: 79.56585049664037\n",
      "INFO:TRAIN loss: 0.6358302072878995, acc: 79.56585049664037\n",
      "INFO:TRAIN loss: 0.6358302072878995, acc: 79.56585049664037\n",
      "24it [00:02,  8.28it/s]\n",
      "INFO:VAL loss: 1.0590029681722328, acc: 71.01314484126983\n",
      "INFO:VAL loss: 1.0590029681722328, acc: 71.01314484126983\n",
      "INFO:VAL loss: 1.0590029681722328, acc: 71.01314484126983\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.585720628499985, acc: 80.69607252410167\n",
      "INFO:TRAIN loss: 0.585720628499985, acc: 80.69607252410167\n",
      "INFO:TRAIN loss: 0.585720628499985, acc: 80.69607252410167\n",
      "24it [00:02,  8.25it/s]\n",
      "INFO:VAL loss: 1.0607209081451097, acc: 71.24100942460318\n",
      "INFO:VAL loss: 1.0607209081451097, acc: 71.24100942460318\n",
      "INFO:VAL loss: 1.0607209081451097, acc: 71.24100942460318\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.5200999075649704, acc: 82.81638000292142\n",
      "INFO:TRAIN loss: 0.5200999075649704, acc: 82.81638000292142\n",
      "INFO:TRAIN loss: 0.5200999075649704, acc: 82.81638000292142\n",
      "24it [00:02,  8.28it/s]\n",
      "INFO:VAL loss: 1.1190507610638938, acc: 69.81181795634922\n",
      "INFO:VAL loss: 1.1190507610638938, acc: 69.81181795634922\n",
      "INFO:VAL loss: 1.1190507610638938, acc: 69.81181795634922\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.4819110160225011, acc: 83.79939015483492\n",
      "INFO:TRAIN loss: 0.4819110160225011, acc: 83.79939015483492\n",
      "INFO:TRAIN loss: 0.4819110160225011, acc: 83.79939015483492\n",
      "24it [00:02,  8.29it/s]\n",
      "INFO:VAL loss: 1.200824074447155, acc: 69.94202628968252\n",
      "INFO:VAL loss: 1.200824074447155, acc: 69.94202628968252\n",
      "INFO:VAL loss: 1.200824074447155, acc: 69.94202628968252\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.428827599422332, acc: 85.77271399357289\n",
      "INFO:TRAIN loss: 0.428827599422332, acc: 85.77271399357289\n",
      "INFO:TRAIN loss: 0.428827599422332, acc: 85.77271399357289\n",
      "24it [00:02,  8.30it/s]\n",
      "INFO:VAL loss: 1.157564543187618, acc: 70.36520337301586\n",
      "INFO:VAL loss: 1.157564543187618, acc: 70.36520337301586\n",
      "INFO:VAL loss: 1.157564543187618, acc: 70.36520337301586\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.39449628730493075, acc: 86.50991454864162\n",
      "INFO:TRAIN loss: 0.39449628730493075, acc: 86.50991454864162\n",
      "INFO:TRAIN loss: 0.39449628730493075, acc: 86.50991454864162\n",
      "24it [00:02,  8.30it/s]\n",
      "INFO:VAL loss: 1.2283317123850188, acc: 69.90947420634922\n",
      "INFO:VAL loss: 1.2283317123850188, acc: 69.90947420634922\n",
      "INFO:VAL loss: 1.2283317123850188, acc: 69.90947420634922\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.3567238729789945, acc: 87.89256500146067\n",
      "INFO:TRAIN loss: 0.3567238729789945, acc: 87.89256500146067\n",
      "INFO:TRAIN loss: 0.3567238729789945, acc: 87.89256500146067\n",
      "24it [00:02,  8.29it/s]\n",
      "INFO:VAL loss: 1.2884110584855075, acc: 70.3977554563492\n",
      "INFO:VAL loss: 1.2884110584855075, acc: 70.3977554563492\n",
      "INFO:VAL loss: 1.2884110584855075, acc: 70.3977554563492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.33479302435930525, acc: 88.4620124890447\n",
      "INFO:TRAIN loss: 0.33479302435930525, acc: 88.4620124890447\n",
      "INFO:TRAIN loss: 0.33479302435930525, acc: 88.4620124890447\n",
      "24it [00:02,  8.30it/s]\n",
      "INFO:VAL loss: 1.3463456233342486, acc: 69.48319692460318\n",
      "INFO:VAL loss: 1.3463456233342486, acc: 69.48319692460318\n",
      "INFO:VAL loss: 1.3463456233342486, acc: 69.48319692460318\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.30395327563300456, acc: 89.67987693543674\n",
      "INFO:TRAIN loss: 0.30395327563300456, acc: 89.67987693543674\n",
      "INFO:TRAIN loss: 0.30395327563300456, acc: 89.67987693543674\n",
      "24it [00:02,  8.28it/s]\n",
      "INFO:VAL loss: 1.3521016438802085, acc: 71.04569692460318\n",
      "INFO:VAL loss: 1.3521016438802085, acc: 71.04569692460318\n",
      "INFO:VAL loss: 1.3521016438802085, acc: 71.04569692460318\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.2855226850948451, acc: 90.26415972830853\n",
      "INFO:TRAIN loss: 0.2855226850948451, acc: 90.26415972830853\n",
      "INFO:TRAIN loss: 0.2855226850948451, acc: 90.26415972830853\n",
      "24it [00:02,  8.30it/s]\n",
      "INFO:VAL loss: 1.4133096560835838, acc: 69.68160962301587\n",
      "INFO:VAL loss: 1.4133096560835838, acc: 69.68160962301587\n",
      "INFO:VAL loss: 1.4133096560835838, acc: 69.68160962301587\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:39,  4.16it/s]\n",
      "INFO:TRAIN loss: 0.2712089840802678, acc: 90.73432478819747\n",
      "INFO:TRAIN loss: 0.2712089840802678, acc: 90.73432478819747\n",
      "INFO:TRAIN loss: 0.2712089840802678, acc: 90.73432478819747\n",
      "24it [00:02,  8.32it/s]\n",
      "INFO:VAL loss: 1.4902446915706, acc: 70.10168650793652\n",
      "INFO:VAL loss: 1.4902446915706, acc: 70.10168650793652\n",
      "INFO:VAL loss: 1.4902446915706, acc: 70.10168650793652\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:39,  4.16it/s]\n",
      "INFO:TRAIN loss: 0.2603640591074353, acc: 91.18394865614964\n",
      "INFO:TRAIN loss: 0.2603640591074353, acc: 91.18394865614964\n",
      "INFO:TRAIN loss: 0.2603640591074353, acc: 91.18394865614964\n",
      "24it [00:02,  8.29it/s]\n",
      "INFO:VAL loss: 1.4958901554346085, acc: 70.03968253968253\n",
      "INFO:VAL loss: 1.4958901554346085, acc: 70.03968253968253\n",
      "INFO:VAL loss: 1.4958901554346085, acc: 70.03968253968253\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:40,  4.05it/s]\n",
      "INFO:TRAIN loss: 0.24617521739079182, acc: 91.63973488168274\n",
      "INFO:TRAIN loss: 0.24617521739079182, acc: 91.63973488168274\n",
      "INFO:TRAIN loss: 0.24617521739079182, acc: 91.63973488168274\n",
      "24it [00:02,  8.30it/s]\n",
      "INFO:VAL loss: 1.5319318970044453, acc: 70.16989087301587\n",
      "INFO:VAL loss: 1.5319318970044453, acc: 70.16989087301587\n",
      "INFO:VAL loss: 1.5319318970044453, acc: 70.16989087301587\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:39,  4.17it/s]\n",
      "INFO:TRAIN loss: 0.24345245107185615, acc: 91.40830411919369\n",
      "INFO:TRAIN loss: 0.24345245107185615, acc: 91.40830411919369\n",
      "INFO:TRAIN loss: 0.24345245107185615, acc: 91.40830411919369\n",
      "24it [00:02,  8.34it/s]\n",
      "INFO:VAL loss: 1.522042175134023, acc: 69.58395337301586\n",
      "INFO:VAL loss: 1.522042175134023, acc: 69.58395337301586\n",
      "INFO:VAL loss: 1.522042175134023, acc: 69.58395337301586\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:39,  4.17it/s]\n",
      "INFO:TRAIN loss: 0.24621030519162215, acc: 91.32910641250369\n",
      "INFO:TRAIN loss: 0.24621030519162215, acc: 91.32910641250369\n",
      "INFO:TRAIN loss: 0.24621030519162215, acc: 91.32910641250369\n",
      "24it [00:02,  8.34it/s]\n",
      "INFO:VAL loss: 1.605598787466685, acc: 70.16989087301586\n",
      "INFO:VAL loss: 1.605598787466685, acc: 70.16989087301586\n",
      "INFO:VAL loss: 1.605598787466685, acc: 70.16989087301586\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:39,  4.17it/s]\n",
      "INFO:TRAIN loss: 0.21760216547301936, acc: 92.35000365176742\n",
      "INFO:TRAIN loss: 0.21760216547301936, acc: 92.35000365176742\n",
      "INFO:TRAIN loss: 0.21760216547301936, acc: 92.35000365176742\n",
      "24it [00:02,  8.35it/s]\n",
      "INFO:VAL loss: 1.6497228642304738, acc: 68.96236359126983\n",
      "INFO:VAL loss: 1.6497228642304738, acc: 68.96236359126983\n",
      "INFO:VAL loss: 1.6497228642304738, acc: 68.96236359126983\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.2080824865611053, acc: 92.76174043236927\n",
      "INFO:TRAIN loss: 0.2080824865611053, acc: 92.76174043236927\n",
      "INFO:TRAIN loss: 0.2080824865611053, acc: 92.76174043236927\n",
      "24it [00:02,  8.24it/s]\n",
      "INFO:VAL loss: 1.5673536707957585, acc: 69.87692212301586\n",
      "INFO:VAL loss: 1.5673536707957585, acc: 69.87692212301586\n",
      "INFO:VAL loss: 1.5673536707957585, acc: 69.87692212301586\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.21147137827759868, acc: 92.4310272421852\n",
      "INFO:TRAIN loss: 0.21147137827759868, acc: 92.4310272421852\n",
      "INFO:TRAIN loss: 0.21147137827759868, acc: 92.4310272421852\n",
      "24it [00:02,  8.21it/s]\n",
      "INFO:VAL loss: 1.6159329935908318, acc: 69.38864087301589\n",
      "INFO:VAL loss: 1.6159329935908318, acc: 69.38864087301589\n",
      "INFO:VAL loss: 1.6159329935908318, acc: 69.38864087301589\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.20796764616860197, acc: 92.64625328659068\n",
      "INFO:TRAIN loss: 0.20796764616860197, acc: 92.64625328659068\n",
      "INFO:TRAIN loss: 0.20796764616860197, acc: 92.64625328659068\n",
      "24it [00:02,  8.28it/s]\n",
      "INFO:VAL loss: 1.7519836674133935, acc: 69.41809275793652\n",
      "INFO:VAL loss: 1.7519836674133935, acc: 69.41809275793652\n",
      "INFO:VAL loss: 1.7519836674133935, acc: 69.41809275793652\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.20241158581310242, acc: 92.84276402278702\n",
      "INFO:TRAIN loss: 0.20241158581310242, acc: 92.84276402278702\n",
      "INFO:TRAIN loss: 0.20241158581310242, acc: 92.84276402278702\n",
      "24it [00:02,  8.29it/s]\n",
      "INFO:VAL loss: 1.720582495133082, acc: 69.77926587301589\n",
      "INFO:VAL loss: 1.720582495133082, acc: 69.77926587301589\n",
      "INFO:VAL loss: 1.720582495133082, acc: 69.77926587301589\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.1924023744335935, acc: 93.04498064563253\n",
      "INFO:TRAIN loss: 0.1924023744335935, acc: 93.04498064563253\n",
      "INFO:TRAIN loss: 0.1924023744335935, acc: 93.04498064563253\n",
      "24it [00:02,  8.30it/s]\n",
      "INFO:VAL loss: 1.722525025407473, acc: 69.13132440476191\n",
      "INFO:VAL loss: 1.722525025407473, acc: 69.13132440476191\n",
      "INFO:VAL loss: 1.722525025407473, acc: 69.13132440476191\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.18824774735361513, acc: 93.36565147531407\n",
      "INFO:TRAIN loss: 0.18824774735361513, acc: 93.36565147531407\n",
      "INFO:TRAIN loss: 0.18824774735361513, acc: 93.36565147531407\n",
      "24it [00:02,  8.26it/s]\n",
      "INFO:VAL loss: 1.6620955218871434, acc: 69.84126984126985\n",
      "INFO:VAL loss: 1.6620955218871434, acc: 69.84126984126985\n",
      "INFO:VAL loss: 1.6620955218871434, acc: 69.84126984126985\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.17888534836973888, acc: 93.41837386795213\n",
      "INFO:TRAIN loss: 0.17888534836973888, acc: 93.41837386795213\n",
      "INFO:TRAIN loss: 0.17888534836973888, acc: 93.41837386795213\n",
      "24it [00:02,  8.26it/s]\n",
      "INFO:VAL loss: 1.7887041221062343, acc: 70.00713045634922\n",
      "INFO:VAL loss: 1.7887041221062343, acc: 70.00713045634922\n",
      "INFO:VAL loss: 1.7887041221062343, acc: 70.00713045634922\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.18249822700499022, acc: 93.38870325737659\n",
      "INFO:TRAIN loss: 0.18249822700499022, acc: 93.38870325737659\n",
      "INFO:TRAIN loss: 0.18249822700499022, acc: 93.38870325737659\n",
      "24it [00:02,  8.30it/s]\n",
      "INFO:VAL loss: 1.6970292826493583, acc: 69.94202628968254\n",
      "INFO:VAL loss: 1.6970292826493583, acc: 69.94202628968254\n",
      "INFO:VAL loss: 1.6970292826493583, acc: 69.94202628968254\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:41,  3.95it/s]\n",
      "INFO:TRAIN loss: 0.1843303205228291, acc: 93.45717389716619\n",
      "INFO:TRAIN loss: 0.1843303205228291, acc: 93.45717389716619\n",
      "INFO:TRAIN loss: 0.1843303205228291, acc: 93.45717389716619\n",
      "24it [00:02,  8.14it/s]\n",
      "INFO:VAL loss: 1.8909222731987636, acc: 69.84437003968256\n",
      "INFO:VAL loss: 1.8909222731987636, acc: 69.84437003968256\n",
      "INFO:VAL loss: 1.8909222731987636, acc: 69.84437003968256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:40,  4.00it/s]\n",
      "INFO:TRAIN loss: 0.17826277675804186, acc: 93.26545610575515\n",
      "INFO:TRAIN loss: 0.17826277675804186, acc: 93.26545610575515\n",
      "INFO:TRAIN loss: 0.17826277675804186, acc: 93.26545610575515\n",
      "24it [00:03,  7.99it/s]\n",
      "INFO:VAL loss: 1.7712119221687317, acc: 69.29098462301589\n",
      "INFO:VAL loss: 1.7712119221687317, acc: 69.29098462301589\n",
      "INFO:VAL loss: 1.7712119221687317, acc: 69.29098462301589\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:40,  4.01it/s]\n",
      "INFO:TRAIN loss: 0.1712776714581653, acc: 93.67719288635699\n",
      "INFO:TRAIN loss: 0.1712776714581653, acc: 93.67719288635699\n",
      "INFO:TRAIN loss: 0.1712776714581653, acc: 93.67719288635699\n",
      "24it [00:03,  7.94it/s]\n",
      "INFO:VAL loss: 1.858802338441213, acc: 69.3204365079365\n",
      "INFO:VAL loss: 1.858802338441213, acc: 69.3204365079365\n",
      "INFO:VAL loss: 1.858802338441213, acc: 69.3204365079365\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:40,  4.02it/s]\n",
      "INFO:TRAIN loss: 0.16695604587625135, acc: 93.8310235904178\n",
      "INFO:TRAIN loss: 0.16695604587625135, acc: 93.8310235904178\n",
      "INFO:TRAIN loss: 0.16695604587625135, acc: 93.8310235904178\n",
      "24it [00:02,  8.12it/s]\n",
      "INFO:VAL loss: 1.8031934698422754, acc: 69.64905753968253\n",
      "INFO:VAL loss: 1.8031934698422754, acc: 69.64905753968253\n",
      "INFO:VAL loss: 1.8031934698422754, acc: 69.64905753968253\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:40,  4.01it/s]\n",
      "INFO:TRAIN loss: 0.17243542202228426, acc: 93.53865395851597\n",
      "INFO:TRAIN loss: 0.17243542202228426, acc: 93.53865395851597\n",
      "INFO:TRAIN loss: 0.17243542202228426, acc: 93.53865395851597\n",
      "24it [00:02,  8.11it/s]\n",
      "INFO:VAL loss: 1.8304381817579267, acc: 69.74671378968254\n",
      "INFO:VAL loss: 1.8304381817579267, acc: 69.74671378968254\n",
      "INFO:VAL loss: 1.8304381817579267, acc: 69.74671378968254\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:40,  4.03it/s]\n",
      "INFO:TRAIN loss: 0.17649887721597057, acc: 93.557825737657\n",
      "INFO:TRAIN loss: 0.17649887721597057, acc: 93.557825737657\n",
      "INFO:TRAIN loss: 0.17649887721597057, acc: 93.557825737657\n",
      "24it [00:03,  7.85it/s]\n",
      "INFO:VAL loss: 1.9412981569766998, acc: 68.99801587301586\n",
      "INFO:VAL loss: 1.9412981569766998, acc: 68.99801587301586\n",
      "INFO:VAL loss: 1.9412981569766998, acc: 68.99801587301586\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:40,  3.99it/s]\n",
      "INFO:TRAIN loss: 0.17522766674223123, acc: 93.47634567630729\n",
      "INFO:TRAIN loss: 0.17522766674223123, acc: 93.47634567630729\n",
      "INFO:TRAIN loss: 0.17522766674223123, acc: 93.47634567630729\n",
      "24it [00:03,  7.78it/s]\n",
      "INFO:VAL loss: 1.9251514772574108, acc: 69.3235367063492\n",
      "INFO:VAL loss: 1.9251514772574108, acc: 69.3235367063492\n",
      "INFO:VAL loss: 1.9251514772574108, acc: 69.3235367063492\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:40,  3.99it/s]\n",
      "INFO:TRAIN loss: 0.17273391102172111, acc: 93.61534107508031\n",
      "INFO:TRAIN loss: 0.17273391102172111, acc: 93.61534107508031\n",
      "INFO:TRAIN loss: 0.17273391102172111, acc: 93.61534107508031\n",
      "24it [00:02,  8.13it/s]\n",
      "INFO:VAL loss: 1.888228590289752, acc: 70.62562003968254\n",
      "INFO:VAL loss: 1.888228590289752, acc: 70.62562003968254\n",
      "INFO:VAL loss: 1.888228590289752, acc: 70.62562003968254\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:40,  4.05it/s]\n",
      "INFO:TRAIN loss: 0.16403259060408443, acc: 93.81230828220856\n",
      "INFO:TRAIN loss: 0.16403259060408443, acc: 93.81230828220856\n",
      "INFO:TRAIN loss: 0.16403259060408443, acc: 93.81230828220856\n",
      "24it [00:02,  8.09it/s]\n",
      "INFO:VAL loss: 2.0098186830679574, acc: 69.74051339285715\n",
      "INFO:VAL loss: 2.0098186830679574, acc: 69.74051339285715\n",
      "INFO:VAL loss: 2.0098186830679574, acc: 69.74051339285715\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:39,  4.13it/s]\n",
      "INFO:TRAIN loss: 0.17007131518030466, acc: 93.41403739409876\n",
      "INFO:TRAIN loss: 0.17007131518030466, acc: 93.41403739409876\n",
      "INFO:TRAIN loss: 0.17007131518030466, acc: 93.41403739409876\n",
      "24it [00:02,  8.28it/s]\n",
      "INFO:VAL loss: 1.984526917338371, acc: 70.66127232142857\n",
      "INFO:VAL loss: 1.984526917338371, acc: 70.66127232142857\n",
      "INFO:VAL loss: 1.984526917338371, acc: 70.66127232142857\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.1644005805162564, acc: 93.62492696465092\n",
      "INFO:TRAIN loss: 0.1644005805162564, acc: 93.62492696465092\n",
      "INFO:TRAIN loss: 0.1644005805162564, acc: 93.62492696465092\n",
      "24it [00:02,  8.31it/s]\n",
      "INFO:VAL loss: 1.9672647615273795, acc: 69.06001984126985\n",
      "INFO:VAL loss: 1.9672647615273795, acc: 69.06001984126985\n",
      "INFO:VAL loss: 1.9672647615273795, acc: 69.06001984126985\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.1587177475720096, acc: 93.86411773298279\n",
      "INFO:TRAIN loss: 0.1587177475720096, acc: 93.86411773298279\n",
      "INFO:TRAIN loss: 0.1587177475720096, acc: 93.86411773298279\n",
      "24it [00:02,  8.27it/s]\n",
      "INFO:VAL loss: 2.0255994697411857, acc: 70.03658234126985\n",
      "INFO:VAL loss: 2.0255994697411857, acc: 70.03658234126985\n",
      "INFO:VAL loss: 2.0255994697411857, acc: 70.03658234126985\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.15926542197085605, acc: 93.96956251825884\n",
      "INFO:TRAIN loss: 0.15926542197085605, acc: 93.96956251825884\n",
      "INFO:TRAIN loss: 0.15926542197085605, acc: 93.96956251825884\n",
      "24it [00:02,  8.34it/s]\n",
      "INFO:VAL loss: 1.9933444062868761, acc: 69.54830109126985\n",
      "INFO:VAL loss: 1.9933444062868761, acc: 69.54830109126985\n",
      "INFO:VAL loss: 1.9933444062868761, acc: 69.54830109126985\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.16013829563201576, acc: 93.81710122699388\n",
      "INFO:TRAIN loss: 0.16013829563201576, acc: 93.81710122699388\n",
      "INFO:TRAIN loss: 0.16013829563201576, acc: 93.81710122699388\n",
      "24it [00:02,  8.35it/s]\n",
      "INFO:VAL loss: 2.1075064639250436, acc: 69.45374503968253\n",
      "INFO:VAL loss: 2.1075064639250436, acc: 69.45374503968253\n",
      "INFO:VAL loss: 2.1075064639250436, acc: 69.45374503968253\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:39,  4.15it/s]\n",
      "INFO:TRAIN loss: 0.15946048040491492, acc: 93.802722392638\n",
      "INFO:TRAIN loss: 0.15946048040491492, acc: 93.802722392638\n",
      "INFO:TRAIN loss: 0.15946048040491492, acc: 93.802722392638\n",
      "24it [00:02,  8.30it/s]\n",
      "INFO:VAL loss: 2.1043759584426875, acc: 70.23499503968253\n",
      "INFO:VAL loss: 2.1043759584426875, acc: 70.23499503968253\n",
      "INFO:VAL loss: 2.1043759584426875, acc: 70.23499503968253\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.16405364500781508, acc: 93.67719288635699\n",
      "INFO:TRAIN loss: 0.16405364500781508, acc: 93.67719288635699\n",
      "INFO:TRAIN loss: 0.16405364500781508, acc: 93.67719288635699\n",
      "24it [00:02,  8.31it/s]\n",
      "INFO:VAL loss: 2.0036590347687406, acc: 68.8352554563492\n",
      "INFO:VAL loss: 2.0036590347687406, acc: 68.8352554563492\n",
      "INFO:VAL loss: 2.0036590347687406, acc: 68.8352554563492\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "163it [00:39,  4.14it/s]\n",
      "INFO:TRAIN loss: 0.16167713818283178, acc: 93.65231522056673\n",
      "INFO:TRAIN loss: 0.16167713818283178, acc: 93.65231522056673\n",
      "INFO:TRAIN loss: 0.16167713818283178, acc: 93.65231522056673\n",
      "24it [00:02,  8.33it/s]\n",
      "INFO:VAL loss: 2.1968533049027124, acc: 69.77616567460316\n",
      "INFO:VAL loss: 2.1968533049027124, acc: 69.77616567460316\n",
      "INFO:VAL loss: 2.1968533049027124, acc: 69.77616567460316\n",
      "47it [00:05,  8.17it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 2.1304445241359957, acc: 69.05071324951646\n",
      "INFO:\n",
      "\n",
      "TEST loss: 2.1304445241359957, acc: 69.05071324951646\n",
      "INFO:\n",
      "\n",
      "TEST loss: 2.1304445241359957, acc: 69.05071324951646\n",
      "INFO:{'epoch_index': 49, 'train_loss': [2.0522606321639083, 1.390689462240488, 1.1889687915521163, 1.0685461477999316, 0.97834705136305, 0.8967736889979592, 0.828635947470285, 0.751125992075797, 0.697122481154518, 0.6358302072878995, 0.585720628499985, 0.5200999075649704, 0.4819110160225011, 0.428827599422332, 0.39449628730493075, 0.3567238729789945, 0.33479302435930525, 0.30395327563300456, 0.2855226850948451, 0.2712089840802678, 0.2603640591074353, 0.24617521739079182, 0.24345245107185615, 0.24621030519162215, 0.21760216547301936, 0.2080824865611053, 0.21147137827759868, 0.20796764616860197, 0.20241158581310242, 0.1924023744335935, 0.18824774735361513, 0.17888534836973888, 0.18249822700499022, 0.1843303205228291, 0.17826277675804186, 0.1712776714581653, 0.16695604587625135, 0.17243542202228426, 0.17649887721597057, 0.17522766674223123, 0.17273391102172111, 0.16403259060408443, 0.17007131518030466, 0.1644005805162564, 0.1587177475720096, 0.15926542197085605, 0.16013829563201576, 0.15946048040491492, 0.16405364500781508, 0.16167713818283178], 'train_acc': [40.264387963774475, 58.878587861524984, 64.49066973415135, 68.17028191644758, 70.70141323400526, 72.57203111305871, 74.3938066023956, 76.6325682880514, 77.81505623721883, 79.56585049664037, 80.69607252410167, 82.81638000292142, 83.79939015483492, 85.77271399357289, 86.50991454864162, 87.89256500146067, 88.4620124890447, 89.67987693543674, 90.26415972830853, 90.73432478819747, 91.18394865614964, 91.63973488168274, 91.40830411919369, 91.32910641250369, 92.35000365176742, 92.76174043236927, 92.4310272421852, 92.64625328659068, 92.84276402278702, 93.04498064563253, 93.36565147531407, 93.41837386795213, 93.38870325737659, 93.45717389716619, 93.26545610575515, 93.67719288635699, 93.8310235904178, 93.53865395851597, 93.557825737657, 93.47634567630729, 93.61534107508031, 93.81230828220856, 93.41403739409876, 93.62492696465092, 93.86411773298279, 93.96956251825884, 93.81710122699388, 93.802722392638, 93.67719288635699, 93.65231522056673], 'val_loss': [1.4663044313589733, 1.2536193778117497, 1.1591115072369573, 1.0579699724912643, 1.0687980900208156, 1.0498034159342449, 1.0370397120714183, 1.043759753306707, 1.053704485297203, 1.0590029681722328, 1.0607209081451097, 1.1190507610638938, 1.200824074447155, 1.157564543187618, 1.2283317123850188, 1.2884110584855075, 1.3463456233342486, 1.3521016438802085, 1.4133096560835838, 1.4902446915706, 1.4958901554346085, 1.5319318970044453, 1.522042175134023, 1.605598787466685, 1.6497228642304738, 1.5673536707957585, 1.6159329935908318, 1.7519836674133935, 1.720582495133082, 1.722525025407473, 1.6620955218871434, 1.7887041221062343, 1.6970292826493583, 1.8909222731987636, 1.7712119221687317, 1.858802338441213, 1.8031934698422754, 1.8304381817579267, 1.9412981569766998, 1.9251514772574108, 1.888228590289752, 2.0098186830679574, 1.984526917338371, 1.9672647615273795, 2.0255994697411857, 1.9933444062868761, 2.1075064639250436, 2.1043759584426875, 2.0036590347687406, 2.1968533049027124], 'val_acc': [57.34126984126985, 63.06733630952381, 65.47929067460318, 68.90035962301587, 69.06312003968253, 69.94202628968253, 70.13733878968254, 69.8800223214286, 70.23499503968253, 71.01314484126983, 71.24100942460318, 69.81181795634922, 69.94202628968252, 70.36520337301586, 69.90947420634922, 70.3977554563492, 69.48319692460318, 71.04569692460318, 69.68160962301587, 70.10168650793652, 70.03968253968253, 70.16989087301587, 69.58395337301586, 70.16989087301586, 68.96236359126983, 69.87692212301586, 69.38864087301589, 69.41809275793652, 69.77926587301589, 69.13132440476191, 69.84126984126985, 70.00713045634922, 69.94202628968254, 69.84437003968256, 69.29098462301589, 69.3204365079365, 69.64905753968253, 69.74671378968254, 68.99801587301586, 69.3235367063492, 70.62562003968254, 69.74051339285715, 70.66127232142857, 69.06001984126985, 70.03658234126985, 69.54830109126985, 69.45374503968253, 70.23499503968253, 68.8352554563492, 69.77616567460316], 'test_loss': 2.1304445241359957, 'test_acc': 69.05071324951646}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:{'epoch_index': 49, 'train_loss': [2.0522606321639083, 1.390689462240488, 1.1889687915521163, 1.0685461477999316, 0.97834705136305, 0.8967736889979592, 0.828635947470285, 0.751125992075797, 0.697122481154518, 0.6358302072878995, 0.585720628499985, 0.5200999075649704, 0.4819110160225011, 0.428827599422332, 0.39449628730493075, 0.3567238729789945, 0.33479302435930525, 0.30395327563300456, 0.2855226850948451, 0.2712089840802678, 0.2603640591074353, 0.24617521739079182, 0.24345245107185615, 0.24621030519162215, 0.21760216547301936, 0.2080824865611053, 0.21147137827759868, 0.20796764616860197, 0.20241158581310242, 0.1924023744335935, 0.18824774735361513, 0.17888534836973888, 0.18249822700499022, 0.1843303205228291, 0.17826277675804186, 0.1712776714581653, 0.16695604587625135, 0.17243542202228426, 0.17649887721597057, 0.17522766674223123, 0.17273391102172111, 0.16403259060408443, 0.17007131518030466, 0.1644005805162564, 0.1587177475720096, 0.15926542197085605, 0.16013829563201576, 0.15946048040491492, 0.16405364500781508, 0.16167713818283178], 'train_acc': [40.264387963774475, 58.878587861524984, 64.49066973415135, 68.17028191644758, 70.70141323400526, 72.57203111305871, 74.3938066023956, 76.6325682880514, 77.81505623721883, 79.56585049664037, 80.69607252410167, 82.81638000292142, 83.79939015483492, 85.77271399357289, 86.50991454864162, 87.89256500146067, 88.4620124890447, 89.67987693543674, 90.26415972830853, 90.73432478819747, 91.18394865614964, 91.63973488168274, 91.40830411919369, 91.32910641250369, 92.35000365176742, 92.76174043236927, 92.4310272421852, 92.64625328659068, 92.84276402278702, 93.04498064563253, 93.36565147531407, 93.41837386795213, 93.38870325737659, 93.45717389716619, 93.26545610575515, 93.67719288635699, 93.8310235904178, 93.53865395851597, 93.557825737657, 93.47634567630729, 93.61534107508031, 93.81230828220856, 93.41403739409876, 93.62492696465092, 93.86411773298279, 93.96956251825884, 93.81710122699388, 93.802722392638, 93.67719288635699, 93.65231522056673], 'val_loss': [1.4663044313589733, 1.2536193778117497, 1.1591115072369573, 1.0579699724912643, 1.0687980900208156, 1.0498034159342449, 1.0370397120714183, 1.043759753306707, 1.053704485297203, 1.0590029681722328, 1.0607209081451097, 1.1190507610638938, 1.200824074447155, 1.157564543187618, 1.2283317123850188, 1.2884110584855075, 1.3463456233342486, 1.3521016438802085, 1.4133096560835838, 1.4902446915706, 1.4958901554346085, 1.5319318970044453, 1.522042175134023, 1.605598787466685, 1.6497228642304738, 1.5673536707957585, 1.6159329935908318, 1.7519836674133935, 1.720582495133082, 1.722525025407473, 1.6620955218871434, 1.7887041221062343, 1.6970292826493583, 1.8909222731987636, 1.7712119221687317, 1.858802338441213, 1.8031934698422754, 1.8304381817579267, 1.9412981569766998, 1.9251514772574108, 1.888228590289752, 2.0098186830679574, 1.984526917338371, 1.9672647615273795, 2.0255994697411857, 1.9933444062868761, 2.1075064639250436, 2.1043759584426875, 2.0036590347687406, 2.1968533049027124], 'val_acc': [57.34126984126985, 63.06733630952381, 65.47929067460318, 68.90035962301587, 69.06312003968253, 69.94202628968253, 70.13733878968254, 69.8800223214286, 70.23499503968253, 71.01314484126983, 71.24100942460318, 69.81181795634922, 69.94202628968252, 70.36520337301586, 69.90947420634922, 70.3977554563492, 69.48319692460318, 71.04569692460318, 69.68160962301587, 70.10168650793652, 70.03968253968253, 70.16989087301587, 69.58395337301586, 70.16989087301586, 68.96236359126983, 69.87692212301586, 69.38864087301589, 69.41809275793652, 69.77926587301589, 69.13132440476191, 69.84126984126985, 70.00713045634922, 69.94202628968254, 69.84437003968256, 69.29098462301589, 69.3204365079365, 69.64905753968253, 69.74671378968254, 68.99801587301586, 69.3235367063492, 70.62562003968254, 69.74051339285715, 70.66127232142857, 69.06001984126985, 70.03658234126985, 69.54830109126985, 69.45374503968253, 70.23499503968253, 68.8352554563492, 69.77616567460316], 'test_loss': 2.1304445241359957, 'test_acc': 69.05071324951646}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [2.0522606321639083, 1.390689462240488, 1.1889687915521163, 1.0685461477999316, 0.97834705136305, 0.8967736889979592, 0.828635947470285, 0.751125992075797, 0.697122481154518, 0.6358302072878995, 0.585720628499985, 0.5200999075649704, 0.4819110160225011, 0.428827599422332, 0.39449628730493075, 0.3567238729789945, 0.33479302435930525, 0.30395327563300456, 0.2855226850948451, 0.2712089840802678, 0.2603640591074353, 0.24617521739079182, 0.24345245107185615, 0.24621030519162215, 0.21760216547301936, 0.2080824865611053, 0.21147137827759868, 0.20796764616860197, 0.20241158581310242, 0.1924023744335935, 0.18824774735361513, 0.17888534836973888, 0.18249822700499022, 0.1843303205228291, 0.17826277675804186, 0.1712776714581653, 0.16695604587625135, 0.17243542202228426, 0.17649887721597057, 0.17522766674223123, 0.17273391102172111, 0.16403259060408443, 0.17007131518030466, 0.1644005805162564, 0.1587177475720096, 0.15926542197085605, 0.16013829563201576, 0.15946048040491492, 0.16405364500781508, 0.16167713818283178], 'train_acc': [40.264387963774475, 58.878587861524984, 64.49066973415135, 68.17028191644758, 70.70141323400526, 72.57203111305871, 74.3938066023956, 76.6325682880514, 77.81505623721883, 79.56585049664037, 80.69607252410167, 82.81638000292142, 83.79939015483492, 85.77271399357289, 86.50991454864162, 87.89256500146067, 88.4620124890447, 89.67987693543674, 90.26415972830853, 90.73432478819747, 91.18394865614964, 91.63973488168274, 91.40830411919369, 91.32910641250369, 92.35000365176742, 92.76174043236927, 92.4310272421852, 92.64625328659068, 92.84276402278702, 93.04498064563253, 93.36565147531407, 93.41837386795213, 93.38870325737659, 93.45717389716619, 93.26545610575515, 93.67719288635699, 93.8310235904178, 93.53865395851597, 93.557825737657, 93.47634567630729, 93.61534107508031, 93.81230828220856, 93.41403739409876, 93.62492696465092, 93.86411773298279, 93.96956251825884, 93.81710122699388, 93.802722392638, 93.67719288635699, 93.65231522056673], 'val_loss': [1.4663044313589733, 1.2536193778117497, 1.1591115072369573, 1.0579699724912643, 1.0687980900208156, 1.0498034159342449, 1.0370397120714183, 1.043759753306707, 1.053704485297203, 1.0590029681722328, 1.0607209081451097, 1.1190507610638938, 1.200824074447155, 1.157564543187618, 1.2283317123850188, 1.2884110584855075, 1.3463456233342486, 1.3521016438802085, 1.4133096560835838, 1.4902446915706, 1.4958901554346085, 1.5319318970044453, 1.522042175134023, 1.605598787466685, 1.6497228642304738, 1.5673536707957585, 1.6159329935908318, 1.7519836674133935, 1.720582495133082, 1.722525025407473, 1.6620955218871434, 1.7887041221062343, 1.6970292826493583, 1.8909222731987636, 1.7712119221687317, 1.858802338441213, 1.8031934698422754, 1.8304381817579267, 1.9412981569766998, 1.9251514772574108, 1.888228590289752, 2.0098186830679574, 1.984526917338371, 1.9672647615273795, 2.0255994697411857, 1.9933444062868761, 2.1075064639250436, 2.1043759584426875, 2.0036590347687406, 2.1968533049027124], 'val_acc': [57.34126984126985, 63.06733630952381, 65.47929067460318, 68.90035962301587, 69.06312003968253, 69.94202628968253, 70.13733878968254, 69.8800223214286, 70.23499503968253, 71.01314484126983, 71.24100942460318, 69.81181795634922, 69.94202628968252, 70.36520337301586, 69.90947420634922, 70.3977554563492, 69.48319692460318, 71.04569692460318, 69.68160962301587, 70.10168650793652, 70.03968253968253, 70.16989087301587, 69.58395337301586, 70.16989087301586, 68.96236359126983, 69.87692212301586, 69.38864087301589, 69.41809275793652, 69.77926587301589, 69.13132440476191, 69.84126984126985, 70.00713045634922, 69.94202628968254, 69.84437003968256, 69.29098462301589, 69.3204365079365, 69.64905753968253, 69.74671378968254, 68.99801587301586, 69.3235367063492, 70.62562003968254, 69.74051339285715, 70.66127232142857, 69.06001984126985, 70.03658234126985, 69.54830109126985, 69.45374503968253, 70.23499503968253, 68.8352554563492, 69.77616567460316], 'test_loss': 2.1304445241359957, 'test_acc': 69.05071324951646}\n"
     ]
    }
   ],
   "source": [
    "# Model 11\n",
    "args.model_id=11\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_myembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_myembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_myembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_Conv1d(embedding_size=100, num_channels=128,hidden_dim=100, label_nums=label_nums, dropout_p=0.1)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "#args.logger.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe286da3",
   "metadata": {},
   "source": [
    "**acc: 69.05**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b93268",
   "metadata": {},
   "source": [
    "Use my embedding for job_description used on conv1d model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7306dfc",
   "metadata": {},
   "source": [
    "**`model 12: text--job_description, embedding--pretrain embedding, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d299f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=12, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=12, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=12, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=12, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 2.64481549979719, acc: 23.82367440841367\n",
      "INFO:TRAIN loss: 2.64481549979719, acc: 23.82367440841367\n",
      "INFO:TRAIN loss: 2.64481549979719, acc: 23.82367440841367\n",
      "INFO:TRAIN loss: 2.64481549979719, acc: 23.82367440841367\n",
      "24it [00:02, 10.87it/s]\n",
      "INFO:VAL loss: 2.0642712811628976, acc: 40.36613343253969\n",
      "INFO:VAL loss: 2.0642712811628976, acc: 40.36613343253969\n",
      "INFO:VAL loss: 2.0642712811628976, acc: 40.36613343253969\n",
      "INFO:VAL loss: 2.0642712811628976, acc: 40.36613343253969\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 1.970312620964518, acc: 42.05877519719542\n",
      "INFO:TRAIN loss: 1.970312620964518, acc: 42.05877519719542\n",
      "INFO:TRAIN loss: 1.970312620964518, acc: 42.05877519719542\n",
      "INFO:TRAIN loss: 1.970312620964518, acc: 42.05877519719542\n",
      "24it [00:02, 10.99it/s]\n",
      "INFO:VAL loss: 1.8661440114180248, acc: 45.379154265873034\n",
      "INFO:VAL loss: 1.8661440114180248, acc: 45.379154265873034\n",
      "INFO:VAL loss: 1.8661440114180248, acc: 45.379154265873034\n",
      "INFO:VAL loss: 1.8661440114180248, acc: 45.379154265873034\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 1.7215144049170552, acc: 49.307761831726545\n",
      "INFO:TRAIN loss: 1.7215144049170552, acc: 49.307761831726545\n",
      "INFO:TRAIN loss: 1.7215144049170552, acc: 49.307761831726545\n",
      "INFO:TRAIN loss: 1.7215144049170552, acc: 49.307761831726545\n",
      "24it [00:02, 10.89it/s]\n",
      "INFO:VAL loss: 1.620772823691368, acc: 53.33116319444445\n",
      "INFO:VAL loss: 1.620772823691368, acc: 53.33116319444445\n",
      "INFO:VAL loss: 1.620772823691368, acc: 53.33116319444445\n",
      "INFO:VAL loss: 1.620772823691368, acc: 53.33116319444445\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 1.5660451409275544, acc: 53.940028848962896\n",
      "INFO:TRAIN loss: 1.5660451409275544, acc: 53.940028848962896\n",
      "INFO:TRAIN loss: 1.5660451409275544, acc: 53.940028848962896\n",
      "INFO:TRAIN loss: 1.5660451409275544, acc: 53.940028848962896\n",
      "24it [00:02, 10.90it/s]\n",
      "INFO:VAL loss: 1.5278209298849106, acc: 56.22209821428571\n",
      "INFO:VAL loss: 1.5278209298849106, acc: 56.22209821428571\n",
      "INFO:VAL loss: 1.5278209298849106, acc: 56.22209821428571\n",
      "INFO:VAL loss: 1.5278209298849106, acc: 56.22209821428571\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 1.4357029141092599, acc: 57.29029725387087\n",
      "INFO:TRAIN loss: 1.4357029141092599, acc: 57.29029725387087\n",
      "INFO:TRAIN loss: 1.4357029141092599, acc: 57.29029725387087\n",
      "INFO:TRAIN loss: 1.4357029141092599, acc: 57.29029725387087\n",
      "24it [00:02, 10.92it/s]\n",
      "INFO:VAL loss: 1.4563077737887702, acc: 57.51798115079365\n",
      "INFO:VAL loss: 1.4563077737887702, acc: 57.51798115079365\n",
      "INFO:VAL loss: 1.4563077737887702, acc: 57.51798115079365\n",
      "INFO:VAL loss: 1.4563077737887702, acc: 57.51798115079365\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 1.3392657725357573, acc: 60.23499123575811\n",
      "INFO:TRAIN loss: 1.3392657725357573, acc: 60.23499123575811\n",
      "INFO:TRAIN loss: 1.3392657725357573, acc: 60.23499123575811\n",
      "INFO:TRAIN loss: 1.3392657725357573, acc: 60.23499123575811\n",
      "24it [00:02, 10.90it/s]\n",
      "INFO:VAL loss: 1.4259889672199884, acc: 59.095982142857146\n",
      "INFO:VAL loss: 1.4259889672199884, acc: 59.095982142857146\n",
      "INFO:VAL loss: 1.4259889672199884, acc: 59.095982142857146\n",
      "INFO:VAL loss: 1.4259889672199884, acc: 59.095982142857146\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 1.2667924820279783, acc: 62.261493938066046\n",
      "INFO:TRAIN loss: 1.2667924820279783, acc: 62.261493938066046\n",
      "INFO:TRAIN loss: 1.2667924820279783, acc: 62.261493938066046\n",
      "INFO:TRAIN loss: 1.2667924820279783, acc: 62.261493938066046\n",
      "24it [00:02, 10.94it/s]\n",
      "INFO:VAL loss: 1.400616606076558, acc: 60.00434027777778\n",
      "INFO:VAL loss: 1.400616606076558, acc: 60.00434027777778\n",
      "INFO:VAL loss: 1.400616606076558, acc: 60.00434027777778\n",
      "INFO:VAL loss: 1.400616606076558, acc: 60.00434027777778\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 1.1910687249862342, acc: 64.2850295793164\n",
      "INFO:TRAIN loss: 1.1910687249862342, acc: 64.2850295793164\n",
      "INFO:TRAIN loss: 1.1910687249862342, acc: 64.2850295793164\n",
      "INFO:TRAIN loss: 1.1910687249862342, acc: 64.2850295793164\n",
      "24it [00:02, 10.91it/s]\n",
      "INFO:VAL loss: 1.431149592002233, acc: 59.477306547619044\n",
      "INFO:VAL loss: 1.431149592002233, acc: 59.477306547619044\n",
      "INFO:VAL loss: 1.431149592002233, acc: 59.477306547619044\n",
      "INFO:VAL loss: 1.431149592002233, acc: 59.477306547619044\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 1.120567545934689, acc: 66.19307807478822\n",
      "INFO:TRAIN loss: 1.120567545934689, acc: 66.19307807478822\n",
      "INFO:TRAIN loss: 1.120567545934689, acc: 66.19307807478822\n",
      "INFO:TRAIN loss: 1.120567545934689, acc: 66.19307807478822\n",
      "24it [00:02, 10.92it/s]\n",
      "INFO:VAL loss: 1.3885577917099, acc: 60.847594246031754\n",
      "INFO:VAL loss: 1.3885577917099, acc: 60.847594246031754\n",
      "INFO:VAL loss: 1.3885577917099, acc: 60.847594246031754\n",
      "INFO:VAL loss: 1.3885577917099, acc: 60.847594246031754\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 1.0495362757173785, acc: 67.9790205959684\n",
      "INFO:TRAIN loss: 1.0495362757173785, acc: 67.9790205959684\n",
      "INFO:TRAIN loss: 1.0495362757173785, acc: 67.9790205959684\n",
      "INFO:TRAIN loss: 1.0495362757173785, acc: 67.9790205959684\n",
      "24it [00:02, 10.98it/s]\n",
      "INFO:VAL loss: 1.36677640179793, acc: 61.306423611111114\n",
      "INFO:VAL loss: 1.36677640179793, acc: 61.306423611111114\n",
      "INFO:VAL loss: 1.36677640179793, acc: 61.306423611111114\n",
      "INFO:VAL loss: 1.36677640179793, acc: 61.306423611111114\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.9939224259253662, acc: 69.27539804265255\n",
      "INFO:TRAIN loss: 0.9939224259253662, acc: 69.27539804265255\n",
      "INFO:TRAIN loss: 0.9939224259253662, acc: 69.27539804265255\n",
      "INFO:TRAIN loss: 0.9939224259253662, acc: 69.27539804265255\n",
      "24it [00:02, 10.88it/s]\n",
      "INFO:VAL loss: 1.3784312903881073, acc: 61.892361111111114\n",
      "INFO:VAL loss: 1.3784312903881073, acc: 61.892361111111114\n",
      "INFO:VAL loss: 1.3784312903881073, acc: 61.892361111111114\n",
      "INFO:VAL loss: 1.3784312903881073, acc: 61.892361111111114\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.91952466599049, acc: 71.6757504382121\n",
      "INFO:TRAIN loss: 0.91952466599049, acc: 71.6757504382121\n",
      "INFO:TRAIN loss: 0.91952466599049, acc: 71.6757504382121\n",
      "INFO:TRAIN loss: 0.91952466599049, acc: 71.6757504382121\n",
      "24it [00:02, 10.99it/s]\n",
      "INFO:VAL loss: 1.3906192084153493, acc: 62.25043402777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:VAL loss: 1.3906192084153493, acc: 62.25043402777778\n",
      "INFO:VAL loss: 1.3906192084153493, acc: 62.25043402777778\n",
      "INFO:VAL loss: 1.3906192084153493, acc: 62.25043402777778\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.8602835133763175, acc: 73.07529031551277\n",
      "INFO:TRAIN loss: 0.8602835133763175, acc: 73.07529031551277\n",
      "INFO:TRAIN loss: 0.8602835133763175, acc: 73.07529031551277\n",
      "INFO:TRAIN loss: 0.8602835133763175, acc: 73.07529031551277\n",
      "24it [00:02, 10.98it/s]\n",
      "INFO:VAL loss: 1.3857847849527998, acc: 62.60540674603175\n",
      "INFO:VAL loss: 1.3857847849527998, acc: 62.60540674603175\n",
      "INFO:VAL loss: 1.3857847849527998, acc: 62.60540674603175\n",
      "INFO:VAL loss: 1.3857847849527998, acc: 62.60540674603175\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.8100207758827447, acc: 74.50883727724218\n",
      "INFO:TRAIN loss: 0.8100207758827447, acc: 74.50883727724218\n",
      "INFO:TRAIN loss: 0.8100207758827447, acc: 74.50883727724218\n",
      "INFO:TRAIN loss: 0.8100207758827447, acc: 74.50883727724218\n",
      "24it [00:02, 10.93it/s]\n",
      "INFO:VAL loss: 1.3948541084925332, acc: 63.06113591269842\n",
      "INFO:VAL loss: 1.3948541084925332, acc: 63.06113591269842\n",
      "INFO:VAL loss: 1.3948541084925332, acc: 63.06113591269842\n",
      "INFO:VAL loss: 1.3948541084925332, acc: 63.06113591269842\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.7530796604653808, acc: 76.0996384750219\n",
      "INFO:TRAIN loss: 0.7530796604653808, acc: 76.0996384750219\n",
      "INFO:TRAIN loss: 0.7530796604653808, acc: 76.0996384750219\n",
      "INFO:TRAIN loss: 0.7530796604653808, acc: 76.0996384750219\n",
      "24it [00:02, 11.03it/s]\n",
      "INFO:VAL loss: 1.457922930518786, acc: 62.448846726190474\n",
      "INFO:VAL loss: 1.457922930518786, acc: 62.448846726190474\n",
      "INFO:VAL loss: 1.457922930518786, acc: 62.448846726190474\n",
      "INFO:VAL loss: 1.457922930518786, acc: 62.448846726190474\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.687420227227767, acc: 77.9218704352907\n",
      "INFO:TRAIN loss: 0.687420227227767, acc: 77.9218704352907\n",
      "INFO:TRAIN loss: 0.687420227227767, acc: 77.9218704352907\n",
      "INFO:TRAIN loss: 0.687420227227767, acc: 77.9218704352907\n",
      "24it [00:02, 10.96it/s]\n",
      "INFO:VAL loss: 1.4987968355417252, acc: 62.60850694444444\n",
      "INFO:VAL loss: 1.4987968355417252, acc: 62.60850694444444\n",
      "INFO:VAL loss: 1.4987968355417252, acc: 62.60850694444444\n",
      "INFO:VAL loss: 1.4987968355417252, acc: 62.60850694444444\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.6411005615091033, acc: 79.24517966695878\n",
      "INFO:TRAIN loss: 0.6411005615091033, acc: 79.24517966695878\n",
      "INFO:TRAIN loss: 0.6411005615091033, acc: 79.24517966695878\n",
      "INFO:TRAIN loss: 0.6411005615091033, acc: 79.24517966695878\n",
      "24it [00:02, 10.99it/s]\n",
      "INFO:VAL loss: 1.583403040965398, acc: 62.904575892857146\n",
      "INFO:VAL loss: 1.583403040965398, acc: 62.904575892857146\n",
      "INFO:VAL loss: 1.583403040965398, acc: 62.904575892857146\n",
      "INFO:VAL loss: 1.583403040965398, acc: 62.904575892857146\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.6045948096945241, acc: 80.25557807478818\n",
      "INFO:TRAIN loss: 0.6045948096945241, acc: 80.25557807478818\n",
      "INFO:TRAIN loss: 0.6045948096945241, acc: 80.25557807478818\n",
      "INFO:TRAIN loss: 0.6045948096945241, acc: 80.25557807478818\n",
      "24it [00:02, 11.00it/s]\n",
      "INFO:VAL loss: 1.5743117084105809, acc: 62.120225694444436\n",
      "INFO:VAL loss: 1.5743117084105809, acc: 62.120225694444436\n",
      "INFO:VAL loss: 1.5743117084105809, acc: 62.120225694444436\n",
      "INFO:VAL loss: 1.5743117084105809, acc: 62.120225694444436\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:34,  4.75it/s]\n",
      "INFO:TRAIN loss: 0.5633205776931315, acc: 81.42596954425943\n",
      "INFO:TRAIN loss: 0.5633205776931315, acc: 81.42596954425943\n",
      "INFO:TRAIN loss: 0.5633205776931315, acc: 81.42596954425943\n",
      "INFO:TRAIN loss: 0.5633205776931315, acc: 81.42596954425943\n",
      "24it [00:02, 10.98it/s]\n",
      "INFO:VAL loss: 1.6295657555262244, acc: 61.66449652777778\n",
      "INFO:VAL loss: 1.6295657555262244, acc: 61.66449652777778\n",
      "INFO:VAL loss: 1.6295657555262244, acc: 61.66449652777778\n",
      "INFO:VAL loss: 1.6295657555262244, acc: 61.66449652777778\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:34,  4.74it/s]\n",
      "INFO:TRAIN loss: 0.517937526381089, acc: 82.94875657318143\n",
      "INFO:TRAIN loss: 0.517937526381089, acc: 82.94875657318143\n",
      "INFO:TRAIN loss: 0.517937526381089, acc: 82.94875657318143\n",
      "INFO:TRAIN loss: 0.517937526381089, acc: 82.94875657318143\n",
      "24it [00:02, 11.00it/s]\n",
      "INFO:VAL loss: 1.6303360660870871, acc: 61.85980902777778\n",
      "INFO:VAL loss: 1.6303360660870871, acc: 61.85980902777778\n",
      "INFO:VAL loss: 1.6303360660870871, acc: 61.85980902777778\n",
      "INFO:VAL loss: 1.6303360660870871, acc: 61.85980902777778\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.49723454560238906, acc: 83.2525379783815\n",
      "INFO:TRAIN loss: 0.49723454560238906, acc: 83.2525379783815\n",
      "INFO:TRAIN loss: 0.49723454560238906, acc: 83.2525379783815\n",
      "INFO:TRAIN loss: 0.49723454560238906, acc: 83.2525379783815\n",
      "24it [00:02, 10.93it/s]\n",
      "INFO:VAL loss: 1.6898348331451418, acc: 61.472284226190474\n",
      "INFO:VAL loss: 1.6898348331451418, acc: 61.472284226190474\n",
      "INFO:VAL loss: 1.6898348331451418, acc: 61.472284226190474\n",
      "INFO:VAL loss: 1.6898348331451418, acc: 61.472284226190474\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:34,  4.74it/s]\n",
      "INFO:TRAIN loss: 0.4499241406200855, acc: 85.03026402278705\n",
      "INFO:TRAIN loss: 0.4499241406200855, acc: 85.03026402278705\n",
      "INFO:TRAIN loss: 0.4499241406200855, acc: 85.03026402278705\n",
      "INFO:TRAIN loss: 0.4499241406200855, acc: 85.03026402278705\n",
      "24it [00:02, 10.94it/s]\n",
      "INFO:VAL loss: 1.70232030749321, acc: 61.889260912698425\n",
      "INFO:VAL loss: 1.70232030749321, acc: 61.889260912698425\n",
      "INFO:VAL loss: 1.70232030749321, acc: 61.889260912698425\n",
      "INFO:VAL loss: 1.70232030749321, acc: 61.889260912698425\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.4316955199636565, acc: 85.49472319602688\n",
      "INFO:TRAIN loss: 0.4316955199636565, acc: 85.49472319602688\n",
      "INFO:TRAIN loss: 0.4316955199636565, acc: 85.49472319602688\n",
      "INFO:TRAIN loss: 0.4316955199636565, acc: 85.49472319602688\n",
      "24it [00:02, 10.93it/s]\n",
      "INFO:VAL loss: 1.783667057752609, acc: 61.27387152777777\n",
      "INFO:VAL loss: 1.783667057752609, acc: 61.27387152777777\n",
      "INFO:VAL loss: 1.783667057752609, acc: 61.27387152777777\n",
      "INFO:VAL loss: 1.783667057752609, acc: 61.27387152777777\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:34,  4.71it/s]\n",
      "INFO:TRAIN loss: 0.40895273860978193, acc: 86.26250730353492\n",
      "INFO:TRAIN loss: 0.40895273860978193, acc: 86.26250730353492\n",
      "INFO:TRAIN loss: 0.40895273860978193, acc: 86.26250730353492\n",
      "INFO:TRAIN loss: 0.40895273860978193, acc: 86.26250730353492\n",
      "24it [00:02, 10.95it/s]\n",
      "INFO:VAL loss: 1.8366174896558125, acc: 61.89546130952382\n",
      "INFO:VAL loss: 1.8366174896558125, acc: 61.89546130952382\n",
      "INFO:VAL loss: 1.8366174896558125, acc: 61.89546130952382\n",
      "INFO:VAL loss: 1.8366174896558125, acc: 61.89546130952382\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.3842389627468366, acc: 87.0423878907391\n",
      "INFO:TRAIN loss: 0.3842389627468366, acc: 87.0423878907391\n",
      "INFO:TRAIN loss: 0.3842389627468366, acc: 87.0423878907391\n",
      "INFO:TRAIN loss: 0.3842389627468366, acc: 87.0423878907391\n",
      "24it [00:02, 10.96it/s]\n",
      "INFO:VAL loss: 1.9118752529223757, acc: 61.76835317460317\n",
      "INFO:VAL loss: 1.9118752529223757, acc: 61.76835317460317\n",
      "INFO:VAL loss: 1.9118752529223757, acc: 61.76835317460317\n",
      "INFO:VAL loss: 1.9118752529223757, acc: 61.76835317460317\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.3652481930387533, acc: 87.63328951212391\n",
      "INFO:TRAIN loss: 0.3652481930387533, acc: 87.63328951212391\n",
      "INFO:TRAIN loss: 0.3652481930387533, acc: 87.63328951212391\n",
      "INFO:TRAIN loss: 0.3652481930387533, acc: 87.63328951212391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:02, 10.98it/s]\n",
      "INFO:VAL loss: 2.0034369627634683, acc: 61.50483630952381\n",
      "INFO:VAL loss: 2.0034369627634683, acc: 61.50483630952381\n",
      "INFO:VAL loss: 2.0034369627634683, acc: 61.50483630952381\n",
      "INFO:VAL loss: 2.0034369627634683, acc: 61.50483630952381\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.35564983850973503, acc: 88.03886393514462\n",
      "INFO:TRAIN loss: 0.35564983850973503, acc: 88.03886393514462\n",
      "INFO:TRAIN loss: 0.35564983850973503, acc: 88.03886393514462\n",
      "INFO:TRAIN loss: 0.35564983850973503, acc: 88.03886393514462\n",
      "24it [00:02, 11.00it/s]\n",
      "INFO:VAL loss: 2.026082019011179, acc: 61.013454861111114\n",
      "INFO:VAL loss: 2.026082019011179, acc: 61.013454861111114\n",
      "INFO:VAL loss: 2.026082019011179, acc: 61.013454861111114\n",
      "INFO:VAL loss: 2.026082019011179, acc: 61.013454861111114\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.33524918931027875, acc: 88.6249726117441\n",
      "INFO:TRAIN loss: 0.33524918931027875, acc: 88.6249726117441\n",
      "INFO:TRAIN loss: 0.33524918931027875, acc: 88.6249726117441\n",
      "INFO:TRAIN loss: 0.33524918931027875, acc: 88.6249726117441\n",
      "24it [00:02, 11.04it/s]\n",
      "INFO:VAL loss: 2.053962533672651, acc: 60.84449404761904\n",
      "INFO:VAL loss: 2.053962533672651, acc: 60.84449404761904\n",
      "INFO:VAL loss: 2.053962533672651, acc: 60.84449404761904\n",
      "INFO:VAL loss: 2.053962533672651, acc: 60.84449404761904\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.32662783325449823, acc: 88.84019865614957\n",
      "INFO:TRAIN loss: 0.32662783325449823, acc: 88.84019865614957\n",
      "INFO:TRAIN loss: 0.32662783325449823, acc: 88.84019865614957\n",
      "INFO:TRAIN loss: 0.32662783325449823, acc: 88.84019865614957\n",
      "24it [00:02, 10.92it/s]\n",
      "INFO:VAL loss: 1.993646701176962, acc: 62.32173859126984\n",
      "INFO:VAL loss: 1.993646701176962, acc: 62.32173859126984\n",
      "INFO:VAL loss: 1.993646701176962, acc: 62.32173859126984\n",
      "INFO:VAL loss: 1.993646701176962, acc: 62.32173859126984\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.3107757403806675, acc: 89.37883435582827\n",
      "INFO:TRAIN loss: 0.3107757403806675, acc: 89.37883435582827\n",
      "INFO:TRAIN loss: 0.3107757403806675, acc: 89.37883435582827\n",
      "INFO:TRAIN loss: 0.3107757403806675, acc: 89.37883435582827\n",
      "24it [00:02, 10.88it/s]\n",
      "INFO:VAL loss: 2.097368876139323, acc: 61.507936507936506\n",
      "INFO:VAL loss: 2.097368876139323, acc: 61.507936507936506\n",
      "INFO:VAL loss: 2.097368876139323, acc: 61.507936507936506\n",
      "INFO:VAL loss: 2.097368876139323, acc: 61.507936507936506\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.2974174796986432, acc: 89.90993828513002\n",
      "INFO:TRAIN loss: 0.2974174796986432, acc: 89.90993828513002\n",
      "INFO:TRAIN loss: 0.2974174796986432, acc: 89.90993828513002\n",
      "INFO:TRAIN loss: 0.2974174796986432, acc: 89.90993828513002\n",
      "24it [00:02, 10.94it/s]\n",
      "INFO:VAL loss: 2.1116600185632706, acc: 61.439732142857146\n",
      "INFO:VAL loss: 2.1116600185632706, acc: 61.439732142857146\n",
      "INFO:VAL loss: 2.1116600185632706, acc: 61.439732142857146\n",
      "INFO:VAL loss: 2.1116600185632706, acc: 61.439732142857146\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:34,  4.70it/s]\n",
      "INFO:TRAIN loss: 0.2895005282266007, acc: 90.23631500146068\n",
      "INFO:TRAIN loss: 0.2895005282266007, acc: 90.23631500146068\n",
      "INFO:TRAIN loss: 0.2895005282266007, acc: 90.23631500146068\n",
      "INFO:TRAIN loss: 0.2895005282266007, acc: 90.23631500146068\n",
      "24it [00:02, 10.93it/s]\n",
      "INFO:VAL loss: 2.100222418705622, acc: 61.37152777777778\n",
      "INFO:VAL loss: 2.100222418705622, acc: 61.37152777777778\n",
      "INFO:VAL loss: 2.100222418705622, acc: 61.37152777777778\n",
      "INFO:VAL loss: 2.100222418705622, acc: 61.37152777777778\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.2851042433019065, acc: 90.3355974291557\n",
      "INFO:TRAIN loss: 0.2851042433019065, acc: 90.3355974291557\n",
      "INFO:TRAIN loss: 0.2851042433019065, acc: 90.3355974291557\n",
      "INFO:TRAIN loss: 0.2851042433019065, acc: 90.3355974291557\n",
      "24it [00:02, 10.93it/s]\n",
      "INFO:VAL loss: 2.1539387404918666, acc: 61.176215277777786\n",
      "INFO:VAL loss: 2.1539387404918666, acc: 61.176215277777786\n",
      "INFO:VAL loss: 2.1539387404918666, acc: 61.176215277777786\n",
      "INFO:VAL loss: 2.1539387404918666, acc: 61.176215277777786\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.29483056840903926, acc: 89.98708187262638\n",
      "INFO:TRAIN loss: 0.29483056840903926, acc: 89.98708187262638\n",
      "INFO:TRAIN loss: 0.29483056840903926, acc: 89.98708187262638\n",
      "INFO:TRAIN loss: 0.29483056840903926, acc: 89.98708187262638\n",
      "24it [00:02, 10.87it/s]\n",
      "INFO:VAL loss: 2.095039978623391, acc: 62.74491567460317\n",
      "INFO:VAL loss: 2.095039978623391, acc: 62.74491567460317\n",
      "INFO:VAL loss: 2.095039978623391, acc: 62.74491567460317\n",
      "INFO:VAL loss: 2.095039978623391, acc: 62.74491567460317\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.2698810414119733, acc: 90.68685181127667\n",
      "INFO:TRAIN loss: 0.2698810414119733, acc: 90.68685181127667\n",
      "INFO:TRAIN loss: 0.2698810414119733, acc: 90.68685181127667\n",
      "INFO:TRAIN loss: 0.2698810414119733, acc: 90.68685181127667\n",
      "24it [00:02, 10.86it/s]\n",
      "INFO:VAL loss: 2.1493031630913415, acc: 62.64725942460318\n",
      "INFO:VAL loss: 2.1493031630913415, acc: 62.64725942460318\n",
      "INFO:VAL loss: 2.1493031630913415, acc: 62.64725942460318\n",
      "INFO:VAL loss: 2.1493031630913415, acc: 62.64725942460318\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.2419683368293786, acc: 91.51648773006137\n",
      "INFO:TRAIN loss: 0.2419683368293786, acc: 91.51648773006137\n",
      "INFO:TRAIN loss: 0.2419683368293786, acc: 91.51648773006137\n",
      "INFO:TRAIN loss: 0.2419683368293786, acc: 91.51648773006137\n",
      "24it [00:02, 10.94it/s]\n",
      "INFO:VAL loss: 2.297056794166565, acc: 62.15277777777778\n",
      "INFO:VAL loss: 2.297056794166565, acc: 62.15277777777778\n",
      "INFO:VAL loss: 2.297056794166565, acc: 62.15277777777778\n",
      "INFO:VAL loss: 2.297056794166565, acc: 62.15277777777778\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.25014863373494584, acc: 91.59134896289811\n",
      "INFO:TRAIN loss: 0.25014863373494584, acc: 91.59134896289811\n",
      "INFO:TRAIN loss: 0.25014863373494584, acc: 91.59134896289811\n",
      "INFO:TRAIN loss: 0.25014863373494584, acc: 91.59134896289811\n",
      "24it [00:02, 10.87it/s]\n",
      "INFO:VAL loss: 2.3050765991210938, acc: 61.95746527777778\n",
      "INFO:VAL loss: 2.3050765991210938, acc: 61.95746527777778\n",
      "INFO:VAL loss: 2.3050765991210938, acc: 61.95746527777778\n",
      "INFO:VAL loss: 2.3050765991210938, acc: 61.95746527777778\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.2642050766688916, acc: 90.9504637744669\n",
      "INFO:TRAIN loss: 0.2642050766688916, acc: 90.9504637744669\n",
      "INFO:TRAIN loss: 0.2642050766688916, acc: 90.9504637744669\n",
      "INFO:TRAIN loss: 0.2642050766688916, acc: 90.9504637744669\n",
      "24it [00:02, 10.96it/s]\n",
      "INFO:VAL loss: 2.217064599196116, acc: 61.86600942460316\n",
      "INFO:VAL loss: 2.217064599196116, acc: 61.86600942460316\n",
      "INFO:VAL loss: 2.217064599196116, acc: 61.86600942460316\n",
      "INFO:VAL loss: 2.217064599196116, acc: 61.86600942460316\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.24689544417375445, acc: 91.60618426818574\n",
      "INFO:TRAIN loss: 0.24689544417375445, acc: 91.60618426818574\n",
      "INFO:TRAIN loss: 0.24689544417375445, acc: 91.60618426818574\n",
      "INFO:TRAIN loss: 0.24689544417375445, acc: 91.60618426818574\n",
      "24it [00:02, 10.98it/s]\n",
      "INFO:VAL loss: 2.3445649345715838, acc: 61.537388392857146\n",
      "INFO:VAL loss: 2.3445649345715838, acc: 61.537388392857146\n",
      "INFO:VAL loss: 2.3445649345715838, acc: 61.537388392857146\n",
      "INFO:VAL loss: 2.3445649345715838, acc: 61.537388392857146\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.2539837790961646, acc: 91.26109224364588\n",
      "INFO:TRAIN loss: 0.2539837790961646, acc: 91.26109224364588\n",
      "INFO:TRAIN loss: 0.2539837790961646, acc: 91.26109224364588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN loss: 0.2539837790961646, acc: 91.26109224364588\n",
      "24it [00:02, 11.04it/s]\n",
      "INFO:VAL loss: 2.317560931046804, acc: 61.43663194444444\n",
      "INFO:VAL loss: 2.317560931046804, acc: 61.43663194444444\n",
      "INFO:VAL loss: 2.317560931046804, acc: 61.43663194444444\n",
      "INFO:VAL loss: 2.317560931046804, acc: 61.43663194444444\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.24621602444926655, acc: 91.62535604732686\n",
      "INFO:TRAIN loss: 0.24621602444926655, acc: 91.62535604732686\n",
      "INFO:TRAIN loss: 0.24621602444926655, acc: 91.62535604732686\n",
      "INFO:TRAIN loss: 0.24621602444926655, acc: 91.62535604732686\n",
      "24it [00:02, 10.98it/s]\n",
      "INFO:VAL loss: 2.260161474347114, acc: 60.85379464285714\n",
      "INFO:VAL loss: 2.260161474347114, acc: 60.85379464285714\n",
      "INFO:VAL loss: 2.260161474347114, acc: 60.85379464285714\n",
      "INFO:VAL loss: 2.260161474347114, acc: 60.85379464285714\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.2301922366480155, acc: 92.0863916885773\n",
      "INFO:TRAIN loss: 0.2301922366480155, acc: 92.0863916885773\n",
      "INFO:TRAIN loss: 0.2301922366480155, acc: 92.0863916885773\n",
      "INFO:TRAIN loss: 0.2301922366480155, acc: 92.0863916885773\n",
      "24it [00:02, 11.02it/s]\n",
      "INFO:VAL loss: 2.3227260063091917, acc: 61.85980902777778\n",
      "INFO:VAL loss: 2.3227260063091917, acc: 61.85980902777778\n",
      "INFO:VAL loss: 2.3227260063091917, acc: 61.85980902777778\n",
      "INFO:VAL loss: 2.3227260063091917, acc: 61.85980902777778\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.23946986859378636, acc: 91.75088555360799\n",
      "INFO:TRAIN loss: 0.23946986859378636, acc: 91.75088555360799\n",
      "INFO:TRAIN loss: 0.23946986859378636, acc: 91.75088555360799\n",
      "INFO:TRAIN loss: 0.23946986859378636, acc: 91.75088555360799\n",
      "24it [00:02, 10.92it/s]\n",
      "INFO:VAL loss: 2.372739429275195, acc: 61.0134548611111\n",
      "INFO:VAL loss: 2.372739429275195, acc: 61.0134548611111\n",
      "INFO:VAL loss: 2.372739429275195, acc: 61.0134548611111\n",
      "INFO:VAL loss: 2.372739429275195, acc: 61.0134548611111\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.2373472316407718, acc: 91.46239592462759\n",
      "INFO:TRAIN loss: 0.2373472316407718, acc: 91.46239592462759\n",
      "INFO:TRAIN loss: 0.2373472316407718, acc: 91.46239592462759\n",
      "INFO:TRAIN loss: 0.2373472316407718, acc: 91.46239592462759\n",
      "24it [00:02, 11.05it/s]\n",
      "INFO:VAL loss: 2.272192354003588, acc: 62.25353422619047\n",
      "INFO:VAL loss: 2.272192354003588, acc: 62.25353422619047\n",
      "INFO:VAL loss: 2.272192354003588, acc: 62.25353422619047\n",
      "INFO:VAL loss: 2.272192354003588, acc: 62.25353422619047\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:34,  4.74it/s]\n",
      "INFO:TRAIN loss: 0.23112255216010508, acc: 92.07726226993859\n",
      "INFO:TRAIN loss: 0.23112255216010508, acc: 92.07726226993859\n",
      "INFO:TRAIN loss: 0.23112255216010508, acc: 92.07726226993859\n",
      "INFO:TRAIN loss: 0.23112255216010508, acc: 92.07726226993859\n",
      "24it [00:02, 10.95it/s]\n",
      "INFO:VAL loss: 2.489300603667895, acc: 61.33897569444444\n",
      "INFO:VAL loss: 2.489300603667895, acc: 61.33897569444444\n",
      "INFO:VAL loss: 2.489300603667895, acc: 61.33897569444444\n",
      "INFO:VAL loss: 2.489300603667895, acc: 61.33897569444444\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:34,  4.71it/s]\n",
      "INFO:TRAIN loss: 0.22648334681439253, acc: 92.13432113643\n",
      "INFO:TRAIN loss: 0.22648334681439253, acc: 92.13432113643\n",
      "INFO:TRAIN loss: 0.22648334681439253, acc: 92.13432113643\n",
      "INFO:TRAIN loss: 0.22648334681439253, acc: 92.13432113643\n",
      "24it [00:02, 10.91it/s]\n",
      "INFO:VAL loss: 2.452936266859372, acc: 61.34517609126985\n",
      "INFO:VAL loss: 2.452936266859372, acc: 61.34517609126985\n",
      "INFO:VAL loss: 2.452936266859372, acc: 61.34517609126985\n",
      "INFO:VAL loss: 2.452936266859372, acc: 61.34517609126985\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.22475113609999958, acc: 92.16216586327785\n",
      "INFO:TRAIN loss: 0.22475113609999958, acc: 92.16216586327785\n",
      "INFO:TRAIN loss: 0.22475113609999958, acc: 92.16216586327785\n",
      "INFO:TRAIN loss: 0.22475113609999958, acc: 92.16216586327785\n",
      "24it [00:02, 10.76it/s]\n",
      "INFO:VAL loss: 2.4362945109605785, acc: 61.67069692460318\n",
      "INFO:VAL loss: 2.4362945109605785, acc: 61.67069692460318\n",
      "INFO:VAL loss: 2.4362945109605785, acc: 61.67069692460318\n",
      "INFO:VAL loss: 2.4362945109605785, acc: 61.67069692460318\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.22131789224279427, acc: 92.32558245690915\n",
      "INFO:TRAIN loss: 0.22131789224279427, acc: 92.32558245690915\n",
      "INFO:TRAIN loss: 0.22131789224279427, acc: 92.32558245690915\n",
      "INFO:TRAIN loss: 0.22131789224279427, acc: 92.32558245690915\n",
      "24it [00:02, 10.90it/s]\n",
      "INFO:VAL loss: 2.3253917843103413, acc: 61.37152777777778\n",
      "INFO:VAL loss: 2.3253917843103413, acc: 61.37152777777778\n",
      "INFO:VAL loss: 2.3253917843103413, acc: 61.37152777777778\n",
      "INFO:VAL loss: 2.3253917843103413, acc: 61.37152777777778\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:34,  4.72it/s]\n",
      "INFO:TRAIN loss: 0.2112145773106557, acc: 92.54651438796375\n",
      "INFO:TRAIN loss: 0.2112145773106557, acc: 92.54651438796375\n",
      "INFO:TRAIN loss: 0.2112145773106557, acc: 92.54651438796375\n",
      "INFO:TRAIN loss: 0.2112145773106557, acc: 92.54651438796375\n",
      "24it [00:02, 10.96it/s]\n",
      "INFO:VAL loss: 2.4856606274843225, acc: 61.605592757936506\n",
      "INFO:VAL loss: 2.4856606274843225, acc: 61.605592757936506\n",
      "INFO:VAL loss: 2.4856606274843225, acc: 61.605592757936506\n",
      "INFO:VAL loss: 2.4856606274843225, acc: 61.605592757936506\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 0.214587504878366, acc: 92.50292141396439\n",
      "INFO:TRAIN loss: 0.214587504878366, acc: 92.50292141396439\n",
      "INFO:TRAIN loss: 0.214587504878366, acc: 92.50292141396439\n",
      "INFO:TRAIN loss: 0.214587504878366, acc: 92.50292141396439\n",
      "24it [00:02, 10.97it/s]\n",
      "INFO:VAL loss: 2.6547123094399776, acc: 61.01035466269841\n",
      "INFO:VAL loss: 2.6547123094399776, acc: 61.01035466269841\n",
      "INFO:VAL loss: 2.6547123094399776, acc: 61.01035466269841\n",
      "INFO:VAL loss: 2.6547123094399776, acc: 61.01035466269841\n",
      "47it [00:04, 10.74it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 2.522403572468048, acc: 61.384792069632496\n",
      "INFO:\n",
      "\n",
      "TEST loss: 2.522403572468048, acc: 61.384792069632496\n",
      "INFO:\n",
      "\n",
      "TEST loss: 2.522403572468048, acc: 61.384792069632496\n",
      "INFO:\n",
      "\n",
      "TEST loss: 2.522403572468048, acc: 61.384792069632496\n",
      "INFO:{'epoch_index': 49, 'train_loss': [2.64481549979719, 1.970312620964518, 1.7215144049170552, 1.5660451409275544, 1.4357029141092599, 1.3392657725357573, 1.2667924820279783, 1.1910687249862342, 1.120567545934689, 1.0495362757173785, 0.9939224259253662, 0.91952466599049, 0.8602835133763175, 0.8100207758827447, 0.7530796604653808, 0.687420227227767, 0.6411005615091033, 0.6045948096945241, 0.5633205776931315, 0.517937526381089, 0.49723454560238906, 0.4499241406200855, 0.4316955199636565, 0.40895273860978193, 0.3842389627468366, 0.3652481930387533, 0.35564983850973503, 0.33524918931027875, 0.32662783325449823, 0.3107757403806675, 0.2974174796986432, 0.2895005282266007, 0.2851042433019065, 0.29483056840903926, 0.2698810414119733, 0.2419683368293786, 0.25014863373494584, 0.2642050766688916, 0.24689544417375445, 0.2539837790961646, 0.24621602444926655, 0.2301922366480155, 0.23946986859378636, 0.2373472316407718, 0.23112255216010508, 0.22648334681439253, 0.22475113609999958, 0.22131789224279427, 0.2112145773106557, 0.214587504878366], 'train_acc': [23.82367440841367, 42.05877519719542, 49.307761831726545, 53.940028848962896, 57.29029725387087, 60.23499123575811, 62.261493938066046, 64.2850295793164, 66.19307807478822, 67.9790205959684, 69.27539804265255, 71.6757504382121, 73.07529031551277, 74.50883727724218, 76.0996384750219, 77.9218704352907, 79.24517966695878, 80.25557807478818, 81.42596954425943, 82.94875657318143, 83.2525379783815, 85.03026402278705, 85.49472319602688, 86.26250730353492, 87.0423878907391, 87.63328951212391, 88.03886393514462, 88.6249726117441, 88.84019865614957, 89.37883435582827, 89.90993828513002, 90.23631500146068, 90.3355974291557, 89.98708187262638, 90.68685181127667, 91.51648773006137, 91.59134896289811, 90.9504637744669, 91.60618426818574, 91.26109224364588, 91.62535604732686, 92.0863916885773, 91.75088555360799, 91.46239592462759, 92.07726226993859, 92.13432113643, 92.16216586327785, 92.32558245690915, 92.54651438796375, 92.50292141396439], 'val_loss': [2.0642712811628976, 1.8661440114180248, 1.620772823691368, 1.5278209298849106, 1.4563077737887702, 1.4259889672199884, 1.400616606076558, 1.431149592002233, 1.3885577917099, 1.36677640179793, 1.3784312903881073, 1.3906192084153493, 1.3857847849527998, 1.3948541084925332, 1.457922930518786, 1.4987968355417252, 1.583403040965398, 1.5743117084105809, 1.6295657555262244, 1.6303360660870871, 1.6898348331451418, 1.70232030749321, 1.783667057752609, 1.8366174896558125, 1.9118752529223757, 2.0034369627634683, 2.026082019011179, 2.053962533672651, 1.993646701176962, 2.097368876139323, 2.1116600185632706, 2.100222418705622, 2.1539387404918666, 2.095039978623391, 2.1493031630913415, 2.297056794166565, 2.3050765991210938, 2.217064599196116, 2.3445649345715838, 2.317560931046804, 2.260161474347114, 2.3227260063091917, 2.372739429275195, 2.272192354003588, 2.489300603667895, 2.452936266859372, 2.4362945109605785, 2.3253917843103413, 2.4856606274843225, 2.6547123094399776], 'val_acc': [40.36613343253969, 45.379154265873034, 53.33116319444445, 56.22209821428571, 57.51798115079365, 59.095982142857146, 60.00434027777778, 59.477306547619044, 60.847594246031754, 61.306423611111114, 61.892361111111114, 62.25043402777778, 62.60540674603175, 63.06113591269842, 62.448846726190474, 62.60850694444444, 62.904575892857146, 62.120225694444436, 61.66449652777778, 61.85980902777778, 61.472284226190474, 61.889260912698425, 61.27387152777777, 61.89546130952382, 61.76835317460317, 61.50483630952381, 61.013454861111114, 60.84449404761904, 62.32173859126984, 61.507936507936506, 61.439732142857146, 61.37152777777778, 61.176215277777786, 62.74491567460317, 62.64725942460318, 62.15277777777778, 61.95746527777778, 61.86600942460316, 61.537388392857146, 61.43663194444444, 60.85379464285714, 61.85980902777778, 61.0134548611111, 62.25353422619047, 61.33897569444444, 61.34517609126985, 61.67069692460318, 61.37152777777778, 61.605592757936506, 61.01035466269841], 'test_loss': 2.522403572468048, 'test_acc': 61.384792069632496}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:{'epoch_index': 49, 'train_loss': [2.64481549979719, 1.970312620964518, 1.7215144049170552, 1.5660451409275544, 1.4357029141092599, 1.3392657725357573, 1.2667924820279783, 1.1910687249862342, 1.120567545934689, 1.0495362757173785, 0.9939224259253662, 0.91952466599049, 0.8602835133763175, 0.8100207758827447, 0.7530796604653808, 0.687420227227767, 0.6411005615091033, 0.6045948096945241, 0.5633205776931315, 0.517937526381089, 0.49723454560238906, 0.4499241406200855, 0.4316955199636565, 0.40895273860978193, 0.3842389627468366, 0.3652481930387533, 0.35564983850973503, 0.33524918931027875, 0.32662783325449823, 0.3107757403806675, 0.2974174796986432, 0.2895005282266007, 0.2851042433019065, 0.29483056840903926, 0.2698810414119733, 0.2419683368293786, 0.25014863373494584, 0.2642050766688916, 0.24689544417375445, 0.2539837790961646, 0.24621602444926655, 0.2301922366480155, 0.23946986859378636, 0.2373472316407718, 0.23112255216010508, 0.22648334681439253, 0.22475113609999958, 0.22131789224279427, 0.2112145773106557, 0.214587504878366], 'train_acc': [23.82367440841367, 42.05877519719542, 49.307761831726545, 53.940028848962896, 57.29029725387087, 60.23499123575811, 62.261493938066046, 64.2850295793164, 66.19307807478822, 67.9790205959684, 69.27539804265255, 71.6757504382121, 73.07529031551277, 74.50883727724218, 76.0996384750219, 77.9218704352907, 79.24517966695878, 80.25557807478818, 81.42596954425943, 82.94875657318143, 83.2525379783815, 85.03026402278705, 85.49472319602688, 86.26250730353492, 87.0423878907391, 87.63328951212391, 88.03886393514462, 88.6249726117441, 88.84019865614957, 89.37883435582827, 89.90993828513002, 90.23631500146068, 90.3355974291557, 89.98708187262638, 90.68685181127667, 91.51648773006137, 91.59134896289811, 90.9504637744669, 91.60618426818574, 91.26109224364588, 91.62535604732686, 92.0863916885773, 91.75088555360799, 91.46239592462759, 92.07726226993859, 92.13432113643, 92.16216586327785, 92.32558245690915, 92.54651438796375, 92.50292141396439], 'val_loss': [2.0642712811628976, 1.8661440114180248, 1.620772823691368, 1.5278209298849106, 1.4563077737887702, 1.4259889672199884, 1.400616606076558, 1.431149592002233, 1.3885577917099, 1.36677640179793, 1.3784312903881073, 1.3906192084153493, 1.3857847849527998, 1.3948541084925332, 1.457922930518786, 1.4987968355417252, 1.583403040965398, 1.5743117084105809, 1.6295657555262244, 1.6303360660870871, 1.6898348331451418, 1.70232030749321, 1.783667057752609, 1.8366174896558125, 1.9118752529223757, 2.0034369627634683, 2.026082019011179, 2.053962533672651, 1.993646701176962, 2.097368876139323, 2.1116600185632706, 2.100222418705622, 2.1539387404918666, 2.095039978623391, 2.1493031630913415, 2.297056794166565, 2.3050765991210938, 2.217064599196116, 2.3445649345715838, 2.317560931046804, 2.260161474347114, 2.3227260063091917, 2.372739429275195, 2.272192354003588, 2.489300603667895, 2.452936266859372, 2.4362945109605785, 2.3253917843103413, 2.4856606274843225, 2.6547123094399776], 'val_acc': [40.36613343253969, 45.379154265873034, 53.33116319444445, 56.22209821428571, 57.51798115079365, 59.095982142857146, 60.00434027777778, 59.477306547619044, 60.847594246031754, 61.306423611111114, 61.892361111111114, 62.25043402777778, 62.60540674603175, 63.06113591269842, 62.448846726190474, 62.60850694444444, 62.904575892857146, 62.120225694444436, 61.66449652777778, 61.85980902777778, 61.472284226190474, 61.889260912698425, 61.27387152777777, 61.89546130952382, 61.76835317460317, 61.50483630952381, 61.013454861111114, 60.84449404761904, 62.32173859126984, 61.507936507936506, 61.439732142857146, 61.37152777777778, 61.176215277777786, 62.74491567460317, 62.64725942460318, 62.15277777777778, 61.95746527777778, 61.86600942460316, 61.537388392857146, 61.43663194444444, 60.85379464285714, 61.85980902777778, 61.0134548611111, 62.25353422619047, 61.33897569444444, 61.34517609126985, 61.67069692460318, 61.37152777777778, 61.605592757936506, 61.01035466269841], 'test_loss': 2.522403572468048, 'test_acc': 61.384792069632496}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [2.64481549979719, 1.970312620964518, 1.7215144049170552, 1.5660451409275544, 1.4357029141092599, 1.3392657725357573, 1.2667924820279783, 1.1910687249862342, 1.120567545934689, 1.0495362757173785, 0.9939224259253662, 0.91952466599049, 0.8602835133763175, 0.8100207758827447, 0.7530796604653808, 0.687420227227767, 0.6411005615091033, 0.6045948096945241, 0.5633205776931315, 0.517937526381089, 0.49723454560238906, 0.4499241406200855, 0.4316955199636565, 0.40895273860978193, 0.3842389627468366, 0.3652481930387533, 0.35564983850973503, 0.33524918931027875, 0.32662783325449823, 0.3107757403806675, 0.2974174796986432, 0.2895005282266007, 0.2851042433019065, 0.29483056840903926, 0.2698810414119733, 0.2419683368293786, 0.25014863373494584, 0.2642050766688916, 0.24689544417375445, 0.2539837790961646, 0.24621602444926655, 0.2301922366480155, 0.23946986859378636, 0.2373472316407718, 0.23112255216010508, 0.22648334681439253, 0.22475113609999958, 0.22131789224279427, 0.2112145773106557, 0.214587504878366], 'train_acc': [23.82367440841367, 42.05877519719542, 49.307761831726545, 53.940028848962896, 57.29029725387087, 60.23499123575811, 62.261493938066046, 64.2850295793164, 66.19307807478822, 67.9790205959684, 69.27539804265255, 71.6757504382121, 73.07529031551277, 74.50883727724218, 76.0996384750219, 77.9218704352907, 79.24517966695878, 80.25557807478818, 81.42596954425943, 82.94875657318143, 83.2525379783815, 85.03026402278705, 85.49472319602688, 86.26250730353492, 87.0423878907391, 87.63328951212391, 88.03886393514462, 88.6249726117441, 88.84019865614957, 89.37883435582827, 89.90993828513002, 90.23631500146068, 90.3355974291557, 89.98708187262638, 90.68685181127667, 91.51648773006137, 91.59134896289811, 90.9504637744669, 91.60618426818574, 91.26109224364588, 91.62535604732686, 92.0863916885773, 91.75088555360799, 91.46239592462759, 92.07726226993859, 92.13432113643, 92.16216586327785, 92.32558245690915, 92.54651438796375, 92.50292141396439], 'val_loss': [2.0642712811628976, 1.8661440114180248, 1.620772823691368, 1.5278209298849106, 1.4563077737887702, 1.4259889672199884, 1.400616606076558, 1.431149592002233, 1.3885577917099, 1.36677640179793, 1.3784312903881073, 1.3906192084153493, 1.3857847849527998, 1.3948541084925332, 1.457922930518786, 1.4987968355417252, 1.583403040965398, 1.5743117084105809, 1.6295657555262244, 1.6303360660870871, 1.6898348331451418, 1.70232030749321, 1.783667057752609, 1.8366174896558125, 1.9118752529223757, 2.0034369627634683, 2.026082019011179, 2.053962533672651, 1.993646701176962, 2.097368876139323, 2.1116600185632706, 2.100222418705622, 2.1539387404918666, 2.095039978623391, 2.1493031630913415, 2.297056794166565, 2.3050765991210938, 2.217064599196116, 2.3445649345715838, 2.317560931046804, 2.260161474347114, 2.3227260063091917, 2.372739429275195, 2.272192354003588, 2.489300603667895, 2.452936266859372, 2.4362945109605785, 2.3253917843103413, 2.4856606274843225, 2.6547123094399776], 'val_acc': [40.36613343253969, 45.379154265873034, 53.33116319444445, 56.22209821428571, 57.51798115079365, 59.095982142857146, 60.00434027777778, 59.477306547619044, 60.847594246031754, 61.306423611111114, 61.892361111111114, 62.25043402777778, 62.60540674603175, 63.06113591269842, 62.448846726190474, 62.60850694444444, 62.904575892857146, 62.120225694444436, 61.66449652777778, 61.85980902777778, 61.472284226190474, 61.889260912698425, 61.27387152777777, 61.89546130952382, 61.76835317460317, 61.50483630952381, 61.013454861111114, 60.84449404761904, 62.32173859126984, 61.507936507936506, 61.439732142857146, 61.37152777777778, 61.176215277777786, 62.74491567460317, 62.64725942460318, 62.15277777777778, 61.95746527777778, 61.86600942460316, 61.537388392857146, 61.43663194444444, 60.85379464285714, 61.85980902777778, 61.0134548611111, 62.25353422619047, 61.33897569444444, 61.34517609126985, 61.67069692460318, 61.37152777777778, 61.605592757936506, 61.01035466269841], 'test_loss': 2.522403572468048, 'test_acc': 61.384792069632496}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [2.64481549979719, 1.970312620964518, 1.7215144049170552, 1.5660451409275544, 1.4357029141092599, 1.3392657725357573, 1.2667924820279783, 1.1910687249862342, 1.120567545934689, 1.0495362757173785, 0.9939224259253662, 0.91952466599049, 0.8602835133763175, 0.8100207758827447, 0.7530796604653808, 0.687420227227767, 0.6411005615091033, 0.6045948096945241, 0.5633205776931315, 0.517937526381089, 0.49723454560238906, 0.4499241406200855, 0.4316955199636565, 0.40895273860978193, 0.3842389627468366, 0.3652481930387533, 0.35564983850973503, 0.33524918931027875, 0.32662783325449823, 0.3107757403806675, 0.2974174796986432, 0.2895005282266007, 0.2851042433019065, 0.29483056840903926, 0.2698810414119733, 0.2419683368293786, 0.25014863373494584, 0.2642050766688916, 0.24689544417375445, 0.2539837790961646, 0.24621602444926655, 0.2301922366480155, 0.23946986859378636, 0.2373472316407718, 0.23112255216010508, 0.22648334681439253, 0.22475113609999958, 0.22131789224279427, 0.2112145773106557, 0.214587504878366], 'train_acc': [23.82367440841367, 42.05877519719542, 49.307761831726545, 53.940028848962896, 57.29029725387087, 60.23499123575811, 62.261493938066046, 64.2850295793164, 66.19307807478822, 67.9790205959684, 69.27539804265255, 71.6757504382121, 73.07529031551277, 74.50883727724218, 76.0996384750219, 77.9218704352907, 79.24517966695878, 80.25557807478818, 81.42596954425943, 82.94875657318143, 83.2525379783815, 85.03026402278705, 85.49472319602688, 86.26250730353492, 87.0423878907391, 87.63328951212391, 88.03886393514462, 88.6249726117441, 88.84019865614957, 89.37883435582827, 89.90993828513002, 90.23631500146068, 90.3355974291557, 89.98708187262638, 90.68685181127667, 91.51648773006137, 91.59134896289811, 90.9504637744669, 91.60618426818574, 91.26109224364588, 91.62535604732686, 92.0863916885773, 91.75088555360799, 91.46239592462759, 92.07726226993859, 92.13432113643, 92.16216586327785, 92.32558245690915, 92.54651438796375, 92.50292141396439], 'val_loss': [2.0642712811628976, 1.8661440114180248, 1.620772823691368, 1.5278209298849106, 1.4563077737887702, 1.4259889672199884, 1.400616606076558, 1.431149592002233, 1.3885577917099, 1.36677640179793, 1.3784312903881073, 1.3906192084153493, 1.3857847849527998, 1.3948541084925332, 1.457922930518786, 1.4987968355417252, 1.583403040965398, 1.5743117084105809, 1.6295657555262244, 1.6303360660870871, 1.6898348331451418, 1.70232030749321, 1.783667057752609, 1.8366174896558125, 1.9118752529223757, 2.0034369627634683, 2.026082019011179, 2.053962533672651, 1.993646701176962, 2.097368876139323, 2.1116600185632706, 2.100222418705622, 2.1539387404918666, 2.095039978623391, 2.1493031630913415, 2.297056794166565, 2.3050765991210938, 2.217064599196116, 2.3445649345715838, 2.317560931046804, 2.260161474347114, 2.3227260063091917, 2.372739429275195, 2.272192354003588, 2.489300603667895, 2.452936266859372, 2.4362945109605785, 2.3253917843103413, 2.4856606274843225, 2.6547123094399776], 'val_acc': [40.36613343253969, 45.379154265873034, 53.33116319444445, 56.22209821428571, 57.51798115079365, 59.095982142857146, 60.00434027777778, 59.477306547619044, 60.847594246031754, 61.306423611111114, 61.892361111111114, 62.25043402777778, 62.60540674603175, 63.06113591269842, 62.448846726190474, 62.60850694444444, 62.904575892857146, 62.120225694444436, 61.66449652777778, 61.85980902777778, 61.472284226190474, 61.889260912698425, 61.27387152777777, 61.89546130952382, 61.76835317460317, 61.50483630952381, 61.013454861111114, 60.84449404761904, 62.32173859126984, 61.507936507936506, 61.439732142857146, 61.37152777777778, 61.176215277777786, 62.74491567460317, 62.64725942460318, 62.15277777777778, 61.95746527777778, 61.86600942460316, 61.537388392857146, 61.43663194444444, 60.85379464285714, 61.85980902777778, 61.0134548611111, 62.25353422619047, 61.33897569444444, 61.34517609126985, 61.67069692460318, 61.37152777777778, 61.605592757936506, 61.01035466269841], 'test_loss': 2.522403572468048, 'test_acc': 61.384792069632496}\n"
     ]
    }
   ],
   "source": [
    "# Model 12\n",
    "args.model_id=12\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_prainembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_prainembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_prainembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "model = JobtypeClassifier_Conv1d(embedding_size=100, num_channels=128,hidden_dim=100, label_nums=label_nums, dropout_p=0.1)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "#args.logger.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4819352",
   "metadata": {},
   "source": [
    "**acc:61.38**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae10e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c661cd63",
   "metadata": {},
   "source": [
    "# Task 2: Multi-class Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19167a17",
   "metadata": {},
   "source": [
    "### Prepare Data for Multi Class Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1483069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from mydataset import JobVectorizer, JobDatasetOnehot, JobDatasetMyembedding, JobDatasetPretrainembedding\n",
    "from mydataset import collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import compute_accuracy, train_engin, test_engine, make_train_state, get_logger\n",
    "import torch.optim as optim \n",
    "\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "\n",
    "from models import RnnModel1, RnnModel2, LstmModel\n",
    "from argparse import Namespace\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170ce427",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    loss_func= nn.CrossEntropyLoss(),\n",
    "    optimizer=None,\n",
    "    model_id=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a8f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"./dataset/job_prapare.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(eval)\n",
    "df['10words_type']=df['10words_type'].apply(eval)\n",
    "df['10words_category']=df['10words_category'].apply(eval)\n",
    "\n",
    "text_column = \"job_description\"\n",
    "label_column = \"category\"\n",
    "label_nums = len(df[label_column].value_counts())\n",
    "\n",
    "train_df = df[df.split=='train'].copy().reset_index(drop=True)\n",
    "val_df = df[df.split=='val'].copy().reset_index(drop=True)\n",
    "test_df = df[df.split=='test'].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "my_embedding = KeyedVectors.load(\"./dataset/my_embedding\", mmap='r')\n",
    "my_embedding.wv.add_vectors(\"<pad>\", torch.zeros(100))\n",
    "\n",
    "jobtype_myembedding_train_full = JobDatasetMyembedding(train_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_myembedding_val_full = JobDatasetMyembedding(val_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_myembedding_test_full = JobDatasetMyembedding(test_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n",
    "\n",
    "jobtype_prainembedding_train_full = JobDatasetPretrainembedding(train_df, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_prainembedding_val_full = JobDatasetPretrainembedding(val_df, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_prainembedding_test_full = JobDatasetPretrainembedding(test_df, text_column=text_column, label_column=label_column, words_len=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255db0a",
   "metadata": {},
   "source": [
    "Compared with pretrain embedding, my embedding is more superior and has higher acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b83a7",
   "metadata": {},
   "source": [
    "**`model 13: text--job_description, embedding--myembedding, model--rnn`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b24990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=13, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:27,  5.89it/s]\n",
      "INFO:TRAIN loss: 3.1235298437574905, acc: 12.018651402278707\n",
      "24it [00:01, 13.72it/s]\n",
      "INFO:VAL loss: 2.9977557758490243, acc: 15.299479166666664\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:18,  9.03it/s]\n",
      "INFO:TRAIN loss: 2.9903613189978104, acc: 14.854248831434411\n",
      "24it [00:01, 14.13it/s]\n",
      "INFO:VAL loss: 2.8983249763647714, acc: 17.681981646825392\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:15, 10.43it/s]\n",
      "INFO:TRAIN loss: 2.929612292833855, acc: 17.250721224072457\n",
      "24it [00:01, 14.19it/s]\n",
      "INFO:VAL loss: 2.8751232524712886, acc: 17.951698908730158\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:18,  8.85it/s]\n",
      "INFO:TRAIN loss: 2.9194676642037614, acc: 16.833735027753434\n",
      "24it [00:01, 14.23it/s]\n",
      "INFO:VAL loss: 2.8132684032122293, acc: 19.218129960317455\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:28,  5.81it/s]\n",
      "INFO:TRAIN loss: 2.8976120422222866, acc: 16.608466622845448\n",
      "24it [00:01, 14.23it/s]\n",
      "INFO:VAL loss: 2.8374347984790798, acc: 15.376984126984127\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:20,  8.09it/s]\n",
      "INFO:TRAIN loss: 2.9799429024655386, acc: 14.691288708735033\n",
      "24it [00:01, 14.24it/s]\n",
      "INFO:VAL loss: 3.0012767215569816, acc: 14.101252480158731\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:16,  9.91it/s]\n",
      "INFO:TRAIN loss: 2.967534524531453, acc: 15.855974291557114\n",
      "24it [00:01, 13.82it/s]\n",
      "INFO:VAL loss: 2.8567942480246233, acc: 17.629278273809526\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:20,  7.86it/s]\n",
      "INFO:TRAIN loss: 2.9006256969428508, acc: 16.66735137306456\n",
      "24it [00:01, 14.24it/s]\n",
      "INFO:VAL loss: 2.835880905389785, acc: 17.13169642857143\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:17,  9.21it/s]\n",
      "INFO:TRAIN loss: 2.8789765308239708, acc: 17.48557551855097\n",
      "24it [00:01, 12.87it/s]\n",
      "INFO:VAL loss: 2.8335884014765425, acc: 16.74727182539683\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:29,  5.57it/s]\n",
      "INFO:TRAIN loss: 2.826432037938592, acc: 18.992386064855395\n",
      "24it [00:01, 13.00it/s]\n",
      "INFO:VAL loss: 2.7418682475884752, acc: 19.614955357142854\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:23,  6.95it/s]\n",
      "INFO:TRAIN loss: 2.994967909678358, acc: 14.61117806018112\n",
      "24it [00:01, 14.12it/s]\n",
      "INFO:VAL loss: 3.0153996745745335, acc: 13.32000248015873\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:17,  9.41it/s]\n",
      "INFO:TRAIN loss: 3.010062865684369, acc: 13.771043309962018\n",
      "24it [00:01, 14.04it/s]\n",
      "INFO:VAL loss: 2.997978508472443, acc: 14.589533730158731\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:16, 10.10it/s]\n",
      "INFO:TRAIN loss: 3.0011801836680783, acc: 13.809386868244228\n",
      "24it [00:01, 13.34it/s]\n",
      "INFO:VAL loss: 2.9906995793183646, acc: 15.500992063492065\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:17,  9.39it/s]\n",
      "INFO:TRAIN loss: 2.998190022685044, acc: 14.14010005842828\n",
      "24it [00:01, 13.58it/s]\n",
      "INFO:VAL loss: 2.9882085820039115, acc: 15.142919146825395\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:17,  9.37it/s]\n",
      "INFO:TRAIN loss: 2.989676149344882, acc: 14.500940330119779\n",
      "24it [00:01, 13.79it/s]\n",
      "INFO:VAL loss: 3.0069733758767447, acc: 14.039248511904761\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:16,  9.95it/s]\n",
      "INFO:TRAIN loss: 3.000507913484163, acc: 14.198528337715453\n",
      "24it [00:01, 13.44it/s]\n",
      "INFO:VAL loss: 2.9824104706446337, acc: 15.045262896825399\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:16,  9.97it/s]\n",
      "INFO:TRAIN loss: 2.9909764433199646, acc: 14.399375547765114\n",
      "24it [00:01, 14.31it/s]\n",
      "INFO:VAL loss: 2.9786200920740766, acc: 15.403335813492065\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:15, 10.44it/s]\n",
      "INFO:TRAIN loss: 2.9880819042767497, acc: 14.461683829973708\n",
      "24it [00:01, 14.27it/s]\n",
      "INFO:VAL loss: 2.9746649761994677, acc: 15.761408730158731\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:15, 10.20it/s]\n",
      "INFO:TRAIN loss: 2.9793493133381097, acc: 14.735338153666373\n",
      "24it [00:01, 13.73it/s]\n",
      "INFO:VAL loss: 2.9708690841992698, acc: 15.598648313492065\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:15, 10.21it/s]\n",
      "INFO:TRAIN loss: 2.9807968563828746, acc: 14.629436897458374\n",
      "24it [00:01, 14.20it/s]\n",
      "INFO:VAL loss: 2.970758428176244, acc: 15.989273313492061\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:15, 10.62it/s]\n",
      "INFO:TRAIN loss: 2.9746929780105864, acc: 14.87821355536079\n",
      "24it [00:01, 14.17it/s]\n",
      "INFO:VAL loss: 2.965214778979619, acc: 15.956721230158735\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:15, 10.68it/s]\n",
      "INFO:TRAIN loss: 2.969064057238996, acc: 14.887799444931348\n",
      "24it [00:01, 13.64it/s]\n",
      "INFO:VAL loss: 2.9612111647923793, acc: 15.696304563492061\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:15, 10.61it/s]\n",
      "INFO:TRAIN loss: 2.96244775590721, acc: 15.314828001752849\n",
      "24it [00:01, 14.03it/s]\n",
      "INFO:VAL loss: 2.9549622933069863, acc: 16.0218253968254\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:16, 10.10it/s]\n",
      "INFO:TRAIN loss: 2.957586655587505, acc: 15.506089322231963\n",
      "24it [00:01, 13.79it/s]\n",
      "INFO:VAL loss: 2.951917409896851, acc: 16.382998511904763\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:15, 10.22it/s]\n",
      "INFO:TRAIN loss: 2.9528857096572585, acc: 15.474364592462754\n",
      "24it [00:01, 13.61it/s]\n",
      "INFO:VAL loss: 2.9429167211055756, acc: 16.513206845238095\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:15, 10.30it/s]\n",
      "INFO:TRAIN loss: 2.94384702436763, acc: 15.606284691790828\n",
      "24it [00:01, 14.10it/s]\n",
      "INFO:VAL loss: 2.9366166392962136, acc: 16.871279761904763\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:16, 10.15it/s]\n",
      "INFO:TRAIN loss: 2.939915917402398, acc: 15.885188431200707\n",
      "24it [00:01, 13.47it/s]\n",
      "INFO:VAL loss: 2.924515048662821, acc: 17.291356646825403\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:15, 10.51it/s]\n",
      "INFO:TRAIN loss: 2.918261915628165, acc: 16.29395815074497\n",
      "24it [00:01, 14.16it/s]\n",
      "INFO:VAL loss: 2.9103620549043017, acc: 17.681981646825395\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:15, 10.63it/s]\n",
      "INFO:TRAIN loss: 2.9090785073356398, acc: 16.78671852176454\n",
      "24it [00:01, 14.05it/s]\n",
      "INFO:VAL loss: 2.894047240416209, acc: 17.717633928571427\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:15, 10.58it/s]\n",
      "INFO:TRAIN loss: 2.8967260261254797, acc: 17.015866929593926\n",
      "24it [00:01, 14.16it/s]\n",
      "INFO:VAL loss: 2.8689347902933755, acc: 17.90984623015873\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:17,  9.44it/s]\n",
      "INFO:TRAIN loss: 2.8629906996627543, acc: 16.800184414256506\n",
      "24it [00:01, 14.21it/s]\n",
      "INFO:VAL loss: 2.8432957629362736, acc: 16.67286706349206\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:21,  7.44it/s]\n",
      "INFO:TRAIN loss: 2.8396418109261914, acc: 17.097346990943624\n",
      "24it [00:01, 14.13it/s]\n",
      "INFO:VAL loss: 3.0092131892840066, acc: 16.24968998015873\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:23,  6.82it/s]\n",
      "INFO:TRAIN loss: 2.9284652391094363, acc: 17.117888182880513\n",
      "24it [00:01, 14.30it/s]\n",
      "INFO:VAL loss: 2.8748513460159297, acc: 17.034040178571427\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:30,  5.40it/s]\n",
      "INFO:TRAIN loss: 2.9254114730226486, acc: 14.98845128542215\n",
      "24it [00:01, 14.26it/s]\n",
      "INFO:VAL loss: 2.9501393536726632, acc: 16.187686011904763\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:38,  4.27it/s]\n",
      "INFO:TRAIN loss: 2.9451643674651526, acc: 14.715709903593343\n",
      "24it [00:01, 14.40it/s]\n",
      "INFO:VAL loss: 2.937853535016378, acc: 15.992373511904763\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:36,  4.52it/s]\n",
      "INFO:TRAIN loss: 2.9238125692847317, acc: 15.299992696465093\n",
      "24it [00:01, 14.37it/s]\n",
      "INFO:VAL loss: 2.922115792830785, acc: 16.25279017857143\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:35,  4.56it/s]\n",
      "INFO:TRAIN loss: 2.910186328770925, acc: 16.11000036517675\n",
      "24it [00:01, 14.42it/s]\n",
      "INFO:VAL loss: 2.8740016917387647, acc: 17.261904761904763\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:28,  5.63it/s]\n",
      "INFO:TRAIN loss: 2.886674066262745, acc: 16.800184414256496\n",
      "24it [00:01, 14.44it/s]\n",
      "INFO:VAL loss: 2.860841790835063, acc: 17.457217261904766\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:30,  5.36it/s]\n",
      "INFO:TRAIN loss: 2.8692152763436916, acc: 17.164448217937476\n",
      "24it [00:01, 14.33it/s]\n",
      "INFO:VAL loss: 2.8957977890968323, acc: 15.956721230158731\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:46,  3.54it/s]\n",
      "INFO:TRAIN loss: 2.9618845029842626, acc: 14.035568215016065\n",
      "24it [00:01, 14.41it/s]\n",
      "INFO:VAL loss: 2.947185963392257, acc: 15.533544146825395\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:41,  3.90it/s]\n",
      "INFO:TRAIN loss: 2.935418389326224, acc: 14.79194054922583\n",
      "24it [00:01, 14.40it/s]\n",
      "INFO:VAL loss: 2.9481200575828552, acc: 15.631200396825395\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:45,  3.55it/s]\n",
      "INFO:TRAIN loss: 2.942254266855907, acc: 14.872507668711656\n",
      "24it [00:01, 14.37it/s]\n",
      "INFO:VAL loss: 2.9314933717250824, acc: 16.054377480158728\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:47,  3.44it/s]\n",
      "INFO:TRAIN loss: 2.9229501185973, acc: 15.784080119777979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 14.41it/s]\n",
      "INFO:VAL loss: 2.917867491642634, acc: 16.282242063492063\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:35,  4.58it/s]\n",
      "INFO:TRAIN loss: 2.9097970000073956, acc: 16.282546377446682\n",
      "24it [00:01, 14.35it/s]\n",
      "INFO:VAL loss: 2.8980253040790562, acc: 16.6077628968254\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:26,  6.22it/s]\n",
      "INFO:TRAIN loss: 2.886749928714308, acc: 17.26076358457494\n",
      "24it [00:01, 14.39it/s]\n",
      "INFO:VAL loss: 2.8766492207845054, acc: 16.868179563492063\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:24,  6.63it/s]\n",
      "INFO:TRAIN loss: 2.892200592836719, acc: 16.730116126205075\n",
      "24it [00:01, 14.38it/s]\n",
      "INFO:VAL loss: 2.8839264611403146, acc: 16.0218253968254\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:23,  6.96it/s]\n",
      "INFO:TRAIN loss: 2.8596304325969673, acc: 17.82245106631609\n",
      "24it [00:01, 14.06it/s]\n",
      "INFO:VAL loss: 2.8564190963904057, acc: 17.327008928571427\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:22,  7.17it/s]\n",
      "INFO:TRAIN loss: 2.8278052645958263, acc: 18.589778702892204\n",
      "24it [00:01, 14.33it/s]\n",
      "INFO:VAL loss: 2.797761281331381, acc: 18.466331845238095\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:22,  7.22it/s]\n",
      "INFO:TRAIN loss: 2.834011216836473, acc: 18.935327198364003\n",
      "24it [00:01, 14.38it/s]\n",
      "INFO:VAL loss: 2.8124539355436964, acc: 18.40122767857143\n",
      "INFO:TRAIN: 49|50\n",
      "163it [00:22,  7.11it/s]\n",
      "INFO:TRAIN loss: 2.8075596715775006, acc: 19.371028702892186\n",
      "24it [00:01, 14.21it/s]\n",
      "INFO:VAL loss: 2.7378747264544168, acc: 19.60565476190476\n",
      "47it [00:03, 14.07it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 2.716462084587585, acc: 21.027260638297875\n",
      "INFO:{'epoch_index': 49, 'train_loss': [3.1235298437574905, 2.9903613189978104, 2.929612292833855, 2.9194676642037614, 2.8976120422222866, 2.9799429024655386, 2.967534524531453, 2.9006256969428508, 2.8789765308239708, 2.826432037938592, 2.994967909678358, 3.010062865684369, 3.0011801836680783, 2.998190022685044, 2.989676149344882, 3.000507913484163, 2.9909764433199646, 2.9880819042767497, 2.9793493133381097, 2.9807968563828746, 2.9746929780105864, 2.969064057238996, 2.96244775590721, 2.957586655587505, 2.9528857096572585, 2.94384702436763, 2.939915917402398, 2.918261915628165, 2.9090785073356398, 2.8967260261254797, 2.8629906996627543, 2.8396418109261914, 2.9284652391094363, 2.9254114730226486, 2.9451643674651526, 2.9238125692847317, 2.910186328770925, 2.886674066262745, 2.8692152763436916, 2.9618845029842626, 2.935418389326224, 2.942254266855907, 2.9229501185973, 2.9097970000073956, 2.886749928714308, 2.892200592836719, 2.8596304325969673, 2.8278052645958263, 2.834011216836473, 2.8075596715775006], 'train_acc': [12.018651402278707, 14.854248831434411, 17.250721224072457, 16.833735027753434, 16.608466622845448, 14.691288708735033, 15.855974291557114, 16.66735137306456, 17.48557551855097, 18.992386064855395, 14.61117806018112, 13.771043309962018, 13.809386868244228, 14.14010005842828, 14.500940330119779, 14.198528337715453, 14.399375547765114, 14.461683829973708, 14.735338153666373, 14.629436897458374, 14.87821355536079, 14.887799444931348, 15.314828001752849, 15.506089322231963, 15.474364592462754, 15.606284691790828, 15.885188431200707, 16.29395815074497, 16.78671852176454, 17.015866929593926, 16.800184414256506, 17.097346990943624, 17.117888182880513, 14.98845128542215, 14.715709903593343, 15.299992696465093, 16.11000036517675, 16.800184414256496, 17.164448217937476, 14.035568215016065, 14.79194054922583, 14.872507668711656, 15.784080119777979, 16.282546377446682, 17.26076358457494, 16.730116126205075, 17.82245106631609, 18.589778702892204, 18.935327198364003, 19.371028702892186], 'val_loss': [2.9977557758490243, 2.8983249763647714, 2.8751232524712886, 2.8132684032122293, 2.8374347984790798, 3.0012767215569816, 2.8567942480246233, 2.835880905389785, 2.8335884014765425, 2.7418682475884752, 3.0153996745745335, 2.997978508472443, 2.9906995793183646, 2.9882085820039115, 3.0069733758767447, 2.9824104706446337, 2.9786200920740766, 2.9746649761994677, 2.9708690841992698, 2.970758428176244, 2.965214778979619, 2.9612111647923793, 2.9549622933069863, 2.951917409896851, 2.9429167211055756, 2.9366166392962136, 2.924515048662821, 2.9103620549043017, 2.894047240416209, 2.8689347902933755, 2.8432957629362736, 3.0092131892840066, 2.8748513460159297, 2.9501393536726632, 2.937853535016378, 2.922115792830785, 2.8740016917387647, 2.860841790835063, 2.8957977890968323, 2.947185963392257, 2.9481200575828552, 2.9314933717250824, 2.917867491642634, 2.8980253040790562, 2.8766492207845054, 2.8839264611403146, 2.8564190963904057, 2.797761281331381, 2.8124539355436964, 2.7378747264544168], 'val_acc': [15.299479166666664, 17.681981646825392, 17.951698908730158, 19.218129960317455, 15.376984126984127, 14.101252480158731, 17.629278273809526, 17.13169642857143, 16.74727182539683, 19.614955357142854, 13.32000248015873, 14.589533730158731, 15.500992063492065, 15.142919146825395, 14.039248511904761, 15.045262896825399, 15.403335813492065, 15.761408730158731, 15.598648313492065, 15.989273313492061, 15.956721230158735, 15.696304563492061, 16.0218253968254, 16.382998511904763, 16.513206845238095, 16.871279761904763, 17.291356646825403, 17.681981646825395, 17.717633928571427, 17.90984623015873, 16.67286706349206, 16.24968998015873, 17.034040178571427, 16.187686011904763, 15.992373511904763, 16.25279017857143, 17.261904761904763, 17.457217261904766, 15.956721230158731, 15.533544146825395, 15.631200396825395, 16.054377480158728, 16.282242063492063, 16.6077628968254, 16.868179563492063, 16.0218253968254, 17.327008928571427, 18.466331845238095, 18.40122767857143, 19.60565476190476], 'test_loss': 2.716462084587585, 'test_acc': 21.027260638297875}\n"
     ]
    }
   ],
   "source": [
    "# Model 13\n",
    "args.model_id=13\n",
    "train_dataloader = DataLoader(jobtype_myembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_myembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_myembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "state = make_train_state() \n",
    "# model = RnnModel1(n_features=100, hidden_dim=128, n_outputs=label_nums)\n",
    "model = RnnModel2(embedding_size=100, num_embeddings=128, num_classes=label_nums, rnn_hidden_size=64)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "\n",
    "args.logger.info(args)\n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "#args.logger.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a3685",
   "metadata": {},
   "source": [
    "**acc: 21.02**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4560b",
   "metadata": {},
   "source": [
    "model using rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00089302",
   "metadata": {},
   "source": [
    "**`model 14: text--job_description, embedding--pretrain embedding, model--rnn`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0152fde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=14, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=14, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "163it [00:10, 14.99it/s]\n",
      "INFO:TRAIN loss: 3.140824878142655, acc: 10.556803242769504\n",
      "INFO:TRAIN loss: 3.140824878142655, acc: 10.556803242769504\n",
      "24it [00:01, 23.12it/s]\n",
      "INFO:VAL loss: 3.0244911710421243, acc: 12.239583333333334\n",
      "INFO:VAL loss: 3.0244911710421243, acc: 12.239583333333334\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "163it [00:18,  9.04it/s]\n",
      "INFO:TRAIN loss: 3.0521995743359516, acc: 12.409846990943613\n",
      "INFO:TRAIN loss: 3.0521995743359516, acc: 12.409846990943613\n",
      "24it [00:01, 23.59it/s]\n",
      "INFO:VAL loss: 3.0656271775563555, acc: 10.810391865079366\n",
      "INFO:VAL loss: 3.0656271775563555, acc: 10.810391865079366\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "163it [00:26,  6.08it/s]\n",
      "INFO:TRAIN loss: 3.058838468387815, acc: 12.510498831434411\n",
      "INFO:TRAIN loss: 3.058838468387815, acc: 12.510498831434411\n",
      "24it [00:01, 23.44it/s]\n",
      "INFO:VAL loss: 3.0819583038489027, acc: 9.449404761904763\n",
      "INFO:VAL loss: 3.0819583038489027, acc: 9.449404761904763\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "163it [00:20,  7.85it/s]\n",
      "INFO:TRAIN loss: 3.037799646517981, acc: 11.954973707274323\n",
      "INFO:TRAIN loss: 3.037799646517981, acc: 11.954973707274323\n",
      "24it [00:01, 23.59it/s]\n",
      "INFO:VAL loss: 3.0193445980548863, acc: 16.350446428571427\n",
      "INFO:VAL loss: 3.0193445980548863, acc: 16.350446428571427\n",
      "INFO:TRAIN: 4|50\n",
      "INFO:TRAIN: 4|50\n",
      "163it [00:10, 15.17it/s]\n",
      "INFO:TRAIN loss: 3.024650050087208, acc: 13.819429228746717\n",
      "INFO:TRAIN loss: 3.024650050087208, acc: 13.819429228746717\n",
      "24it [00:01, 23.58it/s]\n",
      "INFO:VAL loss: 3.096359173456827, acc: 11.790054563492065\n",
      "INFO:VAL loss: 3.096359173456827, acc: 11.790054563492065\n",
      "INFO:TRAIN: 5|50\n",
      "INFO:TRAIN: 5|50\n",
      "163it [00:10, 14.95it/s]\n",
      "INFO:TRAIN loss: 3.0253469695342825, acc: 14.035111744084139\n",
      "INFO:TRAIN loss: 3.0253469695342825, acc: 14.035111744084139\n",
      "24it [00:01, 23.46it/s]\n",
      "INFO:VAL loss: 3.034443974494934, acc: 12.734064980158731\n",
      "INFO:VAL loss: 3.034443974494934, acc: 12.734064980158731\n",
      "INFO:TRAIN: 6|50\n",
      "INFO:TRAIN: 6|50\n",
      "163it [00:25,  6.44it/s]\n",
      "INFO:TRAIN loss: 3.0562737163590508, acc: 11.984187846917907\n",
      "INFO:TRAIN loss: 3.0562737163590508, acc: 11.984187846917907\n",
      "24it [00:01, 23.71it/s]\n",
      "INFO:VAL loss: 3.0629146695137024, acc: 10.683283730158731\n",
      "INFO:VAL loss: 3.0629146695137024, acc: 10.683283730158731\n",
      "INFO:TRAIN: 7|50\n",
      "INFO:TRAIN: 7|50\n",
      "163it [00:38,  4.25it/s]\n",
      "INFO:TRAIN loss: 3.053506015999916, acc: 11.328010882267021\n",
      "INFO:TRAIN loss: 3.053506015999916, acc: 11.328010882267021\n",
      "24it [00:01, 23.70it/s]\n",
      "INFO:VAL loss: 3.0568607151508336, acc: 11.103360615079366\n",
      "INFO:VAL loss: 3.0568607151508336, acc: 11.103360615079366\n",
      "INFO:TRAIN: 8|50\n",
      "INFO:TRAIN: 8|50\n",
      "163it [00:34,  4.73it/s]\n",
      "INFO:TRAIN loss: 3.036901955224254, acc: 11.978938431200705\n",
      "INFO:TRAIN loss: 3.036901955224254, acc: 11.978938431200705\n",
      "24it [00:01, 23.73it/s]\n",
      "INFO:VAL loss: 3.039991239706675, acc: 13.28125\n",
      "INFO:VAL loss: 3.039991239706675, acc: 13.28125\n",
      "INFO:TRAIN: 9|50\n",
      "INFO:TRAIN: 9|50\n",
      "163it [00:24,  6.54it/s]\n",
      "INFO:TRAIN loss: 3.0344146848456273, acc: 12.596771837569383\n",
      "INFO:TRAIN loss: 3.0344146848456273, acc: 12.596771837569383\n",
      "24it [00:01, 23.52it/s]\n",
      "INFO:VAL loss: 3.041796286900839, acc: 13.020833333333334\n",
      "INFO:VAL loss: 3.041796286900839, acc: 13.020833333333334\n",
      "INFO:TRAIN: 10|50\n",
      "INFO:TRAIN: 10|50\n",
      "163it [00:20,  7.78it/s]\n",
      "INFO:TRAIN loss: 3.0036824349245403, acc: 13.801170391469475\n",
      "INFO:TRAIN loss: 3.0036824349245403, acc: 13.801170391469475\n",
      "24it [00:01, 23.11it/s]\n",
      "INFO:VAL loss: 3.0013461410999307, acc: 13.902839781746032\n",
      "INFO:VAL loss: 3.0013461410999307, acc: 13.902839781746032\n",
      "INFO:TRAIN: 11|50\n",
      "INFO:TRAIN: 11|50\n",
      "163it [00:12, 12.55it/s]\n",
      "INFO:TRAIN loss: 2.9658720098390163, acc: 15.299992696465086\n",
      "INFO:TRAIN loss: 2.9658720098390163, acc: 15.299992696465086\n",
      "24it [00:01, 23.63it/s]\n",
      "INFO:VAL loss: 2.9832549393177037, acc: 14.823598710317462\n",
      "INFO:VAL loss: 2.9832549393177037, acc: 14.823598710317462\n",
      "INFO:TRAIN: 12|50\n",
      "INFO:TRAIN: 12|50\n",
      "163it [00:29,  5.51it/s]\n",
      "INFO:TRAIN loss: 3.02519263811638, acc: 13.089988679520886\n",
      "INFO:TRAIN loss: 3.02519263811638, acc: 13.089988679520886\n",
      "24it [00:01, 22.74it/s]\n",
      "INFO:VAL loss: 2.9835649331410727, acc: 14.231460813492063\n",
      "INFO:VAL loss: 2.9835649331410727, acc: 14.231460813492063\n",
      "INFO:TRAIN: 13|50\n",
      "INFO:TRAIN: 13|50\n",
      "163it [00:23,  6.93it/s]\n",
      "INFO:TRAIN loss: 2.9609450387077096, acc: 14.907427695004383\n",
      "INFO:TRAIN loss: 2.9609450387077096, acc: 14.907427695004383\n",
      "24it [00:01, 23.55it/s]\n",
      "INFO:VAL loss: 3.0277063846588135, acc: 12.734064980158731\n",
      "INFO:VAL loss: 3.0277063846588135, acc: 12.734064980158731\n",
      "INFO:TRAIN: 14|50\n",
      "INFO:TRAIN: 14|50\n",
      "163it [00:24,  6.67it/s]\n",
      "INFO:TRAIN loss: 2.965149466976798, acc: 14.954900671925207\n",
      "INFO:TRAIN loss: 2.965149466976798, acc: 14.954900671925207\n",
      "24it [00:01, 23.53it/s]\n",
      "INFO:VAL loss: 2.921813448270162, acc: 15.533544146825397\n",
      "INFO:VAL loss: 2.921813448270162, acc: 15.533544146825397\n",
      "INFO:TRAIN: 15|50\n",
      "INFO:TRAIN: 15|50\n",
      "163it [00:18,  8.83it/s]\n",
      "INFO:TRAIN loss: 2.958533038390925, acc: 15.232891469471225\n",
      "INFO:TRAIN loss: 2.958533038390925, acc: 15.232891469471225\n",
      "24it [00:01, 23.42it/s]\n",
      "INFO:VAL loss: 3.0009367763996124, acc: 13.41455853174603\n",
      "INFO:VAL loss: 3.0009367763996124, acc: 13.41455853174603\n",
      "INFO:TRAIN: 16|50\n",
      "INFO:TRAIN: 16|50\n",
      "163it [00:20,  7.82it/s]\n",
      "INFO:TRAIN loss: 2.9917333286964105, acc: 14.048121165644172\n",
      "INFO:TRAIN loss: 2.9917333286964105, acc: 14.048121165644172\n",
      "24it [00:01, 23.43it/s]\n",
      "INFO:VAL loss: 3.016879985729853, acc: 12.476748511904761\n",
      "INFO:VAL loss: 3.016879985729853, acc: 12.476748511904761\n",
      "INFO:TRAIN: 17|50\n",
      "INFO:TRAIN: 17|50\n",
      "163it [00:27,  5.83it/s]\n",
      "INFO:TRAIN loss: 2.985501403457545, acc: 14.211994230207424\n",
      "INFO:TRAIN loss: 2.985501403457545, acc: 14.211994230207424\n",
      "24it [00:01, 23.31it/s]\n",
      "INFO:VAL loss: 2.9730792840321856, acc: 13.740079365079366\n",
      "INFO:VAL loss: 2.9730792840321856, acc: 13.740079365079366\n",
      "INFO:TRAIN: 18|50\n",
      "INFO:TRAIN: 18|50\n",
      "163it [00:12, 12.88it/s]\n",
      "INFO:TRAIN loss: 2.9699878604865493, acc: 14.97407245106632\n",
      "INFO:TRAIN loss: 2.9699878604865493, acc: 14.97407245106632\n",
      "24it [00:01, 23.21it/s]\n",
      "INFO:VAL loss: 2.9635507067044577, acc: 14.068700396825395\n",
      "INFO:VAL loss: 2.9635507067044577, acc: 14.068700396825395\n",
      "INFO:TRAIN: 19|50\n",
      "INFO:TRAIN: 19|50\n",
      "163it [00:23,  6.89it/s]\n",
      "INFO:TRAIN loss: 3.0256836077918314, acc: 12.812910823838738\n",
      "INFO:TRAIN loss: 3.0256836077918314, acc: 12.812910823838738\n",
      "24it [00:01, 23.53it/s]\n",
      "INFO:VAL loss: 3.0787560741106668, acc: 11.298673115079366\n",
      "INFO:VAL loss: 3.0787560741106668, acc: 11.298673115079366\n",
      "INFO:TRAIN: 20|50\n",
      "INFO:TRAIN: 20|50\n",
      "163it [00:10, 15.36it/s]\n",
      "INFO:TRAIN loss: 3.0597598362554077, acc: 11.701860575518554\n",
      "INFO:TRAIN loss: 3.0597598362554077, acc: 11.701860575518554\n",
      "24it [00:01, 23.49it/s]\n",
      "INFO:VAL loss: 3.072244286537171, acc: 11.197916666666668\n",
      "INFO:VAL loss: 3.072244286537171, acc: 11.197916666666668\n",
      "INFO:TRAIN: 21|50\n",
      "INFO:TRAIN: 21|50\n",
      "163it [00:10, 15.42it/s]\n",
      "INFO:TRAIN loss: 3.05324271412715, acc: 11.666940549225828\n",
      "INFO:TRAIN loss: 3.05324271412715, acc: 11.666940549225828\n",
      "24it [00:01, 23.54it/s]\n",
      "INFO:VAL loss: 3.068923006455104, acc: 11.721850198412701\n",
      "INFO:VAL loss: 3.068923006455104, acc: 11.721850198412701\n",
      "INFO:TRAIN: 22|50\n",
      "INFO:TRAIN: 22|50\n",
      "163it [00:10, 15.44it/s]\n",
      "INFO:TRAIN loss: 3.05364118178198, acc: 11.869157172071281\n",
      "INFO:TRAIN loss: 3.05364118178198, acc: 11.869157172071281\n",
      "24it [00:01, 23.60it/s]\n",
      "INFO:VAL loss: 3.0681763092676793, acc: 11.884610615079364\n",
      "INFO:VAL loss: 3.0681763092676793, acc: 11.884610615079364\n",
      "INFO:TRAIN: 23|50\n",
      "INFO:TRAIN: 23|50\n",
      "163it [00:10, 14.91it/s]\n",
      "INFO:TRAIN loss: 3.0510784906843678, acc: 12.01203257376571\n",
      "INFO:TRAIN loss: 3.0510784906843678, acc: 12.01203257376571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 23.34it/s]\n",
      "INFO:VAL loss: 3.063707987467448, acc: 12.210131448412698\n",
      "INFO:VAL loss: 3.063707987467448, acc: 12.210131448412698\n",
      "INFO:TRAIN: 24|50\n",
      "INFO:TRAIN: 24|50\n",
      "163it [00:10, 15.26it/s]\n",
      "INFO:TRAIN loss: 3.0483488524618316, acc: 12.083013803680982\n",
      "INFO:TRAIN loss: 3.0483488524618316, acc: 12.083013803680982\n",
      "24it [00:01, 23.05it/s]\n",
      "INFO:VAL loss: 3.062306294838587, acc: 12.115575396825397\n",
      "INFO:VAL loss: 3.062306294838587, acc: 12.115575396825397\n",
      "INFO:TRAIN: 25|50\n",
      "INFO:TRAIN: 25|50\n",
      "163it [00:10, 15.31it/s]\n",
      "INFO:TRAIN loss: 3.047217078004147, acc: 12.238213920537538\n",
      "INFO:TRAIN loss: 3.047217078004147, acc: 12.238213920537538\n",
      "24it [00:01, 23.40it/s]\n",
      "INFO:VAL loss: 3.0606548090775805, acc: 12.571304563492065\n",
      "INFO:VAL loss: 3.0606548090775805, acc: 12.571304563492065\n",
      "INFO:TRAIN: 26|50\n",
      "INFO:TRAIN: 26|50\n",
      "163it [00:10, 15.36it/s]\n",
      "INFO:TRAIN loss: 3.047485271114514, acc: 11.988067849839329\n",
      "INFO:TRAIN loss: 3.047485271114514, acc: 11.988067849839329\n",
      "24it [00:01, 23.05it/s]\n",
      "INFO:VAL loss: 3.0690868298212686, acc: 12.0148189484127\n",
      "INFO:VAL loss: 3.0690868298212686, acc: 12.0148189484127\n",
      "INFO:TRAIN: 27|50\n",
      "INFO:TRAIN: 27|50\n",
      "163it [00:10, 15.29it/s]\n",
      "INFO:TRAIN loss: 3.050002096620807, acc: 11.844279506281046\n",
      "INFO:TRAIN loss: 3.050002096620807, acc: 11.844279506281046\n",
      "24it [00:01, 23.26it/s]\n",
      "INFO:VAL loss: 3.0675792892773943, acc: 11.790054563492065\n",
      "INFO:VAL loss: 3.0675792892773943, acc: 11.790054563492065\n",
      "INFO:TRAIN: 28|50\n",
      "INFO:TRAIN: 28|50\n",
      "163it [00:10, 15.33it/s]\n",
      "INFO:TRAIN loss: 3.0527248265553104, acc: 11.571538124452237\n",
      "INFO:TRAIN loss: 3.0527248265553104, acc: 11.571538124452237\n",
      "24it [00:01, 23.21it/s]\n",
      "INFO:VAL loss: 3.068392386039098, acc: 11.26612103174603\n",
      "INFO:VAL loss: 3.068392386039098, acc: 11.26612103174603\n",
      "INFO:TRAIN: 29|50\n",
      "INFO:TRAIN: 29|50\n",
      "163it [00:10, 15.18it/s]\n",
      "INFO:TRAIN loss: 3.052124330602542, acc: 11.921423093777381\n",
      "INFO:TRAIN loss: 3.052124330602542, acc: 11.921423093777381\n",
      "24it [00:01, 23.23it/s]\n",
      "INFO:VAL loss: 3.0667994419733677, acc: 11.816406249999998\n",
      "INFO:VAL loss: 3.0667994419733677, acc: 11.816406249999998\n",
      "INFO:TRAIN: 30|50\n",
      "INFO:TRAIN: 30|50\n",
      "163it [00:10, 15.36it/s]\n",
      "INFO:TRAIN loss: 3.0515546506167914, acc: 11.60942521180251\n",
      "INFO:TRAIN loss: 3.0515546506167914, acc: 11.60942521180251\n",
      "24it [00:01, 23.68it/s]\n",
      "INFO:VAL loss: 3.0656986633936563, acc: 11.754402281746032\n",
      "INFO:VAL loss: 3.0656986633936563, acc: 11.754402281746032\n",
      "INFO:TRAIN: 31|50\n",
      "INFO:TRAIN: 31|50\n",
      "163it [00:10, 15.30it/s]\n",
      "INFO:TRAIN loss: 3.0492389845701804, acc: 11.738834721004965\n",
      "INFO:TRAIN loss: 3.0492389845701804, acc: 11.738834721004965\n",
      "24it [00:01, 23.53it/s]\n",
      "INFO:VAL loss: 3.0676192045211788, acc: 11.786954365079366\n",
      "INFO:VAL loss: 3.0676192045211788, acc: 11.786954365079366\n",
      "INFO:TRAIN: 32|50\n",
      "INFO:TRAIN: 32|50\n",
      "163it [00:10, 15.33it/s]\n",
      "INFO:TRAIN loss: 3.0520518045483938, acc: 11.633389935728896\n",
      "INFO:TRAIN loss: 3.0520518045483938, acc: 11.633389935728896\n",
      "24it [00:01, 23.63it/s]\n",
      "INFO:VAL loss: 3.068177024523418, acc: 11.624193948412701\n",
      "INFO:VAL loss: 3.068177024523418, acc: 11.624193948412701\n",
      "INFO:TRAIN: 33|50\n",
      "INFO:TRAIN: 33|50\n",
      "163it [00:10, 15.40it/s]\n",
      "INFO:TRAIN loss: 3.047181209903554, acc: 11.921423093777387\n",
      "INFO:TRAIN loss: 3.047181209903554, acc: 11.921423093777387\n",
      "24it [00:01, 23.57it/s]\n",
      "INFO:VAL loss: 3.063568651676178, acc: 11.754402281746032\n",
      "INFO:VAL loss: 3.063568651676178, acc: 11.754402281746032\n",
      "INFO:TRAIN: 34|50\n",
      "INFO:TRAIN: 34|50\n",
      "163it [00:10, 15.42it/s]\n",
      "INFO:TRAIN loss: 3.045550804196689, acc: 12.12706324861233\n",
      "INFO:TRAIN loss: 3.045550804196689, acc: 12.12706324861233\n",
      "24it [00:01, 23.62it/s]\n",
      "INFO:VAL loss: 3.0670855144659677, acc: 11.754402281746032\n",
      "INFO:VAL loss: 3.0670855144659677, acc: 11.754402281746032\n",
      "INFO:TRAIN: 35|50\n",
      "INFO:TRAIN: 35|50\n",
      "163it [00:10, 15.40it/s]\n",
      "INFO:TRAIN loss: 3.04736535534537, acc: 11.997197268477947\n",
      "INFO:TRAIN loss: 3.04736535534537, acc: 11.997197268477947\n",
      "24it [00:01, 23.51it/s]\n",
      "INFO:VAL loss: 3.0623897413412733, acc: 12.079923115079364\n",
      "INFO:VAL loss: 3.0623897413412733, acc: 12.079923115079364\n",
      "INFO:TRAIN: 36|50\n",
      "INFO:TRAIN: 36|50\n",
      "163it [00:10, 15.43it/s]\n",
      "INFO:TRAIN loss: 3.042139790540825, acc: 12.175905638328945\n",
      "INFO:TRAIN loss: 3.042139790540825, acc: 12.175905638328945\n",
      "24it [00:01, 23.55it/s]\n",
      "INFO:VAL loss: 3.05926584204038, acc: 12.177579365079366\n",
      "INFO:VAL loss: 3.05926584204038, acc: 12.177579365079366\n",
      "INFO:TRAIN: 37|50\n",
      "INFO:TRAIN: 37|50\n",
      "163it [00:10, 15.26it/s]\n",
      "INFO:TRAIN loss: 3.0475835917186154, acc: 11.709164110429448\n",
      "INFO:TRAIN loss: 3.0475835917186154, acc: 11.709164110429448\n",
      "24it [00:01, 21.61it/s]\n",
      "INFO:VAL loss: 3.0645904640356703, acc: 11.786954365079366\n",
      "INFO:VAL loss: 3.0645904640356703, acc: 11.786954365079366\n",
      "INFO:TRAIN: 38|50\n",
      "INFO:TRAIN: 38|50\n",
      "163it [00:11, 14.40it/s]\n",
      "INFO:TRAIN loss: 3.045239724995899, acc: 12.117477359041777\n",
      "INFO:TRAIN loss: 3.045239724995899, acc: 12.117477359041777\n",
      "24it [00:01, 21.24it/s]\n",
      "INFO:VAL loss: 3.0582214891910553, acc: 12.145027281746032\n",
      "INFO:VAL loss: 3.0582214891910553, acc: 12.145027281746032\n",
      "INFO:TRAIN: 39|50\n",
      "INFO:TRAIN: 39|50\n",
      "163it [00:38,  4.25it/s]\n",
      "INFO:TRAIN loss: 3.048700177596391, acc: 11.632476993865028\n",
      "INFO:TRAIN loss: 3.048700177596391, acc: 11.632476993865028\n",
      "24it [00:01, 22.14it/s]\n",
      "INFO:VAL loss: 3.060772945483525, acc: 11.786954365079367\n",
      "INFO:VAL loss: 3.060772945483525, acc: 11.786954365079367\n",
      "INFO:TRAIN: 40|50\n",
      "INFO:TRAIN: 40|50\n",
      "163it [00:41,  3.92it/s]\n",
      "INFO:TRAIN loss: 3.0453873953204953, acc: 11.687025270230798\n",
      "INFO:TRAIN loss: 3.0453873953204953, acc: 11.687025270230798\n",
      "24it [00:01, 23.08it/s]\n",
      "INFO:VAL loss: 3.05952129761378, acc: 11.754402281746032\n",
      "INFO:VAL loss: 3.05952129761378, acc: 11.754402281746032\n",
      "INFO:TRAIN: 41|50\n",
      "INFO:TRAIN: 41|50\n",
      "163it [00:41,  3.95it/s]\n",
      "INFO:TRAIN loss: 3.043199028705527, acc: 11.801599474145478\n",
      "INFO:TRAIN loss: 3.043199028705527, acc: 11.801599474145478\n",
      "24it [00:01, 23.40it/s]\n",
      "INFO:VAL loss: 3.0600022872289023, acc: 11.689298115079364\n",
      "INFO:VAL loss: 3.0600022872289023, acc: 11.689298115079364\n",
      "INFO:TRAIN: 42|50\n",
      "INFO:TRAIN: 42|50\n",
      "163it [00:40,  4.00it/s]\n",
      "INFO:TRAIN loss: 3.0437537175746048, acc: 11.840399503359622\n",
      "INFO:TRAIN loss: 3.0437537175746048, acc: 11.840399503359622\n",
      "24it [00:01, 23.41it/s]\n",
      "INFO:VAL loss: 3.0571386814117436, acc: 11.822606646825397\n",
      "INFO:VAL loss: 3.0571386814117436, acc: 11.822606646825397\n",
      "INFO:TRAIN: 43|50\n",
      "INFO:TRAIN: 43|50\n",
      "163it [00:41,  3.97it/s]\n",
      "INFO:TRAIN loss: 3.0417164103385135, acc: 11.881710122699385\n",
      "INFO:TRAIN loss: 3.0417164103385135, acc: 11.881710122699385\n",
      "24it [00:01, 23.48it/s]\n",
      "INFO:VAL loss: 3.052772551774978, acc: 12.473648313492063\n",
      "INFO:VAL loss: 3.052772551774978, acc: 12.473648313492063\n",
      "INFO:TRAIN: 44|50\n",
      "INFO:TRAIN: 44|50\n",
      "163it [00:40,  4.05it/s]\n",
      "INFO:TRAIN loss: 3.036872666306292, acc: 12.055625547765116\n",
      "INFO:TRAIN loss: 3.036872666306292, acc: 12.055625547765116\n",
      "24it [00:01, 23.44it/s]\n",
      "INFO:VAL loss: 3.0519824723402658, acc: 12.506200396825397\n",
      "INFO:VAL loss: 3.0519824723402658, acc: 12.506200396825397\n",
      "INFO:TRAIN: 45|50\n",
      "INFO:TRAIN: 45|50\n",
      "163it [00:41,  3.97it/s]\n",
      "INFO:TRAIN loss: 3.0348175157067225, acc: 12.128432661408125\n",
      "INFO:TRAIN loss: 3.0348175157067225, acc: 12.128432661408125\n",
      "24it [00:01, 22.92it/s]\n",
      "INFO:VAL loss: 3.0482511818408966, acc: 12.506200396825395\n",
      "INFO:VAL loss: 3.0482511818408966, acc: 12.506200396825395\n",
      "INFO:TRAIN: 46|50\n",
      "INFO:TRAIN: 46|50\n",
      "163it [00:41,  3.92it/s]\n",
      "INFO:TRAIN loss: 3.034782046920683, acc: 12.400717572304993\n",
      "INFO:TRAIN loss: 3.034782046920683, acc: 12.400717572304993\n",
      "24it [00:01, 23.47it/s]\n",
      "INFO:VAL loss: 3.0490393737951917, acc: 12.603856646825397\n",
      "INFO:VAL loss: 3.0490393737951917, acc: 12.603856646825397\n",
      "INFO:TRAIN: 47|50\n",
      "INFO:TRAIN: 47|50\n",
      "163it [00:42,  3.84it/s]\n",
      "INFO:TRAIN loss: 3.0340545484624766, acc: 12.414183464796963\n",
      "INFO:TRAIN loss: 3.0340545484624766, acc: 12.414183464796963\n",
      "24it [00:01, 22.77it/s]\n",
      "INFO:VAL loss: 3.0459203124046317, acc: 12.24578373015873\n",
      "INFO:VAL loss: 3.0459203124046317, acc: 12.24578373015873\n",
      "INFO:TRAIN: 48|50\n",
      "INFO:TRAIN: 48|50\n",
      "163it [00:41,  3.89it/s]\n",
      "INFO:TRAIN loss: 3.0299569902244525, acc: 12.490870581361376\n",
      "INFO:TRAIN loss: 3.0299569902244525, acc: 12.490870581361376\n",
      "24it [00:01, 23.82it/s]\n",
      "INFO:VAL loss: 3.0455097556114197, acc: 12.53875248015873\n",
      "INFO:VAL loss: 3.0455097556114197, acc: 12.53875248015873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAIN: 49|50\n",
      "INFO:TRAIN: 49|50\n",
      "163it [00:41,  3.90it/s]\n",
      "INFO:TRAIN loss: 3.0270122735778253, acc: 12.735310765410453\n",
      "INFO:TRAIN loss: 3.0270122735778253, acc: 12.735310765410453\n",
      "24it [00:01, 21.86it/s]\n",
      "INFO:VAL loss: 3.0409760375817623, acc: 12.408544146825399\n",
      "INFO:VAL loss: 3.0409760375817623, acc: 12.408544146825399\n",
      "47it [00:02, 21.88it/s]\n",
      "INFO:\n",
      "\n",
      "TEST loss: 3.0308414215737205, acc: 13.090848646034818\n",
      "INFO:\n",
      "\n",
      "TEST loss: 3.0308414215737205, acc: 13.090848646034818\n",
      "INFO:{'epoch_index': 49, 'train_loss': [3.140824878142655, 3.0521995743359516, 3.058838468387815, 3.037799646517981, 3.024650050087208, 3.0253469695342825, 3.0562737163590508, 3.053506015999916, 3.036901955224254, 3.0344146848456273, 3.0036824349245403, 2.9658720098390163, 3.02519263811638, 2.9609450387077096, 2.965149466976798, 2.958533038390925, 2.9917333286964105, 2.985501403457545, 2.9699878604865493, 3.0256836077918314, 3.0597598362554077, 3.05324271412715, 3.05364118178198, 3.0510784906843678, 3.0483488524618316, 3.047217078004147, 3.047485271114514, 3.050002096620807, 3.0527248265553104, 3.052124330602542, 3.0515546506167914, 3.0492389845701804, 3.0520518045483938, 3.047181209903554, 3.045550804196689, 3.04736535534537, 3.042139790540825, 3.0475835917186154, 3.045239724995899, 3.048700177596391, 3.0453873953204953, 3.043199028705527, 3.0437537175746048, 3.0417164103385135, 3.036872666306292, 3.0348175157067225, 3.034782046920683, 3.0340545484624766, 3.0299569902244525, 3.0270122735778253], 'train_acc': [10.556803242769504, 12.409846990943613, 12.510498831434411, 11.954973707274323, 13.819429228746717, 14.035111744084139, 11.984187846917907, 11.328010882267021, 11.978938431200705, 12.596771837569383, 13.801170391469475, 15.299992696465086, 13.089988679520886, 14.907427695004383, 14.954900671925207, 15.232891469471225, 14.048121165644172, 14.211994230207424, 14.97407245106632, 12.812910823838738, 11.701860575518554, 11.666940549225828, 11.869157172071281, 12.01203257376571, 12.083013803680982, 12.238213920537538, 11.988067849839329, 11.844279506281046, 11.571538124452237, 11.921423093777381, 11.60942521180251, 11.738834721004965, 11.633389935728896, 11.921423093777387, 12.12706324861233, 11.997197268477947, 12.175905638328945, 11.709164110429448, 12.117477359041777, 11.632476993865028, 11.687025270230798, 11.801599474145478, 11.840399503359622, 11.881710122699385, 12.055625547765116, 12.128432661408125, 12.400717572304993, 12.414183464796963, 12.490870581361376, 12.735310765410453], 'val_loss': [3.0244911710421243, 3.0656271775563555, 3.0819583038489027, 3.0193445980548863, 3.096359173456827, 3.034443974494934, 3.0629146695137024, 3.0568607151508336, 3.039991239706675, 3.041796286900839, 3.0013461410999307, 2.9832549393177037, 2.9835649331410727, 3.0277063846588135, 2.921813448270162, 3.0009367763996124, 3.016879985729853, 2.9730792840321856, 2.9635507067044577, 3.0787560741106668, 3.072244286537171, 3.068923006455104, 3.0681763092676793, 3.063707987467448, 3.062306294838587, 3.0606548090775805, 3.0690868298212686, 3.0675792892773943, 3.068392386039098, 3.0667994419733677, 3.0656986633936563, 3.0676192045211788, 3.068177024523418, 3.063568651676178, 3.0670855144659677, 3.0623897413412733, 3.05926584204038, 3.0645904640356703, 3.0582214891910553, 3.060772945483525, 3.05952129761378, 3.0600022872289023, 3.0571386814117436, 3.052772551774978, 3.0519824723402658, 3.0482511818408966, 3.0490393737951917, 3.0459203124046317, 3.0455097556114197, 3.0409760375817623], 'val_acc': [12.239583333333334, 10.810391865079366, 9.449404761904763, 16.350446428571427, 11.790054563492065, 12.734064980158731, 10.683283730158731, 11.103360615079366, 13.28125, 13.020833333333334, 13.902839781746032, 14.823598710317462, 14.231460813492063, 12.734064980158731, 15.533544146825397, 13.41455853174603, 12.476748511904761, 13.740079365079366, 14.068700396825395, 11.298673115079366, 11.197916666666668, 11.721850198412701, 11.884610615079364, 12.210131448412698, 12.115575396825397, 12.571304563492065, 12.0148189484127, 11.790054563492065, 11.26612103174603, 11.816406249999998, 11.754402281746032, 11.786954365079366, 11.624193948412701, 11.754402281746032, 11.754402281746032, 12.079923115079364, 12.177579365079366, 11.786954365079366, 12.145027281746032, 11.786954365079367, 11.754402281746032, 11.689298115079364, 11.822606646825397, 12.473648313492063, 12.506200396825397, 12.506200396825395, 12.603856646825397, 12.24578373015873, 12.53875248015873, 12.408544146825399], 'test_loss': 3.0308414215737205, 'test_acc': 13.090848646034818}\n",
      "INFO:{'epoch_index': 49, 'train_loss': [3.140824878142655, 3.0521995743359516, 3.058838468387815, 3.037799646517981, 3.024650050087208, 3.0253469695342825, 3.0562737163590508, 3.053506015999916, 3.036901955224254, 3.0344146848456273, 3.0036824349245403, 2.9658720098390163, 3.02519263811638, 2.9609450387077096, 2.965149466976798, 2.958533038390925, 2.9917333286964105, 2.985501403457545, 2.9699878604865493, 3.0256836077918314, 3.0597598362554077, 3.05324271412715, 3.05364118178198, 3.0510784906843678, 3.0483488524618316, 3.047217078004147, 3.047485271114514, 3.050002096620807, 3.0527248265553104, 3.052124330602542, 3.0515546506167914, 3.0492389845701804, 3.0520518045483938, 3.047181209903554, 3.045550804196689, 3.04736535534537, 3.042139790540825, 3.0475835917186154, 3.045239724995899, 3.048700177596391, 3.0453873953204953, 3.043199028705527, 3.0437537175746048, 3.0417164103385135, 3.036872666306292, 3.0348175157067225, 3.034782046920683, 3.0340545484624766, 3.0299569902244525, 3.0270122735778253], 'train_acc': [10.556803242769504, 12.409846990943613, 12.510498831434411, 11.954973707274323, 13.819429228746717, 14.035111744084139, 11.984187846917907, 11.328010882267021, 11.978938431200705, 12.596771837569383, 13.801170391469475, 15.299992696465086, 13.089988679520886, 14.907427695004383, 14.954900671925207, 15.232891469471225, 14.048121165644172, 14.211994230207424, 14.97407245106632, 12.812910823838738, 11.701860575518554, 11.666940549225828, 11.869157172071281, 12.01203257376571, 12.083013803680982, 12.238213920537538, 11.988067849839329, 11.844279506281046, 11.571538124452237, 11.921423093777381, 11.60942521180251, 11.738834721004965, 11.633389935728896, 11.921423093777387, 12.12706324861233, 11.997197268477947, 12.175905638328945, 11.709164110429448, 12.117477359041777, 11.632476993865028, 11.687025270230798, 11.801599474145478, 11.840399503359622, 11.881710122699385, 12.055625547765116, 12.128432661408125, 12.400717572304993, 12.414183464796963, 12.490870581361376, 12.735310765410453], 'val_loss': [3.0244911710421243, 3.0656271775563555, 3.0819583038489027, 3.0193445980548863, 3.096359173456827, 3.034443974494934, 3.0629146695137024, 3.0568607151508336, 3.039991239706675, 3.041796286900839, 3.0013461410999307, 2.9832549393177037, 2.9835649331410727, 3.0277063846588135, 2.921813448270162, 3.0009367763996124, 3.016879985729853, 2.9730792840321856, 2.9635507067044577, 3.0787560741106668, 3.072244286537171, 3.068923006455104, 3.0681763092676793, 3.063707987467448, 3.062306294838587, 3.0606548090775805, 3.0690868298212686, 3.0675792892773943, 3.068392386039098, 3.0667994419733677, 3.0656986633936563, 3.0676192045211788, 3.068177024523418, 3.063568651676178, 3.0670855144659677, 3.0623897413412733, 3.05926584204038, 3.0645904640356703, 3.0582214891910553, 3.060772945483525, 3.05952129761378, 3.0600022872289023, 3.0571386814117436, 3.052772551774978, 3.0519824723402658, 3.0482511818408966, 3.0490393737951917, 3.0459203124046317, 3.0455097556114197, 3.0409760375817623], 'val_acc': [12.239583333333334, 10.810391865079366, 9.449404761904763, 16.350446428571427, 11.790054563492065, 12.734064980158731, 10.683283730158731, 11.103360615079366, 13.28125, 13.020833333333334, 13.902839781746032, 14.823598710317462, 14.231460813492063, 12.734064980158731, 15.533544146825397, 13.41455853174603, 12.476748511904761, 13.740079365079366, 14.068700396825395, 11.298673115079366, 11.197916666666668, 11.721850198412701, 11.884610615079364, 12.210131448412698, 12.115575396825397, 12.571304563492065, 12.0148189484127, 11.790054563492065, 11.26612103174603, 11.816406249999998, 11.754402281746032, 11.786954365079366, 11.624193948412701, 11.754402281746032, 11.754402281746032, 12.079923115079364, 12.177579365079366, 11.786954365079366, 12.145027281746032, 11.786954365079367, 11.754402281746032, 11.689298115079364, 11.822606646825397, 12.473648313492063, 12.506200396825397, 12.506200396825395, 12.603856646825397, 12.24578373015873, 12.53875248015873, 12.408544146825399], 'test_loss': 3.0308414215737205, 'test_acc': 13.090848646034818}\n"
     ]
    }
   ],
   "source": [
    "# Model 14\n",
    "args.model_id=14\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_prainembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_prainembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_prainembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# model = RnnModel1(n_features=100, hidden_dim=128, n_outputs=label_nums)\n",
    "model = RnnModel2(embedding_size=100, num_embeddings=128, num_classes=label_nums, rnn_hidden_size=64)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "args.logger.info(args)\n",
    "\n",
    "# Train and test\n",
    "state = make_train_state() \n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "#args.logger.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc2f9d",
   "metadata": {},
   "source": [
    "**acc: 13.09**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450b2ac",
   "metadata": {},
   "source": [
    "Still my embedding has higher acc than pretrain embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d0597",
   "metadata": {},
   "source": [
    "**`model 15: text--job_description, embedding--myembedding, model--LSTM`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ab4f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=15, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=15, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:Namespace(batch_size=128, learning_rate=0.001, num_epochs=50, seed=1234, device=device(type='cpu'), loss_func=CrossEntropyLoss(), optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), model_id=15, logger=<RootLogger root (DEBUG)>)\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "INFO:TRAIN: 0|50\n",
      "163it [09:58,  3.67s/it]\n",
      "INFO:TRAIN loss: 2.6140617570994094, acc: 25.880760663160974\n",
      "INFO:TRAIN loss: 2.6140617570994094, acc: 25.880760663160974\n",
      "INFO:TRAIN loss: 2.6140617570994094, acc: 25.880760663160974\n",
      "24it [00:08,  2.85it/s]\n",
      "INFO:VAL loss: 2.086859032511711, acc: 37.72011408730159\n",
      "INFO:VAL loss: 2.086859032511711, acc: 37.72011408730159\n",
      "INFO:VAL loss: 2.086859032511711, acc: 37.72011408730159\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "INFO:TRAIN: 1|50\n",
      "163it [09:11,  3.38s/it]\n",
      "INFO:TRAIN loss: 1.8459953779091862, acc: 45.159810473269054\n",
      "INFO:TRAIN loss: 1.8459953779091862, acc: 45.159810473269054\n",
      "INFO:TRAIN loss: 1.8459953779091862, acc: 45.159810473269054\n",
      "24it [00:08,  2.78it/s]\n",
      "INFO:VAL loss: 1.7014606197675068, acc: 51.209077380952394\n",
      "INFO:VAL loss: 1.7014606197675068, acc: 51.209077380952394\n",
      "INFO:VAL loss: 1.7014606197675068, acc: 51.209077380952394\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "INFO:TRAIN: 2|50\n",
      "163it [10:45,  3.96s/it]\n",
      "INFO:TRAIN loss: 1.457127525762547, acc: 58.1295190622261\n",
      "INFO:TRAIN loss: 1.457127525762547, acc: 58.1295190622261\n",
      "INFO:TRAIN loss: 1.457127525762547, acc: 58.1295190622261\n",
      "24it [00:08,  2.68it/s]\n",
      "INFO:VAL loss: 1.3671838094790776, acc: 61.99311755952381\n",
      "INFO:VAL loss: 1.3671838094790776, acc: 61.99311755952381\n",
      "INFO:VAL loss: 1.3671838094790776, acc: 61.99311755952381\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "INFO:TRAIN: 3|50\n",
      "109it [06:33,  3.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Train and test\u001b[39;00m\n\u001b[1;32m     14\u001b[0m state \u001b[38;5;241m=\u001b[39m make_train_state() \n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain_engin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m test_engine(args, model, test_dataloader, state)\n\u001b[1;32m     17\u001b[0m args\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(state)\n",
      "File \u001b[0;32m~/OneDrive - The University of Western Australia/2022 sem1/CITS4012 NLP/project2/utils.py:139\u001b[0m, in \u001b[0;36mtrain_engin\u001b[0;34m(args, model, train_dataloader, val_dataloader, train_state)\u001b[0m\n\u001b[1;32m    136\u001b[0m loss_batch \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    138\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (loss_batch\u001b[38;5;241m-\u001b[39mrunning_loss) \u001b[38;5;241m/\u001b[39m (batch_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m--> 139\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    142\u001b[0m acc_batch \u001b[38;5;241m=\u001b[39m compute_accuracy(y_pred, labels) \n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 15\n",
    "args.model_id=15\n",
    "train_dataloader = DataLoader(jobtype_myembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_myembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_myembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# build model\n",
    "model = LstmModel(n_features=100, hidden_dim=128, n_outputs=label_nums)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "args.logger.info(args)\n",
    "\n",
    "# Train and test\n",
    "state = make_train_state() \n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "#args.logger.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e40480",
   "metadata": {},
   "source": [
    "**acc: 70**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272cff1",
   "metadata": {},
   "source": [
    "model using rnn on my embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d2fb4",
   "metadata": {},
   "source": [
    "**`model 16: text--job_description, embedding--pretrain embedding, model--LSTM`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 16\n",
    "args.model_id=16\n",
    "train_dataloader = DataLoader(jobtype_prainembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_prainembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_prainembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# build model\n",
    "model = LstmModel(n_features=100, hidden_dim=128, n_outputs=label_nums)\n",
    "args.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "args.logger = get_logger(\"./log\", \"M\"+str(args.model_id)+\"_\"+model.__class__.__name__+\"_\"+train_dataloader.dataset.__class__.__name__)\n",
    "args.logger.info(args)\n",
    "\n",
    "# Train and test\n",
    "state = make_train_state() \n",
    "train_engin(args, model, train_dataloader, val_dataloader, state)\n",
    "test_engine(args, model, test_dataloader, state)\n",
    "args.logger.info(state)\n",
    "#args.logger.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ddb0a",
   "metadata": {},
   "source": [
    "**acc:65**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a7480",
   "metadata": {},
   "source": [
    "model using rnn on pretain embedding, comparing to my embedding, which acc is 70,and now the pretain embedding is 65, we can draw a conclusion that my embedding is having higher acc than pretrain embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f6533",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0310116",
   "metadata": {},
   "source": [
    "   **In this project, we completed two tasks,`1 binary document classification` and `2 multi-class document classification`. The binary document classification uses the `job_description` text field to classify the `job type` as full time or part time. Using the job_type column, the jobs are classified into two categories (full time or other). Multi-category document classification Use the `job_description text` field to predict the job `category`. We tried multiple models, from model1 to model6, for the same text `10word`, we took three different embedding methods, namely `onehot`, `my embedding` and `pretrain embedding` used on two different models `feed_forward` and `conv1d`. And in models 10 to 16, we took the above three different embedding methods for the text job_description and ran them on different models, namely `conv1d`, `rnn` and `lstm`. When running on `lstm`, since our own computer does not carry gpu, we look for gpu for more efficient computing. The detailed data are contained in log.zip.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77692e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
