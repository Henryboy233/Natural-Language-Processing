{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8df8807",
   "metadata": {},
   "source": [
    "# CITS 4012 - Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3bc00",
   "metadata": {},
   "source": [
    "### Henry Liu ( 22672083 ) <br> Harry Huang（ 22642989 ）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64618817",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009639a3",
   "metadata": {},
   "source": [
    "This project is to try out different neural language models on one NLP downsteam task: Document Classification. The dataset **`(seek_australia.csv)`** we use in this project contains job descriptions in natural language, alongside structured information about city, job categories, and salary scale. In this project, we attempt to unlock the information from text narratives in this dataset through document classifications. We have two tasks to do: **`1. Binary Document Classification.` 2. `Multi-class Document Classification`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b7995c",
   "metadata": {},
   "source": [
    "## Setup Libraries and load data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf541f33",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414ea3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6848ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0884a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/liugensheng/OneDrive - The University of Western Australia/2022 sem1/CITS4012 NLP/project2',\n",
       " '/Users/liugensheng/miniconda3/lib/python39.zip',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc0378",
   "metadata": {},
   "source": [
    "### Take a quick look at the data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e3193",
   "metadata": {},
   "source": [
    "**After loading the data, try to use some functions(*i.e. head(), describe()..*) to take a glance at the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5cea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"seek_australia.csv\")\n",
    "data = pd.read_csv(\"dataset/seek_australia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e10029b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ddc7894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category',\n",
       " 'city',\n",
       " 'company_name',\n",
       " 'geo',\n",
       " 'job_board',\n",
       " 'job_description',\n",
       " 'job_title',\n",
       " 'job_type',\n",
       " 'post_date',\n",
       " 'salary_offered',\n",
       " 'state',\n",
       " 'url']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd11e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data)) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4c3650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>company_name</th>\n",
       "      <th>geo</th>\n",
       "      <th>job_board</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "      <th>post_date</th>\n",
       "      <th>salary_offered</th>\n",
       "      <th>state</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail &amp; Consumer Products</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Frontline Executive Retail Sydney</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>Have you had 10 years experience in fresh pro...</td>\n",
       "      <td>Store Manager - Fresh Produce</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:13:45Z</td>\n",
       "      <td>$100k Base + Super + Benefits</td>\n",
       "      <td>North Shore &amp; Northern Beaches</td>\n",
       "      <td>https://www.seek.com.au/job/35989382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Government &amp; Defence</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Powerlink</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>The Opportunity: The Client Solution Analyst ...</td>\n",
       "      <td>Client Solution Analyst</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:04:40Z</td>\n",
       "      <td>Excellent remuneration packages</td>\n",
       "      <td>Northern Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35989272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Richard Jay Laundry</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>An innovative business development role for a...</td>\n",
       "      <td>Service Technician / Installer - NSW</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:04:31Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parramatta &amp; Western Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35989270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Adaptalift Hyster</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>About the role: We are seeking an Automotive W...</td>\n",
       "      <td>Workshop Technician I Material Handling Equipment</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-16T03:15:17Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside &amp; South Eastern Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35993203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Bakers Delight G&amp;M</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>Â Early starts and weekend shifts. No experie...</td>\n",
       "      <td>APPRENTICESHIP JUNIOR BAKER</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-16T01:26:50Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.seek.com.au/job/35991578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category       city                       company_name  \\\n",
       "0  Retail & Consumer Products     Sydney  Frontline Executive Retail Sydney   \n",
       "1        Government & Defence   Brisbane                          Powerlink   \n",
       "2           Trades & Services     Sydney                Richard Jay Laundry   \n",
       "3           Trades & Services  Melbourne                  Adaptalift Hyster   \n",
       "4           Trades & Services   Adelaide                 Bakers Delight G&M   \n",
       "\n",
       "  geo job_board                                    job_description  \\\n",
       "0  AU      seek   Have you had 10 years experience in fresh pro...   \n",
       "1  AU      seek   The Opportunity: The Client Solution Analyst ...   \n",
       "2  AU      seek   An innovative business development role for a...   \n",
       "3  AU      seek  About the role: We are seeking an Automotive W...   \n",
       "4  AU      seek   Â Early starts and weekend shifts. No experie...   \n",
       "\n",
       "                                           job_title   job_type  \\\n",
       "0                      Store Manager - Fresh Produce  Full Time   \n",
       "1                            Client Solution Analyst  Full Time   \n",
       "2               Service Technician / Installer - NSW  Full Time   \n",
       "3  Workshop Technician I Material Handling Equipment  Full Time   \n",
       "4                        APPRENTICESHIP JUNIOR BAKER  Full Time   \n",
       "\n",
       "              post_date                   salary_offered  \\\n",
       "0  2018-04-15T23:13:45Z    $100k Base + Super + Benefits   \n",
       "1  2018-04-15T23:04:40Z  Excellent remuneration packages   \n",
       "2  2018-04-15T23:04:31Z                              NaN   \n",
       "3  2018-04-16T03:15:17Z                              NaN   \n",
       "4  2018-04-16T01:26:50Z                              NaN   \n",
       "\n",
       "                             state                                   url  \n",
       "0   North Shore & Northern Beaches  https://www.seek.com.au/job/35989382  \n",
       "1                 Northern Suburbs  https://www.seek.com.au/job/35989272  \n",
       "2     Parramatta & Western Suburbs  https://www.seek.com.au/job/35989270  \n",
       "3  Bayside & South Eastern Suburbs  https://www.seek.com.au/job/35993203  \n",
       "4                              NaN  https://www.seek.com.au/job/35991578  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b418cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>company_name</th>\n",
       "      <th>geo</th>\n",
       "      <th>job_board</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "      <th>post_date</th>\n",
       "      <th>salary_offered</th>\n",
       "      <th>state</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>29655</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>8952</td>\n",
       "      <td>19180</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>9054</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26850</td>\n",
       "      <td>20979</td>\n",
       "      <td>4</td>\n",
       "      <td>24747</td>\n",
       "      <td>5373</td>\n",
       "      <td>19</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Private Advertiser</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>Today we have around 250 people who work to h...</td>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-16T09:29:00Z</td>\n",
       "      <td>$100,502 - $114,624</td>\n",
       "      <td>CBD &amp; Inner Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35989382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3346</td>\n",
       "      <td>9412</td>\n",
       "      <td>1491</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>101</td>\n",
       "      <td>122</td>\n",
       "      <td>20203</td>\n",
       "      <td>14</td>\n",
       "      <td>130</td>\n",
       "      <td>4690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category    city        company_name    geo job_board  \\\n",
       "count               30000   30000               30000  30000     30000   \n",
       "unique                 30      65                9054      1         1   \n",
       "top     Trades & Services  Sydney  Private Advertiser     AU      seek   \n",
       "freq                 3346    9412                1491  30000     30000   \n",
       "\n",
       "                                          job_description  \\\n",
       "count                                               29655   \n",
       "unique                                              26850   \n",
       "top      Today we have around 250 people who work to h...   \n",
       "freq                                                  101   \n",
       "\n",
       "                           job_title   job_type             post_date  \\\n",
       "count                          30000      30000                 30000   \n",
       "unique                         20979          4                 24747   \n",
       "top     Business Development Manager  Full Time  2018-04-16T09:29:00Z   \n",
       "freq                             122      20203                    14   \n",
       "\n",
       "             salary_offered                state  \\\n",
       "count                  8952                19180   \n",
       "unique                 5373                   19   \n",
       "top     $100,502 - $114,624  CBD & Inner Suburbs   \n",
       "freq                    130                 4690   \n",
       "\n",
       "                                         url  \n",
       "count                                  30000  \n",
       "unique                                 30000  \n",
       "top     https://www.seek.com.au/job/35989382  \n",
       "freq                                       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babdc9f0",
   "metadata": {},
   "source": [
    "**From *`describe()`* we can find that all data *`geo`* is *`AU`* and all *`job_board`* is *`seek`*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97dc33e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   category         30000 non-null  object\n",
      " 1   city             30000 non-null  object\n",
      " 2   company_name     30000 non-null  object\n",
      " 3   geo              30000 non-null  object\n",
      " 4   job_board        30000 non-null  object\n",
      " 5   job_description  29655 non-null  object\n",
      " 6   job_title        30000 non-null  object\n",
      " 7   job_type         30000 non-null  object\n",
      " 8   post_date        30000 non-null  object\n",
      " 9   salary_offered   8952 non-null   object\n",
      " 10  state            19180 non-null  object\n",
      " 11  url              30000 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5320f3f2",
   "metadata": {},
   "source": [
    "**Create two different functions(*`lexical_diversity()` and `tf()`*) to determine the weight**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e4cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c46a038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(text, token):\n",
    "    count = text.count(token) \n",
    "    total = len(text)\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e71bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95cdd5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Have you had 10 years experience in fresh pro...\n",
       "1         The Opportunity: The Client Solution Analyst ...\n",
       "2         An innovative business development role for a...\n",
       "3        About the role: We are seeking an Automotive W...\n",
       "4         Â Early starts and weekend shifts. No experie...\n",
       "                               ...                        \n",
       "29995     Hotel snapshot The Radisson Blu Plaza Sydney ...\n",
       "29996     The Organisation Airservices is a government ...\n",
       "29997    ABOUT THE COMPANY AND ROLE Our client is one o...\n",
       "29998     Long term contract for 12 months with possibl...\n",
       "29999     Customer Service Representative - (West Wyalo...\n",
       "Name: job_description, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0433fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "fw = open(\"job_description.txt\", 'w') #Export the address of the file to be saved\n",
    "fw.write(\"job_description\\n\")\n",
    "for line in data.job_description:    #Read the file\n",
    "        fw.write(str(line))   # Writing a string to a file\n",
    "        # line.rstrip(\"\\n\")To remove end-of-line newlines\n",
    "        fw.write(\"\\n\")    # line feed\n",
    "'''\n",
    "delimiter=\"\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7810530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_job = pd.read_csv(\"job_description.txt\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9f269",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467aefa",
   "metadata": {},
   "source": [
    "**Use gensim to train the word embeddings and TSNE to visualise some examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "857758e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# All Import Statements Defined Here # ----------------\n",
    "import sys\n",
    "assert sys.version_info[0]==3 \n",
    "assert sys.version_info[1] >= 5\n",
    "from gensim.models import KeyedVectors \n",
    "from gensim.test.utils import datapath \n",
    "import pprint\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [10, 5] \n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.decomposition import PCA\n",
    "START_TOKEN = '<START>' \n",
    "END_TOKEN = '<END>'\n",
    "np.random.seed(1212) \n",
    "random.seed(1212)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca0ca8",
   "metadata": {},
   "source": [
    "**Find distinct_words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9367c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Determine a list of distinct words for the corpus.\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "Return:\n",
    "corpus_words (list of strings): list of distinct words across the corpus,␣\n",
    "↪sorted (using python 'sorted' function)\n",
    "num_corpus_words (integer): number of distinct words across the corpus\n",
    "\"\"\"\n",
    "def distinct_words(corpus):\n",
    "\n",
    "    corpus_words = [] \n",
    "    num_corpus_words = -1\n",
    "# ------------------\n",
    "# Write your implementation here.\n",
    "    corpus_words = sorted(list(set([y for x in corpus for y in x])))\n",
    "    corpus_words = [y for x in corpus for y in x] \n",
    "    corpus_words = list(set(corpus_words)) # unique words \n",
    "    corpus_words = sorted(corpus_words) # sorts\n",
    "    num_corpus_words = len(corpus_words)\n",
    "    return corpus_words, num_corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "465c1807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Run this sanity check\n",
    "# Note that this not an exhaustive check for correctness. \n",
    "# Very simple tokenization using the Python string split \n",
    "# with space - string.split(\" \").\n",
    "# ---------------------\n",
    "# Define toy corpus\n",
    "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
    "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
    "# Correct answers\n",
    "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN])\n",
    "ans_num_corpus_words = len(ans_test_corpus_words)\n",
    "# Test correct number of words\n",
    "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. ↪ Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words)\n",
    "# Test correct words\n",
    "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours: {}\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
    "# Print Success\n",
    "print (\"-\" * 80) \n",
    "print(\"Passed All Tests!\") \n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f30a5",
   "metadata": {},
   "source": [
    "**Visualise the embeddings using plot_embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0d9add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
    "NOTE: do not plot all the words listed in M_reduced / word2Ind. Include a label next to each point.\n",
    "Params:\n",
    "M_reduced (numpy matrix of shape (number of unique words in the corpus , 2)): matrix of 2-dimensioal word embeddings\n",
    "word2Ind (dict): dictionary that maps word to indices for matrix M words (list of strings): words whose embeddings we want to visualize\n",
    "\"\"\"\n",
    "def plot_embeddings(M_reduced, word2Ind, words):\n",
    "\n",
    "# ------------------\n",
    "    import matplotlib.pyplot as plt \n",
    "    x_coords = M_reduced[:,0] \n",
    "    y_coords = M_reduced[:,1]\n",
    "    \n",
    "    for word in words:\n",
    "        i = word2Ind[word]\n",
    "        x = x_coords[i]\n",
    "        y = y_coords[i]\n",
    "        plt.scatter(x, y, color='r', marker='x') \n",
    "        plt.annotate(word, (x, y))\n",
    "    plt.show()\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d22c22d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7186f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'city', 'company_name', 'geo', 'job_board',\n",
       "       'job_description', 'job_title', 'job_type', 'post_date',\n",
       "       'salary_offered', 'state', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8234bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jot_category_map: {'Trades & Services': 0, 'Information & Communication Technology': 1, 'Healthcare & Medical': 2, 'Manufacturing, Transport & Logistics': 3, 'Administration & Office Support': 4, 'Accounting': 5, 'Hospitality & Tourism': 6, 'Sales': 7, 'Government & Defence': 8, 'Construction': 9, 'Education & Training': 10, 'Retail & Consumer Products': 11, 'Community Services & Development': 12, 'Mining, Resources & Energy': 13, 'Engineering': 14, 'Call Centre & Customer Service': 15, 'Banking & Financial Services': 16, 'Marketing & Communications': 17, 'Human Resources & Recruitment': 18, 'Real Estate & Property': 19, 'Legal': 20, 'Design & Architecture': 21, 'Insurance & Superannuation': 22, 'Advertising, Arts & Media': 23, 'Consulting & Strategy': 24, 'Science & Technology': 25, 'Sport & Recreation': 26, 'Farming, Animals & Conservation': 27, 'CEO & General Management': 28, 'Self Employment': 29}\n",
      "--------------------------------------------------------------------------------\n",
      "job_type_map: {'Full Time': 0, 'Contract/Temp': 1, 'Casual/Vacation': 1, 'Part Time': 1}\n"
     ]
    }
   ],
   "source": [
    "values = data['category'].value_counts()\n",
    "jot_category_map = {}\n",
    "for i, t in enumerate(values.keys()):\n",
    "    jot_category_map[t] = i\n",
    "print(\"jot_category_map:\", jot_category_map)\n",
    "print(80*'-')\n",
    "values = data['job_type'].value_counts()\n",
    "job_type_map = {}\n",
    "for t in values.keys():\n",
    "    if t == \"Full Time\":\n",
    "        job_type_map[t] = 0\n",
    "    else:\n",
    "        job_type_map[t] = 1\n",
    "print(\"job_type_map:\", job_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcaca636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before process\n",
      "  Have you had 10 years experience in fresh produce that wants to manage their own store for a family owned Australian company that is passionate about food. We are looking for: Must have 10+ years in the fresh food business and have the passion for the role. Current 2IC looking to progress with training into Store manager role. Excellent customer service and communication skills Be hands on and have a can do attitude Be into the fresh food business and have the passion for the role Hardworking, ambitious and competitive people who are passionate about good food. Are able to maximise the financial return in their market, ensuring it meets sales, margin and wages budgets. Have exceptional merchandising capabilities and customer service skills helping us to create unique shopping experiences for our customers. Have a wealth of knowledge of fresh food retailing and a willingness to share this knowledge. Can lead, manage and motivate a teams. Must be able to work weekend and use to early starts which is what fresh produce is all about Whats in it for you: Good salary package $100 K + super + benefits Fun and challenging work environment Great career opportunities Exceptional products and brand reputation Amazing teams Strong expanding business If this is you apply now, interviewing now To apply online, please click on the apply button. Alternatively, for a confidential discussion, please contact Sebastian Waddell on , quoting Ref No. 147061 or otherwise please check out our website for other available positions. www.frontlineretail.com.au \n",
      "\n",
      "after process:\n",
      " year experi fresh produc want manag store famili own australian compani passion food look year fresh food busi passion role current ic look progress train store manag role excel custom servic commun skill hand attitud fresh food busi passion role hardwork ambiti competit peopl passion good food abl maximis financi return market ensur meet sale margin wage budget except merchandis capabl custom servic skill help creat uniqu shop experi custom wealth knowledg fresh food retail willing share knowledg lead manag motiv team abl work weekend use earli start fresh produc what good salari packag k super benefit fun challeng work environ great career opportun except product brand reput amaz team strong expand busi appli interview appli onlin click appli button altern confidenti discus contact sebastian waddel quot ref check websit avail posit wwwfrontlineretailcomau\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn import feature_extraction \n",
    "stop_words = feature_extraction.text.ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess(text):\n",
    "  text = text.lower() #lowercase\n",
    "  text = re.sub(r'[^\\w\\s]', '', text) #remove punctuations\n",
    "  text = re.sub(r'\\d+', '', text) #remove numbers\n",
    "  text = re.sub(r'_', '', text) #remove numbers\n",
    "  text = \" \".join(text.split()) #stripWhitespace\n",
    "  text = text.split()\n",
    "  text = [x for x in text if x not in stop_words] #remove stopwords\n",
    "  text = [x for x in text if x not in [\"user\"]] #remove task specific stopwords\n",
    "  text = \" \".join(text)\n",
    "  \n",
    "  # extract the word stemmer, [\"creates\", \"cats\"] -> [\"creat\", \"cats\"]\n",
    "  # these words could not in dictionary.\n",
    "  stemmer_ps = PorterStemmer()  \n",
    "  text = [stemmer_ps.stem(word) for word in text.split()] #stemming\n",
    "  text = \" \".join(text)\n",
    "\n",
    "  # extract the word lemmatizer, [\"creates\", \"cats\"] -> [\"create\", \"cats\"]\n",
    "  # these words are all in dictionary.\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  text = [lemmatizer.lemmatize(word) for word in text.split()]  #lemmatization\n",
    "  text = \" \".join(text)\n",
    "  return(text)\n",
    "\n",
    "print(\"before process\\n\", data['job_description'][0])\n",
    "print()\n",
    "print(\"after process:\\n\", preprocess(data['job_description'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfc1b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[['job_description','job_type','category']].copy()\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# generate bi and mutli label for bi classific and multi classific respectively\n",
    "df['job_type']=df['job_type'].apply(lambda x: job_type_map[x]) \n",
    "df['category']=df['category'].apply(lambda x: jot_category_map[x]) \n",
    "\n",
    "# clean data and to tokenzier\n",
    "df['job_description']=df['job_description'].apply(lambda x:preprocess(x))\n",
    "\n",
    "# save\n",
    "df.to_csv(\"./dataset/job.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6825d",
   "metadata": {},
   "source": [
    "### Train and visualise my embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b11835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from utils import display_closestwords_tsnescatterplot, visual_wv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(\"./dataset/job.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(lambda x:x.split())\n",
    "\n",
    "my_embedding = Word2Vec(sentences=df['job_description'], min_count=1, window=5, vector_size=100, workers=10)\n",
    "# model = Word2Vec(senteces=df['description'], min_count=1, window=2, vector_size=100, sample=6e-5, alpha=0.03, min_alpha=0.0007, negative=20)\n",
    "\n",
    "my_embedding.save(\"./dataset/my_embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6d2a405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_closestwords_tsnescatterplot(my_embedding.wv, \"custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81e305f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_closestwords_tsnescatterplot(my_embedding.wv, \"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0465c77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1047\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1047\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1047\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1047\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1047\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"0a678743-9c6e-4762-982c-19a26f5eb5f6\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  const docs_json = {\"cff52807-5d9f-4d2d-9550-b0646230a95f\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1011\"}],\"center\":[{\"id\":\"1014\"},{\"id\":\"1018\"},{\"id\":\"1045\"}],\"height\":700,\"left\":[{\"id\":\"1015\"}],\"renderers\":[{\"id\":\"1043\"}],\"title\":{\"id\":\"1048\"},\"toolbar\":{\"id\":\"1029\"},\"width\":700,\"x_range\":{\"id\":\"1003\"},\"x_scale\":{\"id\":\"1007\"},\"y_range\":{\"id\":\"1005\"},\"y_scale\":{\"id\":\"1009\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1038\"},\"glyph\":{\"id\":\"1040\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1042\"},\"nonselection_glyph\":{\"id\":\"1041\"},\"view\":{\"id\":\"1044\"}},\"id\":\"1043\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#8724B5\"},\"hatch_alpha\":{\"value\":0.2},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1042\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1052\",\"type\":\"AllLabels\"},{\"attributes\":{\"source\":{\"id\":\"1038\"}},\"id\":\"1044\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1054\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1003\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1055\",\"type\":\"AllLabels\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"source\":{\"id\":\"1038\"},\"text\":{\"field\":\"text_labels\"},\"text_align\":{\"value\":\"center\"},\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":8}},\"id\":\"1045\",\"type\":\"LabelSet\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1027\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"1048\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"overlay\":{\"id\":\"1027\"}},\"id\":\"1026\",\"type\":\"BoxSelectTool\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"ZoomOutTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.6},\"fill_color\":{\"value\":\"#8724B5\"},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1040\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"ZoomInTool\"},{\"attributes\":{},\"id\":\"1056\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis\":{\"id\":\"1011\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1014\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1019\",\"type\":\"HoverTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1028\"}},\"id\":\"1022\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"data\":{\"index\":[\"\\u00e2\",\"work\",\"experi\",\"manag\",\"role\",\"team\",\"servic\",\"skill\",\"provid\",\"develop\",\"busi\",\"opportun\",\"support\",\"requir\",\"commun\",\"applic\",\"posit\",\"includ\",\"appli\",\"custom\",\"abil\",\"client\",\"project\",\"success\",\"peopl\",\"environ\",\"strong\",\"compani\",\"respons\",\"excel\",\"time\",\"new\",\"look\",\"oper\",\"ensur\",\"current\",\"high\",\"need\",\"industri\",\"profession\",\"join\",\"organis\",\"lead\",\"train\",\"offer\",\"candid\",\"year\",\"assist\",\"career\",\"product\",\"base\",\"health\",\"australia\",\"offic\",\"sale\",\"process\",\"report\",\"contact\",\"inform\",\"program\",\"level\",\"knowledg\",\"qualiti\",\"care\",\"market\",\"deliv\",\"plan\",\"build\",\"employ\",\"key\",\"staff\",\"demonstr\",\"experienc\",\"seek\",\"rang\",\"account\",\"day\",\"great\",\"highli\",\"job\",\"maintain\",\"design\",\"commit\",\"use\",\"person\",\"understand\",\"australian\",\"benefit\",\"make\",\"follow\",\"meet\",\"avail\",\"perform\",\"abl\",\"cultur\",\"recruit\",\"practic\",\"close\",\"intern\",\"diver\"],\"text_labels\":[\"\\u00e2\",\"work\",\"experi\",\"manag\",\"role\",\"team\",\"servic\",\"skill\",\"provid\",\"develop\",\"busi\",\"opportun\",\"support\",\"requir\",\"commun\",\"applic\",\"posit\",\"includ\",\"appli\",\"custom\",\"abil\",\"client\",\"project\",\"success\",\"peopl\",\"environ\",\"strong\",\"compani\",\"respons\",\"excel\",\"time\",\"new\",\"look\",\"oper\",\"ensur\",\"current\",\"high\",\"need\",\"industri\",\"profession\",\"join\",\"organis\",\"lead\",\"train\",\"offer\",\"candid\",\"year\",\"assist\",\"career\",\"product\",\"base\",\"health\",\"australia\",\"offic\",\"sale\",\"process\",\"report\",\"contact\",\"inform\",\"program\",\"level\",\"knowledg\",\"qualiti\",\"care\",\"market\",\"deliv\",\"plan\",\"build\",\"employ\",\"key\",\"staff\",\"demonstr\",\"experienc\",\"seek\",\"rang\",\"account\",\"day\",\"great\",\"highli\",\"job\",\"maintain\",\"design\",\"commit\",\"use\",\"person\",\"understand\",\"australian\",\"benefit\",\"make\",\"follow\",\"meet\",\"avail\",\"perform\",\"abl\",\"cultur\",\"recruit\",\"practic\",\"close\",\"intern\",\"diver\"],\"x\":{\"__ndarray__\":\"SlEIQXz9iEEDXrvBAgxxwaKv3kELod9BM/OjQbdbhEJQuBZCFDrNwW/Myj0Mj39CWhA0QQnW5L/HVEBCWvAmQqN2CUKMUby/dM3xQQ5Kf0EhAYTC984hQU7+MMKKhD7B3HVuQrViVEDN2x7C4ay4QZe2KMEizDTC3NB7Qd81PsIWoZ1BVaN6wPpAbcEO3aVAwgXYwR89EsEP1N/B511LQt7ht8IxwANCARRgwT7dy0KyaJVC4rA4Qi55JsLKjwxApFSlQqWnIkFSafjAQeakQvCQ18KuzILCBwM4QCHGfcJOqY1BGQSBwDGnLkIGqw3C6ZN6Qn/T4UKJE2RC/ChuQrLT/MHKsBNCjNbqwSuw8sGrX4dCvwjWwShNF0IRbwHCNyDMQFMVvkGPGPDB9nKOwWuF88ANtSrCXtEJQtCmJkKD9nPC+1Miwq3YjEK8u7VC35tUQiQF4kIlzMjCQ8SpQoxPbcLy48NBp7CywH64ckGn1TxCfn1owtsGSkG2n9RAovGBwg8AnsK4AjrCbw4SQg==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[100]},\"y\":{\"__ndarray__\":\"J/1IwZ43dcAhL6LB4fvZQTmaS8FogKNAxqCIQZwru0GYujJCUfAZQvTu9kHziCzCOEIgQY34rsE1ZNlB310mwp2XksGGpXHAKQlIwhiORULaIwfCmw0eQu2vx0FDKQnCemgMwfy4zcKWCynCASIEQp+QokA/pkjCC86swXRHYUJuApLCC/yZQQpIlcJHmAXCu9BWwjZOjMEisH/ASSf7QKL4YEGKDuRBUlxaQlZJ2MGcqNDBaT4EwktuhMFDQ/lAGK4+wuCB1UHSWEzCxeAkQr6EmMGRCI3CwqFeQit0eUFxDY9ChKPdQrDVfcII2ajCQPmNQsertkGZSqNCO/ouQkRh7ECTd1pCBxrCQT8qPULUjJHCkyODQjyASUE+hffByaZ5wmDXoMKk8KdCG9VnQSbyJEKacnHCnL7MQpUeEcG6kg9CJ6UJQoA0c0ChsR1BGDyrwV0V/EGFp7fBxeWIwVQ7okL0BATCHjOXQiHvM8L0QpBCIOPuwX481cIBir5C6MXMwFSqUUIo2K9AAmnTwg==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[100]}},\"selected\":{\"id\":\"1057\"},\"selection_policy\":{\"id\":\"1056\"}},\"id\":\"1038\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1057\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#8724B5\"},\"hatch_alpha\":{\"value\":0.1},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1041\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"RedoTool\"},{\"attributes\":{},\"id\":\"1051\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1015\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1018\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"UndoTool\"},{\"attributes\":{},\"id\":\"1016\",\"type\":\"BasicTicker\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1051\"},\"group\":null,\"major_label_policy\":{\"id\":\"1052\"},\"ticker\":{\"id\":\"1016\"}},\"id\":\"1015\",\"type\":\"LinearAxis\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1028\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"tools\":[{\"id\":\"1019\"},{\"id\":\"1020\"},{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"}]},\"id\":\"1029\",\"type\":\"Toolbar\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1054\"},\"group\":null,\"major_label_policy\":{\"id\":\"1055\"},\"ticker\":{\"id\":\"1012\"}},\"id\":\"1011\",\"type\":\"LinearAxis\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.2\"}};\n",
       "  const render_items = [{\"docid\":\"cff52807-5d9f-4d2d-9550-b0646230a95f\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"0a678743-9c6e-4762-982c-19a26f5eb5f6\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_wv(my_embedding, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "031d5d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1165\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1165\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1165\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1165\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1165\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"da63df96-8cf2-46e7-81e4-c39e820773e4\" data-root-id=\"1120\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  const docs_json = {\"90eac291-23b1-40ea-9bed-f4eed5e94f08\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1129\"}],\"center\":[{\"id\":\"1132\"},{\"id\":\"1136\"},{\"id\":\"1163\"}],\"height\":700,\"left\":[{\"id\":\"1133\"}],\"renderers\":[{\"id\":\"1161\"}],\"title\":{\"id\":\"1178\"},\"toolbar\":{\"id\":\"1147\"},\"width\":700,\"x_range\":{\"id\":\"1121\"},\"x_scale\":{\"id\":\"1125\"},\"y_range\":{\"id\":\"1123\"},\"y_scale\":{\"id\":\"1127\"}},\"id\":\"1120\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1185\",\"type\":\"AllLabels\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#8724B5\"},\"hatch_alpha\":{\"value\":0.1},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1159\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.6},\"fill_color\":{\"value\":\"#8724B5\"},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1158\",\"type\":\"Scatter\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1184\"},\"group\":null,\"major_label_policy\":{\"id\":\"1185\"},\"ticker\":{\"id\":\"1130\"}},\"id\":\"1129\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1123\",\"type\":\"DataRange1d\"},{\"attributes\":{\"tools\":[{\"id\":\"1137\"},{\"id\":\"1138\"},{\"id\":\"1139\"},{\"id\":\"1140\"},{\"id\":\"1141\"},{\"id\":\"1142\"},{\"id\":\"1143\"},{\"id\":\"1144\"}]},\"id\":\"1147\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1125\",\"type\":\"LinearScale\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"1178\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1186\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1146\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1145\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1187\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1142\",\"type\":\"RedoTool\"},{\"attributes\":{},\"id\":\"1143\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1121\",\"type\":\"DataRange1d\"},{\"attributes\":{\"overlay\":{\"id\":\"1146\"}},\"id\":\"1140\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1139\",\"type\":\"ZoomOutTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1137\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1138\",\"type\":\"ZoomInTool\"},{\"attributes\":{\"source\":{\"id\":\"1156\"}},\"id\":\"1162\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1141\",\"type\":\"UndoTool\"},{\"attributes\":{},\"id\":\"1134\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1133\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1136\",\"type\":\"Grid\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1156\"},\"glyph\":{\"id\":\"1158\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1160\"},\"nonselection_glyph\":{\"id\":\"1159\"},\"view\":{\"id\":\"1162\"}},\"id\":\"1161\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"1129\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1132\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1130\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1181\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"source\":{\"id\":\"1156\"},\"text\":{\"field\":\"text_labels\"},\"text_align\":{\"value\":\"center\"},\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":8}},\"id\":\"1163\",\"type\":\"LabelSet\"},{\"attributes\":{\"data\":{\"index\":[\"\\u00e2\",\"work\",\"experi\",\"manag\",\"role\",\"team\",\"servic\",\"skill\",\"provid\",\"develop\",\"busi\",\"opportun\",\"support\",\"requir\",\"commun\",\"applic\",\"posit\",\"includ\",\"appli\",\"custom\",\"abil\",\"client\",\"project\",\"success\",\"peopl\",\"environ\",\"strong\",\"compani\",\"respons\",\"excel\",\"time\",\"new\",\"look\",\"oper\",\"ensur\",\"current\",\"high\",\"need\",\"industri\",\"profession\",\"join\",\"organis\",\"lead\",\"train\",\"offer\",\"candid\",\"year\",\"assist\",\"career\",\"product\",\"base\",\"health\",\"australia\",\"offic\",\"sale\",\"process\",\"report\",\"contact\",\"inform\",\"program\",\"level\",\"knowledg\",\"qualiti\",\"care\",\"market\",\"deliv\",\"plan\",\"build\",\"employ\",\"key\",\"staff\",\"demonstr\",\"experienc\",\"seek\",\"rang\",\"account\",\"day\",\"great\",\"highli\",\"job\",\"maintain\",\"design\",\"commit\",\"use\",\"person\",\"understand\",\"australian\",\"benefit\",\"make\",\"follow\",\"meet\",\"avail\",\"perform\",\"abl\",\"cultur\",\"recruit\",\"practic\",\"close\",\"intern\",\"diver\",\"gener\",\"activ\",\"learn\",\"relationship\",\"valu\",\"solut\",\"data\",\"passion\",\"effect\",\"locat\",\"qualif\",\"administr\",\"essenti\",\"grow\",\"group\",\"flexibl\",\"salari\",\"improv\",\"stakehold\",\"click\",\"area\",\"deliveri\",\"hour\",\"good\",\"resum\",\"employe\",\"right\",\"achiev\",\"system\",\"financi\",\"relat\",\"implement\",\"educ\",\"engin\",\"duti\",\"technic\",\"standard\",\"relev\",\"help\",\"drive\",\"continu\",\"best\",\"safeti\",\"amp\",\"prepar\",\"complet\",\"technolog\",\"like\",\"contract\",\"growth\",\"site\",\"leader\",\"coordin\",\"excit\",\"child\",\"senior\",\"commerci\",\"check\",\"engag\",\"nation\",\"construct\",\"consult\",\"email\",\"innov\",\"member\",\"previou\",\"packag\",\"individu\",\"written\",\"desir\",\"proven\",\"integr\",\"ongo\",\"chang\",\"creat\",\"govern\",\"document\",\"consid\",\"cover\",\"sydney\",\"mainten\",\"ideal\",\"focu\",\"encourag\",\"secur\",\"initi\",\"motiv\",\"centr\",\"brand\",\"start\",\"review\",\"want\",\"\\u00e2\\u00e2\",\"perman\",\"school\",\"licenc\",\"collabor\",\"submit\",\"driver\",\"famili\",\"ass\",\"background\",\"strategi\",\"establish\",\"prefer\",\"leadership\",\"except\",\"student\",\"contribut\",\"retail\",\"global\",\"depart\",\"complianc\",\"progress\",\"reward\",\"sound\",\"week\",\"attent\",\"polici\",\"month\",\"approach\",\"network\",\"present\",\"minimum\",\"identifi\",\"criterion\",\"record\",\"challeng\",\"local\",\"task\",\"certif\",\"larg\",\"focus\",\"confidenti\",\"medic\",\"regard\",\"target\",\"trade\",\"equip\",\"order\",\"transport\",\"onlin\",\"letter\",\"direct\",\"attitud\",\"live\",\"discus\",\"issu\",\"analysi\",\"dynam\",\"promot\",\"access\",\"region\",\"number\",\"extern\",\"interest\",\"resourc\",\"verbal\",\"melbourn\",\"differ\",\"execut\",\"set\",\"procedur\",\"clinic\",\"function\",\"travel\",\"enjoy\",\"nsw\",\"sector\",\"test\",\"research\",\"refer\",\"agenc\",\"outcom\",\"safe\",\"risk\",\"note\",\"partner\",\"control\",\"friendli\",\"button\",\"problem\",\"competit\",\"social\",\"exist\",\"effici\",\"tool\",\"similar\",\"appropri\",\"detail\",\"complex\",\"undertak\",\"corpor\",\"youll\",\"specialist\",\"age\",\"store\",\"conduct\",\"term\",\"descript\",\"select\",\"softwar\",\"immedi\",\"nurs\",\"qualifi\",\"extens\",\"reliabl\",\"posse\",\"public\",\"strateg\",\"pm\",\"cv\",\"involv\",\"result\",\"andor\",\"shift\",\"vehicl\",\"facil\",\"life\",\"home\",\"end\",\"advic\",\"april\",\"forward\",\"return\",\"addit\",\"liais\",\"advanc\",\"rate\",\"hospit\",\"talent\",\"audit\",\"world\",\"comput\",\"expect\",\"analyt\",\"receiv\",\"workplac\",\"disabl\",\"multipl\",\"capabl\",\"fit\",\"confid\",\"visit\",\"properti\",\"fast\",\"interperson\",\"firm\",\"limit\",\"phone\",\"specif\",\"hold\",\"driven\",\"insur\",\"hr\",\"open\",\"negoti\",\"field\",\"event\",\"financ\",\"monitor\",\"futur\",\"degre\",\"send\",\"medium\",\"manufactur\",\"inclus\",\"suit\",\"advantag\",\"potenti\",\"manner\",\"dedic\",\"track\",\"digit\",\"largest\",\"love\",\"teach\",\"small\",\"food\",\"proactiv\",\"patient\",\"varieti\",\"long\",\"variou\",\"respect\",\"independ\",\"structur\",\"websit\",\"recognis\",\"leav\",\"equal\",\"portfolio\",\"particip\",\"outstand\",\"place\",\"infrastructur\",\"monday\",\"budget\",\"roster\",\"microsoft\",\"remuner\",\"friday\",\"link\",\"plu\",\"mine\",\"solv\",\"enquiri\",\"wide\",\"major\",\"south\",\"licens\",\"schedul\",\"date\",\"electr\",\"aborigin\",\"address\",\"suppli\",\"resid\",\"accur\",\"polic\",\"run\",\"daili\",\"state\",\"legal\",\"list\",\"enthusiast\",\"consist\",\"basi\",\"casual\",\"suitabl\",\"supervis\",\"fantast\",\"import\",\"regist\",\"line\",\"cost\",\"balanc\",\"attract\",\"claim\",\"tertiari\",\"reput\",\"way\",\"act\",\"investig\",\"goal\",\"word\",\"award\",\"think\",\"mechan\",\"today\",\"whilst\",\"condit\",\"come\",\"know\",\"privat\",\"associ\",\"succeed\",\"share\",\"pace\",\"face\",\"unit\",\"possibl\",\"bank\",\"compet\",\"workforc\",\"teacher\",\"earli\",\"director\",\"pride\",\"increas\",\"supplier\",\"creativ\",\"object\",\"expertis\",\"bring\",\"allow\",\"univers\",\"hand\",\"handl\",\"cbd\",\"asset\",\"brisban\",\"model\",\"mentor\",\"australia\\u00e2\",\"ethic\",\"will\",\"superannu\",\"decis\",\"view\",\"annual\",\"own\",\"hear\",\"discount\",\"m\",\"island\",\"interview\",\"legisl\",\"real\",\"take\",\"free\",\"materi\",\"believ\",\"clearanc\",\"residenti\",\"exposur\",\"campaign\",\"civil\",\"class\",\"uniqu\",\"pay\",\"citi\",\"expand\",\"arrang\",\"regular\",\"autonom\",\"and\\u00e2\",\"energi\",\"prior\",\"instal\",\"park\",\"stock\",\"directli\",\"fulltim\",\"divis\",\"repair\",\"deadlin\",\"specialis\",\"accord\",\"facilit\",\"player\",\"weekend\",\"fun\",\"framework\",\"repres\",\"card\",\"platform\",\"forklift\",\"invest\",\"deal\",\"copi\",\"quot\",\"produc\",\"torr\",\"feel\",\"aspect\",\"capac\",\"contractor\",\"valid\",\"comprehens\",\"strait\",\"updat\",\"appoint\",\"head\",\"fund\",\"you\\u00e2ll\",\"queensland\",\"worker\",\"commenc\",\"primari\",\"car\",\"option\",\"countri\",\"monthli\",\"step\",\"paid\",\"super\",\"enabl\",\"gain\",\"influenc\",\"call\",\"matter\",\"welcom\",\"sustain\",\"payrol\",\"purpos\",\"case\",\"clean\",\"critic\",\"attend\",\"coach\",\"natur\",\"prioriti\",\"just\",\"signific\",\"plant\",\"genuin\",\"enhanc\",\"a\\u00e2\",\"registr\",\"collect\",\"impact\",\"solid\",\"healthcar\",\"truck\",\"obtain\",\"histori\",\"equival\",\"willing\",\"road\",\"point\",\"energet\",\"content\",\"tax\",\"load\",\"readi\",\"core\",\"behaviour\",\"connect\",\"recent\",\"wellb\",\"disciplin\",\"council\",\"mobil\",\"request\",\"form\",\"altern\",\"years\\u00e2\",\"shortlist\",\"question\",\"expert\",\"hard\",\"your\",\"perth\",\"commiss\",\"provis\",\"north\",\"zealand\",\"play\",\"workshop\",\"ap\",\"distribut\",\"law\",\"trust\",\"entri\",\"human\",\"necessari\",\"subject\",\"vari\",\"profici\",\"period\",\"young\",\"prioritis\",\"write\",\"databas\",\"analys\",\"warehous\",\"orient\",\"elig\",\"screen\",\"profit\",\"depend\",\"onsit\",\"sourc\",\"th\",\"space\",\"vision\",\"agil\",\"thrive\",\"enterpris\",\"labour\",\"to\\u00e2\",\"pressur\",\"mental\",\"power\",\"the\\u00e2\",\"sell\",\"western\",\"broad\",\"analyst\",\"victoria\",\"action\",\"volum\",\"overse\",\"respond\",\"protect\",\"manual\",\"partnership\",\"physic\",\"inspir\",\"scienc\",\"adher\",\"better\",\"logist\",\"queri\",\"profil\",\"attribut\",\"interact\",\"insight\",\"architectur\",\"demand\",\"web\",\"fix\",\"clear\",\"file\",\"branch\",\"weekli\",\"short\",\"accept\",\"read\",\"format\",\"transform\",\"thing\",\"graduat\",\"woman\",\"citizen\",\"regul\",\"adapt\",\"supervisor\",\"section\",\"advertis\",\"room\",\"basic\",\"principl\",\"serv\",\"water\",\"ad\",\"accommod\",\"proud\",\"selfmotiv\",\"have\",\"post\",\"code\",\"suburb\",\"idea\",\"attach\",\"modern\",\"assign\",\"we\\u00e2r\",\"heavi\",\"team\\u00e2\",\"ticket\",\"environment\",\"drug\",\"advis\",\"type\",\"payment\",\"studi\",\"reach\",\"purchas\",\"evalu\",\"procur\",\"book\",\"invoic\",\"practition\",\"temporari\",\"cours\",\"utilis\",\"aid\",\"combin\",\"align\",\"hire\",\"machin\",\"coast\",\"recommend\",\"style\",\"scope\",\"highest\",\"fulli\",\"win\",\"alcohol\",\"k\",\"page\",\"vacanc\",\"classroom\",\"keen\",\"incent\",\"hous\",\"carri\",\"central\",\"guidanc\",\"victorian\",\"consum\",\"earn\",\"bonu\",\"automot\",\"adelaid\",\"aim\",\"junior\",\"lifestyl\",\"choic\",\"sap\",\"board\",\"west\",\"determin\",\"night\",\"accredit\",\"pas\",\"main\",\"outlin\",\"skills\\u00e2\",\"hotel\",\"estat\",\"restaur\",\"econom\",\"crimin\",\"known\",\"rail\",\"preemploy\",\"parent\",\"correct\",\"resolv\",\"approv\",\"search\",\"exceed\",\"treat\",\"strive\",\"amaz\",\"sunday\",\"experience\\u00e2\",\"kpi\",\"white\",\"awar\",\"brief\",\"role\\u00e2\",\"shop\",\"kitchen\",\"emerg\",\"comfort\",\"interpret\",\"you\\u00e2\",\"chanc\",\"oral\",\"referr\",\"statement\",\"autom\",\"incom\",\"mean\",\"sport\",\"agre\",\"channel\",\"quickli\",\"institut\",\"defin\",\"forecast\",\"answer\",\"evid\",\"incorrect\",\"childhood\",\"parti\",\"technician\",\"curriculum\",\"reconcili\",\"resolut\",\"territori\",\"canberra\",\"multidisciplinari\",\"induct\",\"overal\",\"beauti\",\"vibrant\",\"estim\",\"worklif\",\"in\\u00e2\",\"accuraci\",\"revenu\",\"special\",\"motor\",\"colleg\",\"compon\",\"big\",\"express\",\"st\",\"art\",\"foster\",\"satisfact\",\"fraud\",\"mind\",\"alongsid\",\"part\",\"mission\",\"given\",\"methodolog\",\"regulatori\",\"embrac\",\"sure\",\"instruct\",\"uptod\",\"consider\",\"occup\",\"price\",\"draw\",\"cloud\",\"intermedi\",\"do\",\"fastpac\",\"hit\",\"prospect\",\"alloc\",\"guid\",\"multitask\",\"trend\",\"guidelin\",\"assur\",\"prevent\",\"alli\",\"dont\",\"built\",\"bill\",\"east\",\"measur\",\"inspect\",\"perk\",\"personnel\",\"ga\",\"stage\",\"situat\",\"heart\",\"reflect\",\"diploma\",\"indigen\",\"maximis\",\"capit\",\"telephon\",\"colleagu\",\"pick\",\"vendor\",\"self\",\"met\",\"hourli\",\"statu\",\"wa\",\"parttim\",\"treatment\",\"eye\",\"guest\",\"million\",\"english\",\"membership\",\"remot\",\"scheme\",\"you\\u00e2r\",\"of\\u00e2\",\"oh\",\"doe\",\"credit\",\"ownership\",\"domest\",\"pa\",\"techniqu\",\"ahpra\",\"academ\",\"overtim\",\"concept\",\"literaci\",\"qld\",\"recept\",\"healthi\",\"rehabilit\",\"propos\",\"owner\",\"iii\",\"correspond\",\"rotat\",\"chef\",\"organ\",\"rapidli\",\"happi\",\"builder\",\"display\",\"northern\",\"eastern\",\"pipelin\",\"gold\",\"c\",\"shape\",\"journey\",\"chain\",\"ground\",\"club\",\"sen\",\"superior\",\"for\\u00e2\",\"tender\",\"visa\",\"pack\",\"acquisit\",\"method\",\"transact\",\"now\\u00e2\",\"mandatori\",\"lift\",\"intervent\",\"dental\",\"advisor\",\"optimis\",\"box\",\"inventori\",\"categori\",\"steel\",\"server\",\"merchandis\",\"feedback\",\"holiday\",\"iv\",\"agreement\",\"deploy\",\"scale\",\"wage\",\"what\"],\"text_labels\":[\"\\u00e2\",\"work\",\"experi\",\"manag\",\"role\",\"team\",\"servic\",\"skill\",\"provid\",\"develop\",\"busi\",\"opportun\",\"support\",\"requir\",\"commun\",\"applic\",\"posit\",\"includ\",\"appli\",\"custom\",\"abil\",\"client\",\"project\",\"success\",\"peopl\",\"environ\",\"strong\",\"compani\",\"respons\",\"excel\",\"time\",\"new\",\"look\",\"oper\",\"ensur\",\"current\",\"high\",\"need\",\"industri\",\"profession\",\"join\",\"organis\",\"lead\",\"train\",\"offer\",\"candid\",\"year\",\"assist\",\"career\",\"product\",\"base\",\"health\",\"australia\",\"offic\",\"sale\",\"process\",\"report\",\"contact\",\"inform\",\"program\",\"level\",\"knowledg\",\"qualiti\",\"care\",\"market\",\"deliv\",\"plan\",\"build\",\"employ\",\"key\",\"staff\",\"demonstr\",\"experienc\",\"seek\",\"rang\",\"account\",\"day\",\"great\",\"highli\",\"job\",\"maintain\",\"design\",\"commit\",\"use\",\"person\",\"understand\",\"australian\",\"benefit\",\"make\",\"follow\",\"meet\",\"avail\",\"perform\",\"abl\",\"cultur\",\"recruit\",\"practic\",\"close\",\"intern\",\"diver\",\"gener\",\"activ\",\"learn\",\"relationship\",\"valu\",\"solut\",\"data\",\"passion\",\"effect\",\"locat\",\"qualif\",\"administr\",\"essenti\",\"grow\",\"group\",\"flexibl\",\"salari\",\"improv\",\"stakehold\",\"click\",\"area\",\"deliveri\",\"hour\",\"good\",\"resum\",\"employe\",\"right\",\"achiev\",\"system\",\"financi\",\"relat\",\"implement\",\"educ\",\"engin\",\"duti\",\"technic\",\"standard\",\"relev\",\"help\",\"drive\",\"continu\",\"best\",\"safeti\",\"amp\",\"prepar\",\"complet\",\"technolog\",\"like\",\"contract\",\"growth\",\"site\",\"leader\",\"coordin\",\"excit\",\"child\",\"senior\",\"commerci\",\"check\",\"engag\",\"nation\",\"construct\",\"consult\",\"email\",\"innov\",\"member\",\"previou\",\"packag\",\"individu\",\"written\",\"desir\",\"proven\",\"integr\",\"ongo\",\"chang\",\"creat\",\"govern\",\"document\",\"consid\",\"cover\",\"sydney\",\"mainten\",\"ideal\",\"focu\",\"encourag\",\"secur\",\"initi\",\"motiv\",\"centr\",\"brand\",\"start\",\"review\",\"want\",\"\\u00e2\\u00e2\",\"perman\",\"school\",\"licenc\",\"collabor\",\"submit\",\"driver\",\"famili\",\"ass\",\"background\",\"strategi\",\"establish\",\"prefer\",\"leadership\",\"except\",\"student\",\"contribut\",\"retail\",\"global\",\"depart\",\"complianc\",\"progress\",\"reward\",\"sound\",\"week\",\"attent\",\"polici\",\"month\",\"approach\",\"network\",\"present\",\"minimum\",\"identifi\",\"criterion\",\"record\",\"challeng\",\"local\",\"task\",\"certif\",\"larg\",\"focus\",\"confidenti\",\"medic\",\"regard\",\"target\",\"trade\",\"equip\",\"order\",\"transport\",\"onlin\",\"letter\",\"direct\",\"attitud\",\"live\",\"discus\",\"issu\",\"analysi\",\"dynam\",\"promot\",\"access\",\"region\",\"number\",\"extern\",\"interest\",\"resourc\",\"verbal\",\"melbourn\",\"differ\",\"execut\",\"set\",\"procedur\",\"clinic\",\"function\",\"travel\",\"enjoy\",\"nsw\",\"sector\",\"test\",\"research\",\"refer\",\"agenc\",\"outcom\",\"safe\",\"risk\",\"note\",\"partner\",\"control\",\"friendli\",\"button\",\"problem\",\"competit\",\"social\",\"exist\",\"effici\",\"tool\",\"similar\",\"appropri\",\"detail\",\"complex\",\"undertak\",\"corpor\",\"youll\",\"specialist\",\"age\",\"store\",\"conduct\",\"term\",\"descript\",\"select\",\"softwar\",\"immedi\",\"nurs\",\"qualifi\",\"extens\",\"reliabl\",\"posse\",\"public\",\"strateg\",\"pm\",\"cv\",\"involv\",\"result\",\"andor\",\"shift\",\"vehicl\",\"facil\",\"life\",\"home\",\"end\",\"advic\",\"april\",\"forward\",\"return\",\"addit\",\"liais\",\"advanc\",\"rate\",\"hospit\",\"talent\",\"audit\",\"world\",\"comput\",\"expect\",\"analyt\",\"receiv\",\"workplac\",\"disabl\",\"multipl\",\"capabl\",\"fit\",\"confid\",\"visit\",\"properti\",\"fast\",\"interperson\",\"firm\",\"limit\",\"phone\",\"specif\",\"hold\",\"driven\",\"insur\",\"hr\",\"open\",\"negoti\",\"field\",\"event\",\"financ\",\"monitor\",\"futur\",\"degre\",\"send\",\"medium\",\"manufactur\",\"inclus\",\"suit\",\"advantag\",\"potenti\",\"manner\",\"dedic\",\"track\",\"digit\",\"largest\",\"love\",\"teach\",\"small\",\"food\",\"proactiv\",\"patient\",\"varieti\",\"long\",\"variou\",\"respect\",\"independ\",\"structur\",\"websit\",\"recognis\",\"leav\",\"equal\",\"portfolio\",\"particip\",\"outstand\",\"place\",\"infrastructur\",\"monday\",\"budget\",\"roster\",\"microsoft\",\"remuner\",\"friday\",\"link\",\"plu\",\"mine\",\"solv\",\"enquiri\",\"wide\",\"major\",\"south\",\"licens\",\"schedul\",\"date\",\"electr\",\"aborigin\",\"address\",\"suppli\",\"resid\",\"accur\",\"polic\",\"run\",\"daili\",\"state\",\"legal\",\"list\",\"enthusiast\",\"consist\",\"basi\",\"casual\",\"suitabl\",\"supervis\",\"fantast\",\"import\",\"regist\",\"line\",\"cost\",\"balanc\",\"attract\",\"claim\",\"tertiari\",\"reput\",\"way\",\"act\",\"investig\",\"goal\",\"word\",\"award\",\"think\",\"mechan\",\"today\",\"whilst\",\"condit\",\"come\",\"know\",\"privat\",\"associ\",\"succeed\",\"share\",\"pace\",\"face\",\"unit\",\"possibl\",\"bank\",\"compet\",\"workforc\",\"teacher\",\"earli\",\"director\",\"pride\",\"increas\",\"supplier\",\"creativ\",\"object\",\"expertis\",\"bring\",\"allow\",\"univers\",\"hand\",\"handl\",\"cbd\",\"asset\",\"brisban\",\"model\",\"mentor\",\"australia\\u00e2\",\"ethic\",\"will\",\"superannu\",\"decis\",\"view\",\"annual\",\"own\",\"hear\",\"discount\",\"m\",\"island\",\"interview\",\"legisl\",\"real\",\"take\",\"free\",\"materi\",\"believ\",\"clearanc\",\"residenti\",\"exposur\",\"campaign\",\"civil\",\"class\",\"uniqu\",\"pay\",\"citi\",\"expand\",\"arrang\",\"regular\",\"autonom\",\"and\\u00e2\",\"energi\",\"prior\",\"instal\",\"park\",\"stock\",\"directli\",\"fulltim\",\"divis\",\"repair\",\"deadlin\",\"specialis\",\"accord\",\"facilit\",\"player\",\"weekend\",\"fun\",\"framework\",\"repres\",\"card\",\"platform\",\"forklift\",\"invest\",\"deal\",\"copi\",\"quot\",\"produc\",\"torr\",\"feel\",\"aspect\",\"capac\",\"contractor\",\"valid\",\"comprehens\",\"strait\",\"updat\",\"appoint\",\"head\",\"fund\",\"you\\u00e2ll\",\"queensland\",\"worker\",\"commenc\",\"primari\",\"car\",\"option\",\"countri\",\"monthli\",\"step\",\"paid\",\"super\",\"enabl\",\"gain\",\"influenc\",\"call\",\"matter\",\"welcom\",\"sustain\",\"payrol\",\"purpos\",\"case\",\"clean\",\"critic\",\"attend\",\"coach\",\"natur\",\"prioriti\",\"just\",\"signific\",\"plant\",\"genuin\",\"enhanc\",\"a\\u00e2\",\"registr\",\"collect\",\"impact\",\"solid\",\"healthcar\",\"truck\",\"obtain\",\"histori\",\"equival\",\"willing\",\"road\",\"point\",\"energet\",\"content\",\"tax\",\"load\",\"readi\",\"core\",\"behaviour\",\"connect\",\"recent\",\"wellb\",\"disciplin\",\"council\",\"mobil\",\"request\",\"form\",\"altern\",\"years\\u00e2\",\"shortlist\",\"question\",\"expert\",\"hard\",\"your\",\"perth\",\"commiss\",\"provis\",\"north\",\"zealand\",\"play\",\"workshop\",\"ap\",\"distribut\",\"law\",\"trust\",\"entri\",\"human\",\"necessari\",\"subject\",\"vari\",\"profici\",\"period\",\"young\",\"prioritis\",\"write\",\"databas\",\"analys\",\"warehous\",\"orient\",\"elig\",\"screen\",\"profit\",\"depend\",\"onsit\",\"sourc\",\"th\",\"space\",\"vision\",\"agil\",\"thrive\",\"enterpris\",\"labour\",\"to\\u00e2\",\"pressur\",\"mental\",\"power\",\"the\\u00e2\",\"sell\",\"western\",\"broad\",\"analyst\",\"victoria\",\"action\",\"volum\",\"overse\",\"respond\",\"protect\",\"manual\",\"partnership\",\"physic\",\"inspir\",\"scienc\",\"adher\",\"better\",\"logist\",\"queri\",\"profil\",\"attribut\",\"interact\",\"insight\",\"architectur\",\"demand\",\"web\",\"fix\",\"clear\",\"file\",\"branch\",\"weekli\",\"short\",\"accept\",\"read\",\"format\",\"transform\",\"thing\",\"graduat\",\"woman\",\"citizen\",\"regul\",\"adapt\",\"supervisor\",\"section\",\"advertis\",\"room\",\"basic\",\"principl\",\"serv\",\"water\",\"ad\",\"accommod\",\"proud\",\"selfmotiv\",\"have\",\"post\",\"code\",\"suburb\",\"idea\",\"attach\",\"modern\",\"assign\",\"we\\u00e2r\",\"heavi\",\"team\\u00e2\",\"ticket\",\"environment\",\"drug\",\"advis\",\"type\",\"payment\",\"studi\",\"reach\",\"purchas\",\"evalu\",\"procur\",\"book\",\"invoic\",\"practition\",\"temporari\",\"cours\",\"utilis\",\"aid\",\"combin\",\"align\",\"hire\",\"machin\",\"coast\",\"recommend\",\"style\",\"scope\",\"highest\",\"fulli\",\"win\",\"alcohol\",\"k\",\"page\",\"vacanc\",\"classroom\",\"keen\",\"incent\",\"hous\",\"carri\",\"central\",\"guidanc\",\"victorian\",\"consum\",\"earn\",\"bonu\",\"automot\",\"adelaid\",\"aim\",\"junior\",\"lifestyl\",\"choic\",\"sap\",\"board\",\"west\",\"determin\",\"night\",\"accredit\",\"pas\",\"main\",\"outlin\",\"skills\\u00e2\",\"hotel\",\"estat\",\"restaur\",\"econom\",\"crimin\",\"known\",\"rail\",\"preemploy\",\"parent\",\"correct\",\"resolv\",\"approv\",\"search\",\"exceed\",\"treat\",\"strive\",\"amaz\",\"sunday\",\"experience\\u00e2\",\"kpi\",\"white\",\"awar\",\"brief\",\"role\\u00e2\",\"shop\",\"kitchen\",\"emerg\",\"comfort\",\"interpret\",\"you\\u00e2\",\"chanc\",\"oral\",\"referr\",\"statement\",\"autom\",\"incom\",\"mean\",\"sport\",\"agre\",\"channel\",\"quickli\",\"institut\",\"defin\",\"forecast\",\"answer\",\"evid\",\"incorrect\",\"childhood\",\"parti\",\"technician\",\"curriculum\",\"reconcili\",\"resolut\",\"territori\",\"canberra\",\"multidisciplinari\",\"induct\",\"overal\",\"beauti\",\"vibrant\",\"estim\",\"worklif\",\"in\\u00e2\",\"accuraci\",\"revenu\",\"special\",\"motor\",\"colleg\",\"compon\",\"big\",\"express\",\"st\",\"art\",\"foster\",\"satisfact\",\"fraud\",\"mind\",\"alongsid\",\"part\",\"mission\",\"given\",\"methodolog\",\"regulatori\",\"embrac\",\"sure\",\"instruct\",\"uptod\",\"consider\",\"occup\",\"price\",\"draw\",\"cloud\",\"intermedi\",\"do\",\"fastpac\",\"hit\",\"prospect\",\"alloc\",\"guid\",\"multitask\",\"trend\",\"guidelin\",\"assur\",\"prevent\",\"alli\",\"dont\",\"built\",\"bill\",\"east\",\"measur\",\"inspect\",\"perk\",\"personnel\",\"ga\",\"stage\",\"situat\",\"heart\",\"reflect\",\"diploma\",\"indigen\",\"maximis\",\"capit\",\"telephon\",\"colleagu\",\"pick\",\"vendor\",\"self\",\"met\",\"hourli\",\"statu\",\"wa\",\"parttim\",\"treatment\",\"eye\",\"guest\",\"million\",\"english\",\"membership\",\"remot\",\"scheme\",\"you\\u00e2r\",\"of\\u00e2\",\"oh\",\"doe\",\"credit\",\"ownership\",\"domest\",\"pa\",\"techniqu\",\"ahpra\",\"academ\",\"overtim\",\"concept\",\"literaci\",\"qld\",\"recept\",\"healthi\",\"rehabilit\",\"propos\",\"owner\",\"iii\",\"correspond\",\"rotat\",\"chef\",\"organ\",\"rapidli\",\"happi\",\"builder\",\"display\",\"northern\",\"eastern\",\"pipelin\",\"gold\",\"c\",\"shape\",\"journey\",\"chain\",\"ground\",\"club\",\"sen\",\"superior\",\"for\\u00e2\",\"tender\",\"visa\",\"pack\",\"acquisit\",\"method\",\"transact\",\"now\\u00e2\",\"mandatori\",\"lift\",\"intervent\",\"dental\",\"advisor\",\"optimis\",\"box\",\"inventori\",\"categori\",\"steel\",\"server\",\"merchandis\",\"feedback\",\"holiday\",\"iv\",\"agreement\",\"deploy\",\"scale\",\"wage\",\"what\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]}},\"selected\":{\"id\":\"1187\"},\"selection_policy\":{\"id\":\"1186\"}},\"id\":\"1156\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"overlay\":{\"id\":\"1145\"}},\"id\":\"1144\",\"type\":\"BoxSelectTool\"},{\"attributes\":{},\"id\":\"1182\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1127\",\"type\":\"LinearScale\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1181\"},\"group\":null,\"major_label_policy\":{\"id\":\"1182\"},\"ticker\":{\"id\":\"1134\"}},\"id\":\"1133\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1184\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#8724B5\"},\"hatch_alpha\":{\"value\":0.2},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":null},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1160\",\"type\":\"Scatter\"}],\"root_ids\":[\"1120\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.2\"}};\n",
       "  const render_items = [{\"docid\":\"90eac291-23b1-40ea-9bed-f4eed5e94f08\",\"root_ids\":[\"1120\"],\"roots\":{\"1120\":\"da63df96-8cf2-46e7-81e4-c39e820773e4\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1120"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_wv(my_embedding, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041216f4",
   "metadata": {},
   "source": [
    "#### GloVe: Global Vectors for Word Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a634fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# All Import Statements Defined Here # Note: Do not add to this list.\n",
    "# ----------------\n",
    "import sys\n",
    "assert sys.version_info[0]==3 \n",
    "assert sys.version_info[1] >= 5\n",
    "from gensim.models import KeyedVectors \n",
    "from gensim.test.utils import datapath \n",
    "import pprint\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [10, 5] \n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.decomposition import PCA\n",
    "START_TOKEN = '<START>' \n",
    "END_TOKEN = '<END>'\n",
    "np.random.seed(1212) \n",
    "random.seed(1212)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20393f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load GloVe Vectors\"\"\"\n",
    "def load_embedding_model(data_job): \n",
    "    import gensim.downloader as api\n",
    "    #data_job = api.load(\"glove-wiki-gigaword-200\")\n",
    "    print(\"Loaded vocab size %i\" % len(data_job))\n",
    "    print(\"The loaded object is of type %s\" % str(type(data_job))) \n",
    "    return data_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7db5c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size 29654\n",
      "The loaded object is of type <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------- # Run Cell to Load Word Vectors\n",
    "# Note: This will take several minutes # (8 mins in my case )\n",
    "# -----------------------------------\n",
    "data_job = load_embedding_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "681039ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=29654, step=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9fe981a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[year, experi, fresh, produc, want, manag, sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[opportun, client, solut, analyst, provid, tec...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[innov, busi, develop, role, awardwin, compani...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[role, seek, automot, workshop, technician, jo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[â, earli, start, weekend, shift, experi, nece...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29649</th>\n",
       "      <td>[hotel, snapshot, radisson, blu, plaza, sydney...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29650</th>\n",
       "      <td>[organis, airservic, govern, own, organis, pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29651</th>\n",
       "      <td>[compani, role, client, australiaâ, lead, comm...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29652</th>\n",
       "      <td>[long, term, contract, month, possibl, extens,...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29653</th>\n",
       "      <td>[custom, servic, repres, west, wyalong, time, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29654 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         job_description  job_type  category\n",
       "0      [year, experi, fresh, produc, want, manag, sto...         0        11\n",
       "1      [opportun, client, solut, analyst, provid, tec...         0         8\n",
       "2      [innov, busi, develop, role, awardwin, compani...         0         0\n",
       "3      [role, seek, automot, workshop, technician, jo...         0         0\n",
       "4      [â, earli, start, weekend, shift, experi, nece...         0         0\n",
       "...                                                  ...       ...       ...\n",
       "29649  [hotel, snapshot, radisson, blu, plaza, sydney...         0         6\n",
       "29650  [organis, airservic, govern, own, organis, pro...         0        28\n",
       "29651  [compani, role, client, australiaâ, lead, comm...         0         5\n",
       "29652  [long, term, contract, month, possibl, extens,...         1         8\n",
       "29653  [custom, servic, repres, west, wyalong, time, ...         1         8\n",
       "\n",
       "[29654 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd9000",
   "metadata": {},
   "source": [
    "#### Train a complete model and then get its model.wv property, which contains independent keyed vectors. e.g., train vectors using word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1862ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#model = Word2Vec(common_texts, window=5, min_count=1, workers=4)\n",
    "model = Word2Vec(data_job, window=5, min_count=1, workers=4)\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb452236",
   "metadata": {},
   "source": [
    "#### Load word vector file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf6508be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_vectors.save(\"vectors_wv\")\n",
    "word_vectors = KeyedVectors.load(\"vectors_wv\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0849a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors_m = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87bd2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = my_embedding.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5704c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_scores = model.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8800fdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'â': 0,\n",
       " 'work': 1,\n",
       " 'experi': 2,\n",
       " 'manag': 3,\n",
       " 'role': 4,\n",
       " 'team': 5,\n",
       " 'servic': 6,\n",
       " 'skill': 7,\n",
       " 'provid': 8,\n",
       " 'develop': 9}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in word_vectors.key_to_index.items() if value<10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e29024a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9507627 ,  1.0146029 ,  1.0702271 , -1.09274   , -0.23753747,\n",
       "        2.345818  , -0.02056601, -1.1699958 ,  2.3283718 ,  0.5882244 ,\n",
       "       -1.6269332 ,  0.4547017 , -0.23103994,  0.8603506 ,  0.2097447 ,\n",
       "        1.8126026 ,  2.1914046 ,  3.0524237 ,  1.2384477 ,  0.32909718,\n",
       "       -0.8360463 , -0.4356144 ,  0.00347651,  0.5036618 ,  1.5680369 ,\n",
       "        3.7829072 ,  0.21651338,  0.8203105 , -0.68331975,  2.1179786 ,\n",
       "       -0.257093  , -0.01681009, -1.2799481 , -0.7847436 ,  1.3500309 ,\n",
       "        1.5619758 , -0.05659841,  0.32628757,  1.6478388 ,  3.3144503 ,\n",
       "        1.2479017 , -0.23970324, -0.21563555, -1.8496777 ,  0.25740215,\n",
       "        1.2076046 ,  3.3718114 , -0.55889475, -0.5681432 ,  0.06519304,\n",
       "        1.0654566 ,  1.8309411 ,  1.1765432 ,  2.2018282 ,  2.1071627 ,\n",
       "        0.48404068, -0.84435576,  0.05815728,  1.0042373 , -0.5717208 ,\n",
       "       -1.3523595 ,  0.79126054, -1.71321   , -0.9088836 ,  0.7349794 ,\n",
       "       -2.0533893 , -0.2595059 , -1.5880747 ,  0.46655884, -0.14522608,\n",
       "       -1.0190488 , -1.4927531 , -0.32952666,  2.349276  , -2.4195514 ,\n",
       "       -0.18313022, -2.1127582 , -1.6950568 ,  2.839163  ,  1.805307  ,\n",
       "       -0.5680501 , -0.00273096,  0.57253706, -0.67230785,  0.2194053 ,\n",
       "       -0.03203251, -0.8117124 , -0.01270298,  0.71674514, -1.4395173 ,\n",
       "       -2.280829  ,  1.0166706 ,  0.43044657, -2.1231291 , -1.1919523 ,\n",
       "        0.30229205, -0.49083626, -1.8656304 , -0.7616805 ,  0.90306276],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.get_vector('work')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5143815",
   "metadata": {},
   "source": [
    "#### Reducing dimensionality of Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4192a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Put the GloVe vectors into a matrix M. Param:\n",
    "wv_pretrained: KeyedVectors object; the 400000 GloVe vectors loaded from file\n",
    "Return:\n",
    "            M: numpy matrix shape (num words, 200) containing the vectors\n",
    "            word2Ind: dictionary mapping each word to its row number in M\n",
    "\"\"\"\n",
    "def get_matrix_of_vectors(wv_pretrained, required_words=['barrels', 'bpd', 'ecuador','energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'venezuela']):\n",
    "    import random\n",
    "    words = list(wv_pretrained.key_to_index.keys())\n",
    "    print(\"Shuffling words ...\")\n",
    "    random.seed(224)\n",
    "    random.shuffle(words)\n",
    "    words = words[:10000]\n",
    "    print(\"Putting %i words into word2Ind and matrix M...\" % len(words)) \n",
    "    word2Ind = {}\n",
    "    M = []\n",
    "    curInd = 0\n",
    "    for w in words: \n",
    "        try:\n",
    "            M.append(wv_pretrained.get_vector(w, norm=True)) \n",
    "            word2Ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError: \n",
    "            continue\n",
    "    for w in required_words:\n",
    "        if w in words: \n",
    "            continue\n",
    "        try:\n",
    "            M.append(wv_pretrained.get_vector(w, norm=True)) \n",
    "            word2Ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError: \n",
    "            continue\n",
    "    M = np.stack(M) \n",
    "    print(\"Done.\") \n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f23450",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8dfe62",
   "metadata": {},
   "source": [
    "**Using Pretrained Word2Vec Vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d260e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "#wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50671697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bash', 0.9530633091926575),\n",
       " ('perl', 0.9224193096160889),\n",
       " ('mysql', 0.9156444072723389),\n",
       " ('plsql', 0.9116639494895935),\n",
       " ('mongodb', 0.9014299511909485),\n",
       " ('apach', 0.9001218676567078),\n",
       " ('python', 0.8969963192939758),\n",
       " ('tsql', 0.8958423137664795),\n",
       " ('script', 0.892011821269989),\n",
       " ('docker', 0.8869137763977051)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=[\"powershel\", \"sccm\"], negative=[\"sccm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf64bb",
   "metadata": {},
   "source": [
    "**Plot using TSNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5f2bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_closestwords_tsnescatterplot(model, word): \n",
    "    arr = np.empty((0,100), dtype='f')\n",
    "    word_labels = [word] \n",
    "    # get close words\n",
    "    close_words = model.similar_by_word(word)\n",
    "    # add the vector for each of the closest words to the array\n",
    "    arr = np.append(arr, np.array([model[word]]), axis=0) \n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model[wrd_score[0]] \n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "    # find tsne coords for 2 dimensions\n",
    "    tsne = TSNE(n_components=2, random_state=0) \n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    # display scatter plot plt.scatter(x_coords, y_coords)\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005) \n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005) \n",
    "    plt.title(f'Words closest to: {word}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42668d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_closestwords_tsnescatterplot(word_vectors, \"sccm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98958de",
   "metadata": {},
   "source": [
    "**Interactive Visualisation using bokeh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da8e155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import push_notebook, output_notebook \n",
    "from bokeh.models import ColumnDataSource, LabelSet \n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import push_notebook, output_notebook \n",
    "from bokeh.models import ColumnDataSource, LabelSet \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bf7b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''makes an interactive scatter plot with text labels for each point'''\n",
    "def interactive_tsne(text_labels, tsne_array):\n",
    "    # Define a dataframe to be used by bokeh context\n",
    "    bokeh_df = pd.DataFrame(tsne_array, text_labels, columns=['x','y']) \n",
    "    bokeh_df['text_labels'] = bokeh_df.index\n",
    "# interactive controls to include to the plot\n",
    "    TOOLS=\"hover, zoom_in, zoom_out, box_zoom, undo, redo, reset, box_select\" \n",
    "    p = figure(tools=TOOLS, plot_width=700, plot_height=700)\n",
    "# define data source for the plot\n",
    "    source = ColumnDataSource(bokeh_df)\n",
    "# scatter plot\n",
    "    p.scatter('x', 'y', source=source, fill_alpha=0.6, fill_color=\"#8724B5\", line_color=None)\n",
    "# text labels\n",
    "    labels = LabelSet(x='x', y='y', text='text_labels', y_offset=8, text_font_size=\"8pt\", text_color=\"#555555\", source=source, text_align='center')\n",
    "    p.add_layout(labels)\n",
    "# show plot inline\n",
    "    output_notebook()\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae9dad0",
   "metadata": {},
   "source": [
    "## Data Prepreocessing and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52472974",
   "metadata": {},
   "source": [
    "### Training my own Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2173e",
   "metadata": {},
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf2e6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv(\"./dataset/job.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(lambda x:x.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4efdf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_topword_by_label(df, label_colum, to_colum):\n",
    "    df[to_colum] = \"\"\n",
    "    for k in df[label_colum].value_counts().keys():\n",
    "\n",
    "        df_tmp = df[df[label_colum]==k]\n",
    "        tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False)    \n",
    "        tfidf_matrix = tfidf.fit_transform(df_tmp['job_description'])\n",
    "        xlabels = tfidf.get_feature_names_out()\n",
    "        assert tfidf_matrix.shape[0] == len(df_tmp)\n",
    "\n",
    "        for idx, row in zip(df_tmp.index, tfidf_matrix):\n",
    "            \n",
    "            row = row.toarray()[0].ravel()\n",
    "            top_idx = row.argsort()[-10:][::-1]\n",
    "            top_words = [xlabels[i] for i in top_idx]\n",
    "\n",
    "            df[to_colum][idx] = top_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6456c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_topword_by_label(df, label_colum='job_type', to_colum='10words_type')\n",
    "gene_topword_by_label(df, label_colum='category', to_colum='10words_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1058e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    20757\n",
       "test      5932\n",
       "val       2965\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import split_by_jobtype\n",
    "proportion = [0.7, 0.10, 0.20]\n",
    "df = split_by_jobtype(df, proportion)\n",
    "df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "925c0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset/job_prapare.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63621680",
   "metadata": {},
   "source": [
    "## Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45383f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/job_prapare.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(eval)\n",
    "df['10words_type']=df['10words_type'].apply(eval)\n",
    "df['10words_category']=df['10words_category'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "276f87e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/liugensheng/OneDrive - The University of Western Australia/2022 sem1/CITS4012 NLP/project2',\n",
       " '/Users/liugensheng/miniconda3/lib/python39.zip',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/liugensheng/miniconda3/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95449d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_text_vectors = [b['text_vector'] for b in batch]\n",
    "    batch_labels = [b['label'] for b in batch]\n",
    "\n",
    "\n",
    "    batch_text_vectors = torch.tensor(np.stack(batch_text_vectors))\n",
    "    batch_labels = torch.tensor(np.stack(batch_labels))\n",
    "\n",
    "\n",
    "    batch_data = {\n",
    "        'batch_text_vectors': batch_text_vectors,\n",
    "        'batch_labels': batch_labels\n",
    "    }\n",
    "\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f529002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mydataset import JobVectorizer, JobDatasetOnehot, JobDatasetMyembedding, JobDatasetPretrainembedding\n",
    "text_column = \"10words_type\"\n",
    "label_column = \"job_type\"\n",
    "label_nums = len(df[label_column].value_counts())\n",
    "\n",
    "train_df = df[df.split=='train'].copy().reset_index(drop=True)\n",
    "val_df = df[df.split=='val'].copy().reset_index(drop=True)\n",
    "test_df = df[df.split=='test'].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d64af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobvectorizer = JobVectorizer.from_dataframe(df, text_column=text_column, cutoff=10)\n",
    "\n",
    "jobtype_onehot_train = JobDatasetOnehot(train_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n",
    "jobtype_onehot_val = JobDatasetOnehot(val_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n",
    "jobtype_onehot_test = JobDatasetOnehot(test_df, vectorizer=jobvectorizer, text_column=text_column, label_column=label_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c41dea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "my_embedding = KeyedVectors.load(\"./dataset/my_embedding\", mmap='r')\n",
    "jobtype_myembedding_train = JobDatasetMyembedding(train_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)\n",
    "jobtype_myembedding_val = JobDatasetMyembedding(val_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)\n",
    "jobtype_myembedding_test = JobDatasetMyembedding(test_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62462754",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtype_pretrainembedding_train = JobDatasetPretrainembedding(train_df, text_column=text_column, label_column=label_column)\n",
    "jobtype_pretrainembedding_val = JobDatasetPretrainembedding(val_df, text_column=text_column, label_column=label_column)\n",
    "jobtype_pretrainembedding_test = JobDatasetPretrainembedding(test_df, text_column=text_column, label_column=label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182df79",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b655378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad24c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "cores = 16\n",
    "model = Word2Vec(min_count=1, \n",
    "                 window=2, vector_size=100, sample=6e-5, alpha=0.03, min_alpha=0.0007, negative=20, workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a2f10",
   "metadata": {},
   "source": [
    "**Comparing the purposely trained and the pre-trained vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0763a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vsphere', 0.8840079307556152),\n",
       " ('vmware', 0.8793255090713501),\n",
       " ('soe', 0.8749751448631287),\n",
       " ('virtualis', 0.8664376139640808),\n",
       " ('unix', 0.864485502243042),\n",
       " ('hyperv', 0.8633731603622437),\n",
       " ('powershel', 0.8550437688827515),\n",
       " ('scom', 0.8535946607589722),\n",
       " ('mysql', 0.8357590436935425),\n",
       " ('dn', 0.8356968760490417)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our trained domain specific embeddings\n",
    "word_vectors.most_similar(positive=[\"sccm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "028afe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('redhat', 0.939782440662384),\n",
       " ('nginx', 0.9359487891197205),\n",
       " ('cloudform', 0.913392186164856),\n",
       " ('scom', 0.9022396802902222),\n",
       " ('babel', 0.8975291848182678),\n",
       " ('elasticsearch', 0.8940725326538086),\n",
       " ('netscal', 0.8929364681243896),\n",
       " ('xen', 0.8927617073059082),\n",
       " ('kafka', 0.8914523720741272),\n",
       " ('openvswitchcontrailnsxnuagenfv', 0.8912717700004578)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrained embeddings\n",
    "word_vectors.most_similar(positive=[\"ubuntu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce503f",
   "metadata": {},
   "source": [
    "## Task 1: Binary Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93492096",
   "metadata": {},
   "source": [
    "### 3.1 Feed-forward Neural Netword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "43ee240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from models import JobtypeClassifier_FeedForward, JobtypeClassifier_Conv1d\n",
    "from utils import compute_accuracy, train_engin, test_engine, make_train_state\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2798d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb2241",
   "metadata": {},
   "source": [
    "**Data and path information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1d348944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    batch_size=128,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=20,\n",
    "    seed=1212,\n",
    "    device=None,\n",
    "    loss_func=None,\n",
    "    optimizer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f23115",
   "metadata": {},
   "source": [
    "**Define the model and train**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34101591",
   "metadata": {},
   "source": [
    "*`Build,train and compare the performance of the following models on Task 1, can switch among three embeddings (one-hot, pre-trained, domain specific). First create a baseline using the top 10 words only with a Feed-forward Neural Network model.Then use the top 10 words only with a CNN Conv1d based model. See Lab 09 for coding examples. Lastly, the full job description as input for a CNN Conv1d based model.`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361c555",
   "metadata": {},
   "source": [
    "**text--10word/job_description; embedding--onehot/my_embedding/pretrain embedding; model--feed_forward/conv1d**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d7307d",
   "metadata": {},
   "source": [
    "**`model 1: text--10word, embedding--onehot, model--feed_forward`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ae69b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "state_jobtype_feedforward = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_onehot_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_onehot_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_onehot_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model\n",
    "feature_len = len(jobvectorizer.text_vocab)\n",
    "model_jobtype_feedforward = JobtypeClassifier_FeedForward(num_features=feature_len) \n",
    "model_jobtype_feedforward = model_jobtype_feedforward.to(args.device)\n",
    "\n",
    "# loss and optimizer\n",
    "args.loss_func = nn.CrossEntropyLoss()\n",
    "args.optimizer = optim.Adam(model_jobtype_feedforward.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d4ff99e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6295229712146924 67.776803973123\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6118717181185882 66.14583333333333\n",
      "\n",
      "TRAIN: 1|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5777978948288899 69.33291338007598\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 50.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.592289333542188 68.10205853174602\n",
      "\n",
      "TRAIN: 2|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5535378437832088 71.10539000876423\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5798386124273142 68.81820436507935\n",
      "\n",
      "TRAIN: 3|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 47.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5349751460405945 73.02918675138768\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 50.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714975992838541 70.19469246031746\n",
      "\n",
      "TRAIN: 4|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5215526171988507 74.20688175576977\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5653733250995476 71.27201140873015\n",
      "\n",
      "TRAIN: 5|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5107075372722254 75.44825445515629\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5618944987654686 71.63008432539681\n",
      "\n",
      "TRAIN: 6|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501478845904942 75.88349948875258\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5585965774953365 71.76029265873015\n",
      "\n",
      "TRAIN: 7|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4933488736489069 76.49745289219983\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5565326648453871 72.11836557539682\n",
      "\n",
      "TRAIN: 8|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4861179418359066 77.11711218229625\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 50.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5553731918334962 72.05326140873015\n",
      "\n",
      "TRAIN: 9|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 47.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4803874754101219 77.31658997955012\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5542971106866995 72.28422619047619\n",
      "\n",
      "TRAIN: 10|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47492477023528407 77.7100679228747\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5531105324625969 72.74305555555556\n",
      "\n",
      "TRAIN: 11|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 48.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46999829075087807 78.05127994449316\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 52.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5530673824250698 73.1693328373016\n",
      "\n",
      "TRAIN: 12|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 47.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46609262399878226 78.34707310838446\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 49.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5540228473643461 73.03912450396827\n",
      "\n",
      "TRAIN: 13|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 44.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4617278934256431 78.57279798422438\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 49.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5541944851477941 72.97402033730158\n",
      "\n",
      "TRAIN: 14|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 46.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4583112357949919 78.81153228162432\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 50.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546979233622551 73.13678075396827\n",
      "\n",
      "TRAIN: 15|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4537725841706516 79.31228089395265\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 52.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5557490636905035 73.0716765873016\n",
      "\n",
      "TRAIN: 16|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 49.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45077470200924796 79.28785969909434\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 52.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5567581666012607 72.94146825396824\n",
      "\n",
      "TRAIN: 17|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44724065942998315 79.49966221151038\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 49.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5569788205126921 73.0716765873016\n",
      "\n",
      "TRAIN: 18|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 45.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4456185312724553 79.59940111013736\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 51.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5578529424965382 73.1693328373016\n",
      "\n",
      "TRAIN: 19|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 46.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44284814303638026 79.71443178498394\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 49.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5593290217220782 73.13678075396825\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 49.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_index': 19, 'train_loss': [0.6295229712146924, 0.5777978948288899, 0.5535378437832088, 0.5349751460405945, 0.5215526171988507, 0.5107075372722254, 0.501478845904942, 0.4933488736489069, 0.4861179418359066, 0.4803874754101219, 0.47492477023528407, 0.46999829075087807, 0.46609262399878226, 0.4617278934256431, 0.4583112357949919, 0.4537725841706516, 0.45077470200924796, 0.44724065942998315, 0.4456185312724553, 0.44284814303638026], 'train_acc': [67.776803973123, 69.33291338007598, 71.10539000876423, 73.02918675138768, 74.20688175576977, 75.44825445515629, 75.88349948875258, 76.49745289219983, 77.11711218229625, 77.31658997955012, 77.7100679228747, 78.05127994449316, 78.34707310838446, 78.57279798422438, 78.81153228162432, 79.31228089395265, 79.28785969909434, 79.49966221151038, 79.59940111013736, 79.71443178498394], 'val_loss': [0.6118717181185882, 0.592289333542188, 0.5798386124273142, 0.5714975992838541, 0.5653733250995476, 0.5618944987654686, 0.5585965774953365, 0.5565326648453871, 0.5553731918334962, 0.5542971106866995, 0.5531105324625969, 0.5530673824250698, 0.5540228473643461, 0.5541944851477941, 0.5546979233622551, 0.5557490636905035, 0.5567581666012607, 0.5569788205126921, 0.5578529424965382, 0.5593290217220782], 'val_acc': [66.14583333333333, 68.10205853174602, 68.81820436507935, 70.19469246031746, 71.27201140873015, 71.63008432539681, 71.76029265873015, 72.11836557539682, 72.05326140873015, 72.28422619047619, 72.74305555555556, 73.1693328373016, 73.03912450396827, 72.97402033730158, 73.13678075396827, 73.0716765873016, 72.94146825396824, 73.0716765873016, 73.1693328373016, 73.13678075396825], 'test_loss': 0.5593290217220782, 'test_acc': 73.13678075396825}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_jobtype_feedforward, train_dataloader, val_dataloader, state_jobtype_feedforward)\n",
    "test_engine(args, model_jobtype_feedforward, test_dataloader, state_jobtype_feedforward)\n",
    "print(state_jobtype_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef12b6",
   "metadata": {},
   "source": [
    "**`acc:73.13`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdace98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d82afbb",
   "metadata": {},
   "source": [
    "**`model 2: text--10word, embedding--my_embedding, model--feed_forward`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d7f47d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "state_jobtype_myembedding_feedforward = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_myembedding_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_myembedding_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_myembedding_test, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model\n",
    "feature_len = 10 * 100\n",
    "model_jobtype_myembedding_feedforward = JobtypeClassifier_FeedForward(num_features=feature_len) \n",
    "model_jobtype_myembedding_feedforward = model_jobtype_myembedding_feedforward.to(args.device)\n",
    "\n",
    "# loss and optimizer\n",
    "args.loss_func = nn.CrossEntropyLoss()\n",
    "args.optimizer = optim.Adam(model_jobtype_feedforward.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "37e2ef21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 121.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8276882522676621 47.93264314928423\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 133.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 1|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 127.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8269210944146465 47.95706434414257\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 124.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 2|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 121.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8261825778733003 48.079170318434095\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 129.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 3|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 123.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266007271281052 47.95706434414257\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 118.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 4|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 123.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8277762320144048 48.00590673385918\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 142.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 5|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 123.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8276468175320539 47.90822195442595\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 142.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 6|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 123.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8276291134898646 47.932643149284246\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 135.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 7|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 124.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8271186172596513 47.981485539000886\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 138.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 8|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 119.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826739840712284 47.98148553900087\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 131.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 9|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 125.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8271021923404532 47.95706434414255\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 139.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 10|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 122.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8262554403463018 48.07917031843412\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 132.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 11|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 125.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826842717963494 48.05474912357582\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 135.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 12|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 123.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8274018022180335 47.90822195442594\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 141.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 13|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 124.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8262941961639497 48.0547491235758\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 140.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 14|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 125.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827751425146325 48.00590673385918\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 136.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 15|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 121.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8274136803632862 47.98148553900089\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 145.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 16|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 127.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8279602860380542 47.90822195442593\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 133.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 17|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 124.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265232663213112 48.00590673385919\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 132.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 18|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 123.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827056090158919 47.932643149284246\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 145.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n",
      "TRAIN: 19|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 129.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8272875481587978 47.932643149284274\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 134.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8308849061528841 47.20517113095238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:00, 137.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_index': 19, 'train_loss': [0.8276882522676621, 0.8269210944146465, 0.8261825778733003, 0.8266007271281052, 0.8277762320144048, 0.8276468175320539, 0.8276291134898646, 0.8271186172596513, 0.826739840712284, 0.8271021923404532, 0.8262554403463018, 0.826842717963494, 0.8274018022180335, 0.8262941961639497, 0.827751425146325, 0.8274136803632862, 0.8279602860380542, 0.8265232663213112, 0.827056090158919, 0.8272875481587978], 'train_acc': [47.93264314928423, 47.95706434414257, 48.079170318434095, 47.95706434414257, 48.00590673385918, 47.90822195442595, 47.932643149284246, 47.981485539000886, 47.98148553900087, 47.95706434414255, 48.07917031843412, 48.05474912357582, 47.90822195442594, 48.0547491235758, 48.00590673385918, 47.98148553900089, 47.90822195442593, 48.00590673385919, 47.932643149284246, 47.932643149284274], 'val_loss': [0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841, 0.8308849061528841], 'val_acc': [47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238, 47.20517113095238], 'test_loss': 0.8246233894469891, 'test_acc': 47.78922872340425}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_jobtype_myembedding_feedforward, train_dataloader, val_dataloader, state_jobtype_myembedding_feedforward)\n",
    "test_engine(args, model_jobtype_myembedding_feedforward, test_dataloader, state_jobtype_myembedding_feedforward)\n",
    "print(state_jobtype_myembedding_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fc2b9",
   "metadata": {},
   "source": [
    "**`acc:47.78`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e48937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad5807dd",
   "metadata": {},
   "source": [
    "**`model 3: text--10word, embedding--pretain embedding, model--feed_forward`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8641253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "state_jobtype_pretrainembedding_feedforward = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_pretrainembedding_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_pretrainembedding_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_pretrainembedding_test, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "feature_len = 10 * 100\n",
    "model_jobtype_pretrainembedding_feedforward = JobtypeClassifier_FeedForward(num_features=feature_len) \n",
    "model_jobtype_pretrainembedding_feedforward = model_jobtype_pretrainembedding_feedforward.to(args.device)\n",
    "\n",
    "# loss and optimizer\n",
    "args.loss_func = nn.CrossEntropyLoss()\n",
    "args.optimizer = optim.Adam(model_jobtype_feedforward.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1f8a5e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 133.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7149437954820742 46.98021654981012\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 134.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 1|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 126.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7148695866023104 47.00463774466841\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 134.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 2|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 132.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7152765751616357 46.85811057551856\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 144.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 3|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 127.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7147179787144343 47.029058939526735\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 145.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 4|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 128.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7151365027837226 46.98021654981009\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 135.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 5|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 127.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7148700096855869 46.98021654981012\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 145.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 6|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 131.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7148522913821638 47.02905893952673\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 132.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 7|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 138.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7147232071022311 46.98021654981011\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 150.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 8|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 139.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714957369251485 46.9557953549518\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 146.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 9|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 137.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7150945897482656 46.931374160093476\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 150.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 10|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 138.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7147666599852905 47.00463774466843\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 151.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 11|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 137.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7147593041139148 46.980216549810116\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 134.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 12|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 128.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146932921526625 47.029058939526735\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 138.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 13|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 132.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7151051609794055 46.931374160093505\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 134.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 14|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 128.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7149191732786916 47.00463774466838\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 138.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 15|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 131.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7150053623263822 46.93137416009349\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 147.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 16|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 133.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7151716501434886 46.88253177037686\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 145.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 17|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 131.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146797041220169 47.02905893952672\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 144.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 18|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 133.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146907108693035 46.9802165498101\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 146.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n",
      "TRAIN: 19|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 134.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7148788966284211 46.98021654981009\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 143.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131715267896652 47.32607886904761\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:00, 144.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_index': 19, 'train_loss': [0.7149437954820742, 0.7148695866023104, 0.7152765751616357, 0.7147179787144343, 0.7151365027837226, 0.7148700096855869, 0.7148522913821638, 0.7147232071022311, 0.714957369251485, 0.7150945897482656, 0.7147666599852905, 0.7147593041139148, 0.7146932921526625, 0.7151051609794055, 0.7149191732786916, 0.7150053623263822, 0.7151716501434886, 0.7146797041220169, 0.7146907108693035, 0.7148788966284211], 'train_acc': [46.98021654981012, 47.00463774466841, 46.85811057551856, 47.029058939526735, 46.98021654981009, 46.98021654981012, 47.02905893952673, 46.98021654981011, 46.9557953549518, 46.931374160093476, 47.00463774466843, 46.980216549810116, 47.029058939526735, 46.931374160093505, 47.00463774466838, 46.93137416009349, 46.88253177037686, 47.02905893952672, 46.9802165498101, 46.98021654981009], 'val_loss': [0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652, 0.7131715267896652], 'val_acc': [47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761, 47.32607886904761], 'test_loss': 0.7140394309733777, 'test_acc': 47.882918278529985}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_jobtype_pretrainembedding_feedforward, train_dataloader, val_dataloader, state_jobtype_pretrainembedding_feedforward)\n",
    "test_engine(args, model_jobtype_pretrainembedding_feedforward, test_dataloader, state_jobtype_pretrainembedding_feedforward)\n",
    "print(state_jobtype_pretrainembedding_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af3465",
   "metadata": {},
   "source": [
    "**`acc:47.88`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f7cbbd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    batch_size=128,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=5,\n",
    "    seed=1234,\n",
    "    num_channels = 1,\n",
    "    hidden_dim = 100,\n",
    "    dropout_p = 0.1,\n",
    "    device=None,\n",
    "    loss_func=None,\n",
    "    optimizer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5108b7",
   "metadata": {},
   "source": [
    "**`model 4: text--10word, embedding--onehot, model--conv1d`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ab964",
   "metadata": {},
   "source": [
    "*do not exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "31d7aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "state_jobtype_conv1d = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_onehot_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_onehot_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_onehot_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model\n",
    "feature_len = len(jobvectorizer.text_vocab)\n",
    "model_jobtype_cov1d = JobtypeClassifier_Conv1d(embedding_size=feature_len, num_channels=args.num_channels,hidden_dim=args.hidden_dim, label_nums=2, dropout_p=args.dropout_p)\n",
    "\n",
    "model_jobtype_cov1d = model_jobtype_cov1d.to(args.device)\n",
    "\n",
    "# loss and optimizer\n",
    "args.loss_func = nn.BCEWithLogitsLoss()\n",
    "args.optimizer = optim.Adam(model_jobtype_cov1d.parameters(), lr=args.learning_rate)\n",
    "'''\n",
    "t = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bba0b",
   "metadata": {},
   "source": [
    "**Visualizing Results Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "75ff92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(perceptron, x_data, y_truth, n_samples=1000, ax=None,epoch=None,title='', levels=[0.3, 0.4, 0.5], linestyles=['--', '-', '--']): \n",
    "    y_pred = perceptron(x_data)\n",
    "    y_pred = (y_pred > 0.5).long().data.numpy().astype(np.int32) \n",
    "    x_data = x_data.data.numpy()\n",
    "    y_truth = y_truth.data.numpy().astype(np.int32) \n",
    "    n_classes = 2\n",
    "    all_x = [[] for _ in range(n_classes)] \n",
    "    all_colors = [[] for _ in range(n_classes)]\n",
    "    colors = ['black', 'white'] \n",
    "    markers = ['o', '*']\n",
    "    for x_i, y_pred_i, y_true_i in zip(x_data, y_pred, y_truth): \n",
    "        all_x[y_true_i].append(x_i)\n",
    "        if y_pred_i == y_true_i:\n",
    "            all_colors[y_true_i].append(\"white\") \n",
    "        else:\n",
    "            all_colors[y_true_i].append(\"black\") \n",
    "            #all_colors[y_true_i].append(colors[y_pred_i])\n",
    "    all_x = [np.stack(x_list) for x_list in all_x] \n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "        \n",
    "    for x_list, color_list, marker in zip(all_x, all_colors, markers): \n",
    "        ax.scatter(x_list[:, 0], x_list[:, 1], edgecolor=\"black\", marker=marker, facecolor=color_list, s=300)\n",
    "    xlim = (min([x_list[:,0].min() for x_list in all_x]), max([x_list[:,0].max() for x_list in all_x])) \n",
    "    ylim = (min([x_list[:,1].min() for x_list in all_x]), max([x_list[:,1].max() for x_list in all_x])) \n",
    "    # hyperplane\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30) \n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    \n",
    "    Z = perceptron(torch.tensor(xy, dtype=torch.float32)).detach().numpy().reshape(XX.shape)\n",
    "    ax.contour(XX, YY, Z, colors='k', levels=levels, linestyles=linestyles)\n",
    "    plt.suptitle(title)\n",
    "    if epoch is not None:\n",
    "        plt.text(xlim[0], ylim[1], \"Epoch = {}\".format(str(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b198c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cd3d1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "class JobtypeClassifier_Conv1d(nn.Module):\n",
    "    def __init__(self, embedding_size, num_channels, hidden_dim, label_nums, dropout_p):\n",
    "\n",
    "        super(JobtypeClassifier_Conv1d, self).__init__()\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_size,\n",
    "            out_channels=num_channels, kernel_size=3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
    "            kernel_size=3, stride=2, padding=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
    "            kernel_size=3, stride=2,  padding=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
    "            kernel_size=3),\n",
    "            nn.ELU()\n",
    "            )\n",
    "\n",
    "        self.drop = nn.Dropout(dropout_p)\n",
    "        self.drop2 = nn.Dropout(dropout_p)\n",
    "        self.pool = nn.AvgPool1d(2)\n",
    "        self.rlue = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(num_channels, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, label_nums)\n",
    "        \n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "\n",
    "        x_embedded = x_in.permute(0, 2, 1)\n",
    "        features = self.convnet(x_embedded)\n",
    "        # print(features.shape)\n",
    "\n",
    "\n",
    "        features = self.pool(features).squeeze(dim=2)\n",
    "        features = self.drop(features)\n",
    "        features = self.fc1(features)\n",
    "        features = self.drop2(features)\n",
    "\n",
    "        features = self.rlue(features)\n",
    "        prediction_vector = self.fc2(features).squeeze(dim=1)\n",
    "\n",
    "        if apply_softmax:\n",
    "             prediction_vector = F.softmax(prediction_vector, dim=1)\n",
    "             \n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416857f6",
   "metadata": {},
   "source": [
    "## Conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07b9e3",
   "metadata": {},
   "source": [
    "**Initial setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e8bef649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    batch_size=128,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=20,\n",
    "    seed=1234,\n",
    "    num_channels = 1,\n",
    "    hidden_dim = 100,\n",
    "    dropout_p = 0.1,\n",
    "    device=None,\n",
    "    loss_func=None,\n",
    "    optimizer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2012b6a7",
   "metadata": {},
   "source": [
    "**`model 5: text--10word, embedding--my_embedding, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fc1b0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5\n",
    "state_jobtype_myembedding_conv1d = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_myembedding_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_myembedding_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_myembedding_test, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model\n",
    "model_jobtype_myembedding_conv1d = JobtypeClassifier_Conv1d(embedding_size=100, num_channels=10, \n",
    "                                            hidden_dim=args.hidden_dim, label_nums=2, dropout_p=args.dropout_p)\n",
    "model_jobtype_myembedding_conv1d = model_jobtype_myembedding_conv1d.to(args.device)\n",
    "\n",
    "# loss and optimizer\n",
    "args.loss_func = nn.CrossEntropyLoss()\n",
    "args.optimizer = optim.Adam(model_jobtype_myembedding_conv1d.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f33a7e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 80.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6157159607834611 67.34726482617585\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 115.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6089040065805117 66.9038318452381\n",
      "\n",
      "TRAIN: 1|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 80.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5863464416170412 69.50979586619925\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 111.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5995223447680472 67.94549851190477\n",
      "\n",
      "TRAIN: 2|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 80.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5705989813146419 71.03166995325738\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 119.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5929161173601945 68.72984871031747\n",
      "\n",
      "TRAIN: 3|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 82.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.556940156989303 72.03476482617594\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 118.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5880269433061283 69.0584697420635\n",
      "\n",
      "TRAIN: 4|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 83.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5473520497968589 72.80300540461585\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 117.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5781549761692684 70.86433531746033\n",
      "\n",
      "TRAIN: 5|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 81.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5382100120643899 73.41513292433538\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 111.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581816293299198 69.98232886904762\n",
      "\n",
      "TRAIN: 6|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 79.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5323962413825868 74.05122516798134\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 111.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5753918935855229 69.9466765873016\n",
      "\n",
      "TRAIN: 7|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 80.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5245969306471887 74.28653593339178\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 110.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5829738254348436 70.07068452380952\n",
      "\n",
      "TRAIN: 8|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 78.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5193177304384897 74.76058099620214\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 105.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5769731476902961 70.63957093253967\n",
      "\n",
      "TRAIN: 9|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 80.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5125011569517525 75.35673203330414\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 108.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572075874855121 71.29371279761905\n",
      "\n",
      "TRAIN: 10|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 80.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5041780349301417 75.77029469763366\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 103.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5766854695975782 71.39136904761904\n",
      "\n",
      "TRAIN: 11|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 80.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5009563316596798 75.81822414548637\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 112.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5734112200637658 70.79303075396825\n",
      "\n",
      "TRAIN: 12|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 80.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4942903633863649 76.34750219106047\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 115.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5977946569522221 70.75737847222224\n",
      "\n",
      "TRAIN: 13|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:02, 81.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49107847257625825 76.63987182296229\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 110.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5799537884692351 71.16350446428571\n",
      "\n",
      "TRAIN: 14|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 83.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48335870954156646 76.97286736780603\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 119.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.584692823390166 71.58668154761904\n",
      "\n",
      "TRAIN: 15|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 83.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4790883276360168 77.24560874963477\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 117.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5851432618995508 71.08909970238098\n",
      "\n",
      "TRAIN: 16|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 83.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47526792423125447 77.59983019281331\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 118.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5872285390893619 70.70467509920634\n",
      "\n",
      "TRAIN: 17|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 83.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47156628454389754 77.71828439964942\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 118.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5922264568507671 71.13095238095238\n",
      "\n",
      "TRAIN: 18|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 83.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46608189607690464 77.96546340929011\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 119.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5947674103081226 71.19605654761904\n",
      "\n",
      "TRAIN: 19|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 84.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46433810880579096 78.24299773590417\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 119.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6028777857621511 70.82868303571426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:00, 117.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_index': 19, 'train_loss': [0.6157159607834611, 0.5863464416170412, 0.5705989813146419, 0.556940156989303, 0.5473520497968589, 0.5382100120643899, 0.5323962413825868, 0.5245969306471887, 0.5193177304384897, 0.5125011569517525, 0.5041780349301417, 0.5009563316596798, 0.4942903633863649, 0.49107847257625825, 0.48335870954156646, 0.4790883276360168, 0.47526792423125447, 0.47156628454389754, 0.46608189607690464, 0.46433810880579096], 'train_acc': [67.34726482617585, 69.50979586619925, 71.03166995325738, 72.03476482617594, 72.80300540461585, 73.41513292433538, 74.05122516798134, 74.28653593339178, 74.76058099620214, 75.35673203330414, 75.77029469763366, 75.81822414548637, 76.34750219106047, 76.63987182296229, 76.97286736780603, 77.24560874963477, 77.59983019281331, 77.71828439964942, 77.96546340929011, 78.24299773590417], 'val_loss': [0.6089040065805117, 0.5995223447680472, 0.5929161173601945, 0.5880269433061283, 0.5781549761692684, 0.581816293299198, 0.5753918935855229, 0.5829738254348436, 0.5769731476902961, 0.572075874855121, 0.5766854695975782, 0.5734112200637658, 0.5977946569522221, 0.5799537884692351, 0.584692823390166, 0.5851432618995508, 0.5872285390893619, 0.5922264568507671, 0.5947674103081226, 0.6028777857621511], 'val_acc': [66.9038318452381, 67.94549851190477, 68.72984871031747, 69.0584697420635, 70.86433531746033, 69.98232886904762, 69.9466765873016, 70.07068452380952, 70.63957093253967, 71.29371279761905, 71.39136904761904, 70.79303075396825, 70.75737847222224, 71.16350446428571, 71.58668154761904, 71.08909970238098, 70.70467509920634, 71.13095238095238, 71.19605654761904, 70.82868303571426], 'test_loss': 0.6115154186461835, 'test_acc': 70.58450193423597}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_jobtype_myembedding_conv1d, train_dataloader, val_dataloader, state_jobtype_myembedding_conv1d)\n",
    "test_engine(args, model_jobtype_myembedding_conv1d, test_dataloader, state_jobtype_myembedding_conv1d)\n",
    "print(state_jobtype_myembedding_conv1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ceb0c",
   "metadata": {},
   "source": [
    "**`acc:70.58`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60599a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbc0adeb",
   "metadata": {},
   "source": [
    "**`model 6: text--10word, embedding--pretrain embedding, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c3028826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6\n",
    "state_jobtype_pretrainembedding_conv1d = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_pretrainembedding_train, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_pretrainembedding_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_pretrainembedding_test, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model\n",
    "model_jobtype_pretrainembedding_conv1d = JobtypeClassifier_Conv1d(embedding_size=100, num_channels=10, \n",
    "                                            hidden_dim=args.hidden_dim, label_nums=2, dropout_p=args.dropout_p)\n",
    "model_jobtype_pretrainembedding_conv1d = model_jobtype_pretrainembedding_conv1d.to(args.device)\n",
    "\n",
    "# loss and optimizer\n",
    "args.loss_func = nn.CrossEntropyLoss()\n",
    "args.optimizer = optim.Adam(model_jobtype_pretrainembedding_conv1d.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "708c37e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6272878668790945 67.33334246275199\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 124.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6273286466797193 65.49479166666667\n",
      "\n",
      "TRAIN: 1|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 85.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60685867107719 68.05274065147535\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624539123227199 65.85286458333333\n",
      "\n",
      "TRAIN: 2|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 85.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5991626806054375 68.71667762196905\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216932100554305 65.91796875000001\n",
      "\n",
      "TRAIN: 3|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 87.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5935820410588037 69.48149466841949\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 124.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6225106728573641 66.2140376984127\n",
      "\n",
      "TRAIN: 4|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5893660154810713 69.8065019719544\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6230520258347193 66.34424603174602\n",
      "\n",
      "TRAIN: 5|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5831297652487372 70.45491893076247\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 122.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6238237706323465 66.53645833333331\n",
      "\n",
      "TRAIN: 6|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 85.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5808112882763334 70.61514022787028\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6261618336041769 66.64031498015873\n",
      "\n",
      "TRAIN: 7|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5762591857485975 70.91800869120654\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 122.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626045590887467 66.54575892857142\n",
      "\n",
      "TRAIN: 8|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5732390655696026 71.52146326321937\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6224614245196183 66.61086309523807\n",
      "\n",
      "TRAIN: 9|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 87.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5687249699618919 71.75859991235752\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6328774789969127 67.29445684523807\n",
      "\n",
      "TRAIN: 10|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5664193429098541 72.2762379491674\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 114.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6282442423204581 66.83872767857142\n",
      "\n",
      "TRAIN: 11|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 87.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5634055687971642 72.46658632778264\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 124.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6305623662968477 66.5132068452381\n",
      "\n",
      "TRAIN: 12|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 87.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5598859382919008 72.76808537832305\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 124.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6311881244182586 67.23245287698413\n",
      "\n",
      "TRAIN: 13|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5575571204621373 73.05132559158633\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 122.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6360117134948572 66.93638392857143\n",
      "\n",
      "TRAIN: 14|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5540318198364937 73.38774466841957\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6311710091928642 67.45721726190477\n",
      "\n",
      "TRAIN: 15|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5498845782016685 73.64519427402867\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 124.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630567600329717 67.52232142857142\n",
      "\n",
      "TRAIN: 16|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 85.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5479713347426223 74.02999926964652\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 122.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6311134584248066 67.58742559523809\n",
      "\n",
      "TRAIN: 17|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 85.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5455536072605228 74.13932405784395\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 122.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6420445181429385 67.58432539682543\n",
      "\n",
      "TRAIN: 18|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 85.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.540864942995317 74.36071245983058\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6380160674452782 67.22625248015872\n",
      "\n",
      "TRAIN: 19|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 86.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5366209081711206 74.81512927256796\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 123.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6383417397737503 67.29135664682539\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:00, 122.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_index': 19, 'train_loss': [0.6272878668790945, 0.60685867107719, 0.5991626806054375, 0.5935820410588037, 0.5893660154810713, 0.5831297652487372, 0.5808112882763334, 0.5762591857485975, 0.5732390655696026, 0.5687249699618919, 0.5664193429098541, 0.5634055687971642, 0.5598859382919008, 0.5575571204621373, 0.5540318198364937, 0.5498845782016685, 0.5479713347426223, 0.5455536072605228, 0.540864942995317, 0.5366209081711206], 'train_acc': [67.33334246275199, 68.05274065147535, 68.71667762196905, 69.48149466841949, 69.8065019719544, 70.45491893076247, 70.61514022787028, 70.91800869120654, 71.52146326321937, 71.75859991235752, 72.2762379491674, 72.46658632778264, 72.76808537832305, 73.05132559158633, 73.38774466841957, 73.64519427402867, 74.02999926964652, 74.13932405784395, 74.36071245983058, 74.81512927256796], 'val_loss': [0.6273286466797193, 0.624539123227199, 0.6216932100554305, 0.6225106728573641, 0.6230520258347193, 0.6238237706323465, 0.6261618336041769, 0.626045590887467, 0.6224614245196183, 0.6328774789969127, 0.6282442423204581, 0.6305623662968477, 0.6311881244182586, 0.6360117134948572, 0.6311710091928642, 0.630567600329717, 0.6311134584248066, 0.6420445181429385, 0.6380160674452782, 0.6383417397737503], 'val_acc': [65.49479166666667, 65.85286458333333, 65.91796875000001, 66.2140376984127, 66.34424603174602, 66.53645833333331, 66.64031498015873, 66.54575892857142, 66.61086309523807, 67.29445684523807, 66.83872767857142, 66.5132068452381, 67.23245287698413, 66.93638392857143, 67.45721726190477, 67.52232142857142, 67.58742559523809, 67.58432539682543, 67.22625248015872, 67.29135664682539], 'test_loss': 0.6406765954291568, 'test_acc': 67.3809235976789}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_jobtype_pretrainembedding_conv1d, train_dataloader, val_dataloader, state_jobtype_pretrainembedding_conv1d)\n",
    "test_engine(args, model_jobtype_pretrainembedding_conv1d, test_dataloader, state_jobtype_pretrainembedding_conv1d)\n",
    "print(state_jobtype_pretrainembedding_conv1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78711369",
   "metadata": {},
   "source": [
    "**`acc:67.38`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40e92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a14eaed",
   "metadata": {},
   "source": [
    "## Full Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "532927a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/job_prapare.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(eval)\n",
    "df['10words_type']=df['10words_type'].apply(eval)\n",
    "df['10words_category']=df['10words_category'].apply(eval)\n",
    "\n",
    "text_column = \"job_description\"\n",
    "label_column = \"job_type\"\n",
    "label_nums = len(df[label_column].value_counts())\n",
    "\n",
    "train_df = df[df.split=='train'].copy().reset_index(drop=True)\n",
    "val_df = df[df.split=='val'].copy().reset_index(drop=True)\n",
    "test_df = df[df.split=='test'].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe65b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cf340d5",
   "metadata": {},
   "source": [
    "**`model 11: text--job_description, embedding--my_embedding, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e211cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 11\n",
    "from gensim.models import KeyedVectors\n",
    "my_embedding = KeyedVectors.load(\"./dataset/my_embedding\", mmap='r')\n",
    "my_embedding.wv.add_vectors(\"<pad>\", torch.zeros(100))\n",
    "\n",
    "jobtype_myembedding_train_full = JobDatasetMyembedding(train_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_myembedding_val_full = JobDatasetMyembedding(val_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_myembedding_test_full = JobDatasetMyembedding(test_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9872aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    batch_size=128,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=20,\n",
    "    seed=1212,\n",
    "    num_channels = 1,\n",
    "    hidden_dim = 100,\n",
    "    dropout_p = 0.1,\n",
    "    device=None,\n",
    "    loss_func=None,\n",
    "    optimizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "df792a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Model 11\n",
    "\n",
    "    state_jobtype_myembedding_conv1d_full = make_train_state(args) \n",
    "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_dataloader = DataLoader(jobtype_myembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_dataloader = DataLoader(jobtype_myembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(jobtype_myembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # model\n",
    "    model_jobtype_myembedding_conv1d_full = JobtypeClassifier_Conv1d(embedding_size=100, num_channels=128, \n",
    "                                                hidden_dim=args.hidden_dim, label_nums=2, dropout_p=args.dropout_p)\n",
    "    model_jobtype_myembedding_conv1d_full = model_jobtype_myembedding_conv1d_full.to(args.device)\n",
    "\n",
    "    # loss and optimizer\n",
    "    args.loss_func = nn.CrossEntropyLoss()\n",
    "    args.optimizer = optim.Adam(model_jobtype_myembedding_conv1d_full.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a524fe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16384x15 and 128x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [181]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_engin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_jobtype_myembedding_conv1d_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_jobtype_myembedding_conv1d_full\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_engine(args, model_jobtype_myembedding_conv1d_full, test_dataloader, state_jobtype_myembedding_conv1d_full)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(state_jobtype_myembedding_conv1d_full)\n",
      "File \u001b[0;32m~/OneDrive - The University of Western Australia/2022 sem1/CITS4012 NLP/project2/utils.py:131\u001b[0m, in \u001b[0;36mtrain_engin\u001b[0;34m(args, model, train_dataloader, val_dataloader, train_state)\u001b[0m\n\u001b[1;32m    128\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    130\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 131\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(y_pred, labels) \n\u001b[1;32m    133\u001b[0m loss_batch \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [142]\u001b[0m, in \u001b[0;36mJobtypeClassifier_Conv1d.forward\u001b[0;34m(self, x_in, apply_softmax)\u001b[0m\n\u001b[1;32m     36\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(features)\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     37\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(features)\n\u001b[0;32m---> 38\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop2(features)\n\u001b[1;32m     41\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrlue(features)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16384x15 and 128x100)"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_jobtype_myembedding_conv1d_full, train_dataloader, val_dataloader, state_jobtype_myembedding_conv1d_full)\n",
    "test_engine(args, model_jobtype_myembedding_conv1d_full, test_dataloader, state_jobtype_myembedding_conv1d_full)\n",
    "print(state_jobtype_myembedding_conv1d_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca86fe",
   "metadata": {},
   "source": [
    "**acc: 80.00**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970cb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc9bdbd4",
   "metadata": {},
   "source": [
    "**`model 12: text--job_description, embedding--pretrain embedding, model--conv1d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a45ea349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 12\n",
    "\n",
    "jobtype_prainembedding_train_full = JobDatasetPretrainembedding(train_df, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_prainembedding_val_full = JobDatasetPretrainembedding(val_df, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_prainembedding_test_full = JobDatasetPretrainembedding(test_df, text_column=text_column, label_column=label_column, words_len=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0956c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 12\n",
    "\n",
    "state_jobtype_pretrainembedding_conv1d_full = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_prainembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_prainembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_prainembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model\n",
    "model_jobtype_pretrainembedding_conv1d_full = JobtypeClassifier_Conv1d(embedding_size=100, num_channels=128, \n",
    "                                            hidden_dim=args.hidden_dim, label_nums=2, dropout_p=args.dropout_p)\n",
    "model_jobtype_pretrainembedding_conv1d_full = model_jobtype_pretrainembedding_conv1d_full.to(args.device)\n",
    "\n",
    "# loss and optimizer\n",
    "args.loss_func = nn.CrossEntropyLoss()\n",
    "args.optimizer = optim.Adam(model_jobtype_pretrainembedding_conv1d_full.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "114cde25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16384x15 and 128x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [175]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_engin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_jobtype_pretrainembedding_conv1d_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_jobtype_pretrainembedding_conv1d_full\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_engine(args, model_jobtype_pretrainembedding_conv1d_full, test_dataloader, state_jobtype_pretrainembedding_conv1d_full)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(state_jobtype_pretrainembedding_conv1d_full)\n",
      "File \u001b[0;32m~/OneDrive - The University of Western Australia/2022 sem1/CITS4012 NLP/project2/utils.py:131\u001b[0m, in \u001b[0;36mtrain_engin\u001b[0;34m(args, model, train_dataloader, val_dataloader, train_state)\u001b[0m\n\u001b[1;32m    128\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    130\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 131\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(y_pred, labels) \n\u001b[1;32m    133\u001b[0m loss_batch \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [142]\u001b[0m, in \u001b[0;36mJobtypeClassifier_Conv1d.forward\u001b[0;34m(self, x_in, apply_softmax)\u001b[0m\n\u001b[1;32m     36\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(features)\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     37\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(features)\n\u001b[0;32m---> 38\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop2(features)\n\u001b[1;32m     41\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrlue(features)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16384x15 and 128x100)"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_jobtype_pretrainembedding_conv1d_full, train_dataloader, val_dataloader, state_jobtype_pretrainembedding_conv1d_full)\n",
    "test_engine(args, model_jobtype_pretrainembedding_conv1d_full, test_dataloader, state_jobtype_pretrainembedding_conv1d_full)\n",
    "print(state_jobtype_pretrainembedding_conv1d_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3bc53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "484946f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/liugensheng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from mydataset import JobVectorizer, JobDatasetOnehot, JobDatasetMyembedding, JobDatasetPretrainembedding\n",
    "from mydataset import collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import compute_accuracy, train_engin, test_engine, make_train_state\n",
    "import torch.optim as optim \n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "\n",
    "from models import RnnModel1, RnnModel2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cd907823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    batch_size=128,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=50,\n",
    "    seed=1212,\n",
    "    device=None,\n",
    "    loss_func=None,\n",
    "    optimizer=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2f9d1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/job_prapare.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['job_description']=df['job_description'].apply(eval)\n",
    "df['10words_type']=df['10words_type'].apply(eval)\n",
    "df['10words_category']=df['10words_category'].apply(eval)\n",
    "\n",
    "text_column = \"job_description\"\n",
    "label_column = \"category\"\n",
    "label_nums = len(df[label_column].value_counts())\n",
    "\n",
    "train_df = df[df.split=='train'].copy().reset_index(drop=True)\n",
    "val_df = df[df.split=='val'].copy().reset_index(drop=True)\n",
    "test_df = df[df.split=='test'].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "09148564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "my_embedding = KeyedVectors.load(\"./dataset/my_embedding\", mmap='r')\n",
    "my_embedding.wv.add_vectors(\"<pad>\", torch.zeros(100))\n",
    "\n",
    "jobtype_myembedding_train_full = JobDatasetMyembedding(train_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_myembedding_val_full = JobDatasetMyembedding(val_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_myembedding_test_full = JobDatasetMyembedding(test_df, embedding=my_embedding.wv, text_column=text_column, label_column=label_column, words_len=128)\n",
    "\n",
    "jobtype_prainembedding_train_full = JobDatasetPretrainembedding(train_df, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_prainembedding_val_full = JobDatasetPretrainembedding(val_df, text_column=text_column, label_column=label_column, words_len=128)\n",
    "jobtype_prainembedding_test_full = JobDatasetPretrainembedding(test_df, text_column=text_column, label_column=label_column, words_len=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "31b17aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model 13\n",
    "state_myembeding_rnn_full = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_myembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_myembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_myembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model_myembedding_rnn_full = RnnModel1(n_features=100, hidden_dim=128, n_outputs=label_nums)\n",
    "model_myembedding_rnn_full = RnnModel2(embedding_size=100, num_embeddings=128, num_classes=label_nums, rnn_hidden_size=64)\n",
    "\n",
    "args.loss_func = nn.CrossEntropyLoss()\n",
    "args.optimizer = optim.Adam(model_myembedding_rnn_full.parameters(), lr=args.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4c2d8777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:30,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1458466594204575 11.030391834647967\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.013978789250056 15.17237103174603\n",
      "\n",
      "TRAIN: 1|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:21,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.961711431573505 16.809770303827044\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8975216845671334 16.83562748015873\n",
      "\n",
      "TRAIN: 2|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:20,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9200075433298123 18.210223122991522\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7663787504037223 21.40531994047619\n",
      "\n",
      "TRAIN: 3|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:38,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.875646221125783 17.67250036517675\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8237350781758623 17.743985615079364\n",
      "\n",
      "TRAIN: 4|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:40,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.915670210598436 17.869011101373065\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8695675233999896 18.202814980158728\n",
      "\n",
      "TRAIN: 5|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:41,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.846124257046752 19.461181711948573\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7869199613730116 19.511098710317455\n",
      "\n",
      "TRAIN: 6|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:25,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7606255730236944 21.31696428571429\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7071998318036394 20.943390376984123\n",
      "\n",
      "TRAIN: 7|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:20,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7639272549401044 20.242888182880517\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.719646294911702 20.256696428571423\n",
      "\n",
      "TRAIN: 8|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:19,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7726668770327905 19.687819529652362\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.724610914786657 20.496961805555554\n",
      "\n",
      "TRAIN: 9|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:26,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7680078371902175 21.039429959100193\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.754826178153356 21.52932787698413\n",
      "\n",
      "TRAIN: 10|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:22,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.777808732050327 21.149211218229617\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.806942751010259 18.827504960317462\n",
      "\n",
      "TRAIN: 11|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:34,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7597534978316594 20.76006974875841\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7449394961198164 20.422557043650798\n",
      "\n",
      "TRAIN: 12|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:30,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7598153754977375 20.760069748758387\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.733037362496058 20.913938492063494\n",
      "\n",
      "TRAIN: 13|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:33,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7385952341044617 21.569164475606197\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6786684095859523 21.402219742063494\n",
      "\n",
      "TRAIN: 14|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:44,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.798522204709199 20.2006646216769\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7979048589865365 19.283234126984127\n",
      "\n",
      "TRAIN: 15|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:39,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8192738345795605 19.683026584867083\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.773594895998637 18.990265376984127\n",
      "\n",
      "TRAIN: 16|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:37,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7945691881004295 20.091339833479402\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7812227308750153 19.901723710317462\n",
      "\n",
      "TRAIN: 17|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:32,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7905698612423766 20.558766067776798\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.76177195707957 20.455109126984123\n",
      "\n",
      "TRAIN: 18|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:27,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7601006791635534 21.216768916155416\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73454999923706 21.008494543650798\n",
      "\n",
      "TRAIN: 19|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:26,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.781510430610983 20.764862693543687\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8113963206609083 18.85695684523809\n",
      "\n",
      "TRAIN: 20|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:26,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.77439336688972 21.034180543383002\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7307664056619005 21.724640376984127\n",
      "\n",
      "TRAIN: 21|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:24,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7233006061951817 22.716504163014907\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.743520200252533 21.002294146825395\n",
      "\n",
      "TRAIN: 22|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:31,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78892720988923 21.18230536079462\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.728175828854243 21.62388392857143\n",
      "\n",
      "TRAIN: 23|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:24,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7636818871176323 22.116929593923473\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7565301756064096 21.203807043650787\n",
      "\n",
      "TRAIN: 24|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:23,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7156486979291485 23.521262416009353\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.675462514162063 22.76630704365079\n",
      "\n",
      "TRAIN: 25|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:22,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.680489845802448 24.331270084721012\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6714703738689423 23.449900793650798\n",
      "\n",
      "TRAIN: 26|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:23,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7519687128944628 22.43805689453696\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6604781945546474 24.136594742063494\n",
      "\n",
      "TRAIN: 27|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:35,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8173365373552945 19.543118244230193\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.725821226835251 21.692088293650794\n",
      "\n",
      "TRAIN: 28|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:38,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8692428012567057 17.45293784691791\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8343270719051366 18.205915178571427\n",
      "\n",
      "TRAIN: 29|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:32,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8060436453556004 19.242075664621673\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7587877313296003 20.68607390873016\n",
      "\n",
      "TRAIN: 30|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:32,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.763046609843435 22.021070698217926\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.741732180118561 21.4936755952381\n",
      "\n",
      "TRAIN: 31|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:33,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7848863118996654 21.344352541630155\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.836855789025625 19.27703373015873\n",
      "\n",
      "TRAIN: 32|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:34,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.842314202361312 19.41713226701723\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8230849405129756 19.706411210317466\n",
      "\n",
      "TRAIN: 33|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:42,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.819234403364498 20.658961437335677\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7752067546049752 20.783730158730155\n",
      "\n",
      "TRAIN: 34|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:37,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8110984644275514 20.433693032427694\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7929424246152244 20.03193204365079\n",
      "\n",
      "TRAIN: 35|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:36,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7675103263620944 21.01797582529944\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.723128616809845 21.008494543650794\n",
      "\n",
      "TRAIN: 36|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:43,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.731026096578025 22.053251898919072\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.736328423023224 20.813182043650794\n",
      "\n",
      "TRAIN: 37|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:42,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.732312489140984 21.906496494303234\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6916919251283002 21.13560267857143\n",
      "\n",
      "TRAIN: 38|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:42,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6985003816569515 22.187910823838727\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.655749360720316 23.42044890873016\n",
      "\n",
      "TRAIN: 39|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:44,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.735712466795751 22.87033486707567\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.70097220937411 22.834511408730158\n",
      "\n",
      "TRAIN: 40|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:44,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.715307307389617 23.520805945077427\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.671799689531326 23.098028273809526\n",
      "\n",
      "TRAIN: 41|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:41,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.724371668751255 22.787028921998242\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.719614058732987 21.659536210317462\n",
      "\n",
      "TRAIN: 42|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:40,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7151541095569827 22.940403155127086\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6600711941719055 23.322792658730155\n",
      "\n",
      "TRAIN: 43|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:37,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6742368388029694 23.904697998831445\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6313554048538212 24.169146825396826\n",
      "\n",
      "TRAIN: 44|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:34,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.649940515588398 24.55128907391177\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6086769700050354 23.97383432539682\n",
      "\n",
      "TRAIN: 45|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:35,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.679241468569984 23.89031916447561\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.646082063515981 23.94438244047619\n",
      "\n",
      "TRAIN: 46|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:34,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.680933545703536 23.555269500438225\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6122642258803053 24.33500744047619\n",
      "\n",
      "TRAIN: 47|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:38,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.709406741557678 21.144418273444344\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6395538051923113 22.769407242063494\n",
      "\n",
      "TRAIN: 48|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:33,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.652821025965404 23.104276219690323\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.657302568356196 21.792844742063494\n",
      "\n",
      "TRAIN: 49|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:34,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6962502119731324 22.153447268477933\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.632983247439067 22.67485119047619\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:03, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_index': 49, 'train_loss': [3.1458466594204575, 2.961711431573505, 2.9200075433298123, 2.875646221125783, 2.915670210598436, 2.846124257046752, 2.7606255730236944, 2.7639272549401044, 2.7726668770327905, 2.7680078371902175, 2.777808732050327, 2.7597534978316594, 2.7598153754977375, 2.7385952341044617, 2.798522204709199, 2.8192738345795605, 2.7945691881004295, 2.7905698612423766, 2.7601006791635534, 2.781510430610983, 2.77439336688972, 2.7233006061951817, 2.78892720988923, 2.7636818871176323, 2.7156486979291485, 2.680489845802448, 2.7519687128944628, 2.8173365373552945, 2.8692428012567057, 2.8060436453556004, 2.763046609843435, 2.7848863118996654, 2.842314202361312, 2.819234403364498, 2.8110984644275514, 2.7675103263620944, 2.731026096578025, 2.732312489140984, 2.6985003816569515, 2.735712466795751, 2.715307307389617, 2.724371668751255, 2.7151541095569827, 2.6742368388029694, 2.649940515588398, 2.679241468569984, 2.680933545703536, 2.709406741557678, 2.652821025965404, 2.6962502119731324], 'train_acc': [11.030391834647967, 16.809770303827044, 18.210223122991522, 17.67250036517675, 17.869011101373065, 19.461181711948573, 21.31696428571429, 20.242888182880517, 19.687819529652362, 21.039429959100193, 21.149211218229617, 20.76006974875841, 20.760069748758387, 21.569164475606197, 20.2006646216769, 19.683026584867083, 20.091339833479402, 20.558766067776798, 21.216768916155416, 20.764862693543687, 21.034180543383002, 22.716504163014907, 21.18230536079462, 22.116929593923473, 23.521262416009353, 24.331270084721012, 22.43805689453696, 19.543118244230193, 17.45293784691791, 19.242075664621673, 22.021070698217926, 21.344352541630155, 19.41713226701723, 20.658961437335677, 20.433693032427694, 21.01797582529944, 22.053251898919072, 21.906496494303234, 22.187910823838727, 22.87033486707567, 23.520805945077427, 22.787028921998242, 22.940403155127086, 23.904697998831445, 24.55128907391177, 23.89031916447561, 23.555269500438225, 21.144418273444344, 23.104276219690323, 22.153447268477933], 'val_loss': [3.013978789250056, 2.8975216845671334, 2.7663787504037223, 2.8237350781758623, 2.8695675233999896, 2.7869199613730116, 2.7071998318036394, 2.719646294911702, 2.724610914786657, 2.754826178153356, 2.806942751010259, 2.7449394961198164, 2.733037362496058, 2.6786684095859523, 2.7979048589865365, 2.773594895998637, 2.7812227308750153, 2.76177195707957, 2.73454999923706, 2.8113963206609083, 2.7307664056619005, 2.743520200252533, 2.728175828854243, 2.7565301756064096, 2.675462514162063, 2.6714703738689423, 2.6604781945546474, 2.725821226835251, 2.8343270719051366, 2.7587877313296003, 2.741732180118561, 2.836855789025625, 2.8230849405129756, 2.7752067546049752, 2.7929424246152244, 2.723128616809845, 2.736328423023224, 2.6916919251283002, 2.655749360720316, 2.70097220937411, 2.671799689531326, 2.719614058732987, 2.6600711941719055, 2.6313554048538212, 2.6086769700050354, 2.646082063515981, 2.6122642258803053, 2.6395538051923113, 2.657302568356196, 2.632983247439067], 'val_acc': [15.17237103174603, 16.83562748015873, 21.40531994047619, 17.743985615079364, 18.202814980158728, 19.511098710317455, 20.943390376984123, 20.256696428571423, 20.496961805555554, 21.52932787698413, 18.827504960317462, 20.422557043650798, 20.913938492063494, 21.402219742063494, 19.283234126984127, 18.990265376984127, 19.901723710317462, 20.455109126984123, 21.008494543650798, 18.85695684523809, 21.724640376984127, 21.002294146825395, 21.62388392857143, 21.203807043650787, 22.76630704365079, 23.449900793650798, 24.136594742063494, 21.692088293650794, 18.205915178571427, 20.68607390873016, 21.4936755952381, 19.27703373015873, 19.706411210317466, 20.783730158730155, 20.03193204365079, 21.008494543650794, 20.813182043650794, 21.13560267857143, 23.42044890873016, 22.834511408730158, 23.098028273809526, 21.659536210317462, 23.322792658730155, 24.169146825396826, 23.97383432539682, 23.94438244047619, 24.33500744047619, 22.769407242063494, 21.792844742063494, 22.67485119047619], 'test_loss': 2.6073900232923792, 'test_acc': 23.550834139264992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_myembedding_rnn_full, train_dataloader, val_dataloader, state_myembeding_rnn_full)\n",
    "test_engine(args, model_myembedding_rnn_full, test_dataloader, state_myembeding_rnn_full)\n",
    "print(state_myembeding_rnn_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3af335ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 14\n",
    "state_pretrainembeding_rnn_full = make_train_state(args) \n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(jobtype_prainembedding_train_full, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(jobtype_prainembedding_val_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(jobtype_prainembedding_test_full, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model_pretrainembedding_rnn_full = RnnModel1(n_features=100, hidden_dim=128, n_outputs=label_nums)\n",
    "model_pretrainembedding_rnn_full = RnnModel2(embedding_size=100, num_embeddings=128, num_classes=label_nums, rnn_hidden_size=64)\n",
    "\n",
    "args.loss_func = nn.CrossEntropyLoss()\n",
    "args.optimizer = optim.Adam(model_pretrainembedding_rnn_full.parameters(), lr=args.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a13c2e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:25,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1422450103642756 9.854750949459541\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 21.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0644426743189497 12.109375000000002\n",
      "\n",
      "TRAIN: 1|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:11, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0475139398516333 12.630322451066316\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 21.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0349468489487963 13.118489583333332\n",
      "\n",
      "TRAIN: 2|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:16,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.041756492450924 12.922692082968155\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.937319089969 16.675967261904763\n",
      "\n",
      "TRAIN: 3|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:19,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.027424746495813 13.063056894536958\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 21.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.056075155735016 11.591641865079366\n",
      "\n",
      "TRAIN: 4|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:15, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0306837500238704 12.970165059888988\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 21.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1317387223243713 9.99348958333333\n",
      "\n",
      "TRAIN: 5|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:28,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0761287168491123 10.741445734735617\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0748158494631452 10.810391865079366\n",
      "\n",
      "TRAIN: 6|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:42,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.061137588477573 11.604632267017239\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0612040162086487 11.464533730158731\n",
      "\n",
      "TRAIN: 7|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:20,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.041537296552601 12.334072816243062\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0383493999640145 12.177579365079364\n",
      "\n",
      "TRAIN: 8|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:20,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0411742523404 12.744896654981007\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0917932589848847 11.754402281746028\n",
      "\n",
      "TRAIN: 9|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:28,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.067066855225826 11.06919186386211\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.078765958547593 10.4523189484127\n",
      "\n",
      "TRAIN: 10|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:28,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0573173871069597 11.657354659655278\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0784254868825274 11.493985615079366\n",
      "\n",
      "TRAIN: 11|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:29,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.053037326028741 11.80639241893076\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.065597256024679 11.852058531746033\n",
      "\n",
      "TRAIN: 12|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:30,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0485928131758797 11.690448802220274\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0635557373364763 12.665860615079367\n",
      "\n",
      "TRAIN: 13|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:31,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0444644331200696 11.929639570552139\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0573206245899205 12.278335813492065\n",
      "\n",
      "TRAIN: 14|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:36,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.033424727024475 12.549298860648552\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0480459531148276 12.730964781746033\n",
      "\n",
      "TRAIN: 15|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:37,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.021838970710894 13.082685144609991\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0376950502395625 12.760416666666666\n",
      "\n",
      "TRAIN: 16|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:34,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0130460116029525 13.53230901256208\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.034784058729808 12.92627728174603\n",
      "\n",
      "TRAIN: 17|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:29,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0119158475676913 13.632047911189014\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0276808639367427 13.186693948412696\n",
      "\n",
      "TRAIN: 18|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:22,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0049476828311845 13.719690330119775\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.075396080811818 10.520523313492063\n",
      "\n",
      "TRAIN: 19|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:25,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0223959340639657 13.195889935728898\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0241628984610243 13.707527281746033\n",
      "\n",
      "TRAIN: 20|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:16,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.99936858130379 14.09262708150745\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0019533038139343 14.355468750000002\n",
      "\n",
      "TRAIN: 21|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:32,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0186836997424162 12.907856777680395\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0462012489636745 10.872395833333332\n",
      "\n",
      "TRAIN: 22|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:36,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0075384341865967 12.10309852468595\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 20.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0128505726655326 12.242683531746032\n",
      "\n",
      "TRAIN: 23|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:32,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.042713188686254 11.782427695004381\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0786322057247166 10.384114583333336\n",
      "\n",
      "TRAIN: 24|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:26,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0560252549458133 11.517902789950334\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0653128325939183 10.384114583333334\n",
      "\n",
      "TRAIN: 25|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:27,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0488906491753522 11.773298276365754\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 21.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.065247625112534 10.351562500000002\n",
      "\n",
      "TRAIN: 26|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:28,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0467254047744845 11.648225241016652\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.061191121737162 10.3515625\n",
      "\n",
      "TRAIN: 27|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:31,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0413926774007405 11.830813613789074\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.055705795685449 12.047371031746033\n",
      "\n",
      "TRAIN: 28|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:38,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0265100367961506 12.531496494303244\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0353914002577467 12.372891865079366\n",
      "\n",
      "TRAIN: 29|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:26,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0205510247704446 12.941863862109264\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0549549361069994 12.958829365079366\n",
      "\n",
      "TRAIN: 30|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:29,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.016493728555784 13.291748831434413\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0220384895801544 12.79296875\n",
      "\n",
      "TRAIN: 31|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:17,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.011571999707837 13.550567849839313\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.026297022898992 12.337239583333334\n",
      "\n",
      "TRAIN: 32|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:19,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.024825695833544 13.17671815658779\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0714869300524392 10.677083333333332\n",
      "\n",
      "TRAIN: 33|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:35,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.04899510137874 11.527945150452824\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0578286548455558 11.005704365079366\n",
      "\n",
      "TRAIN: 34|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:41,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.035308535113656 11.964559596844868\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.041488657395044 11.36377728174603\n",
      "\n",
      "TRAIN: 35|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:23,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.012574472310352 13.230353491089684\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.022506892681122 13.186693948412698\n",
      "\n",
      "TRAIN: 36|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:13, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9993685344976875 13.962761101373063\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.005700091520945 13.935391865079366\n",
      "\n",
      "TRAIN: 37|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:28,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0308893999439057 12.774110794624601\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0218325754006705 13.192894345238095\n",
      "\n",
      "TRAIN: 38|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:24,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9982772136758444 13.741829170318436\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 23.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9982379376888275 13.225446428571427\n",
      "\n",
      "TRAIN: 39|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:12, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.98297536446273 14.658651037101956\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 23.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.984175731738408 14.755394345238093\n",
      "\n",
      "TRAIN: 40|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:30,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.010723522104369 13.49784545720129\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.051840265591939 11.532738095238097\n",
      "\n",
      "TRAIN: 41|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:32,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0326192773924294 12.87521910604733\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.036146362622579 13.450210813492063\n",
      "\n",
      "TRAIN: 42|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:12, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.016213185948096 13.167132267017237\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0089104572931924 15.208023313492063\n",
      "\n",
      "TRAIN: 43|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:15, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.003506569774604 13.866902205667541\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.087508976459503 13.160342261904763\n",
      "\n",
      "TRAIN: 44|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:26,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9927232675025803 13.95842462751973\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9331682225068403 15.243675595238093\n",
      "\n",
      "TRAIN: 45|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:16,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9459646552618297 15.71789183464797\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9468952119350433 14.787946428571425\n",
      "\n",
      "TRAIN: 46|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:11, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.926801510383746 16.43637708150745\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8919649024804435 17.102244543650794\n",
      "\n",
      "TRAIN: 47|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:11, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9819475843862535 15.155747881974879\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.086480210224788 11.275421626984127\n",
      "\n",
      "TRAIN: 48|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:31,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.046050301358744 12.299609260882276\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0532555679480238 11.070808531746032\n",
      "\n",
      "TRAIN: 49|50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:40,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.045902821183935 12.341832822085891\n",
      "VAL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 22.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.056999186674754 12.636408730158731\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:02, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_index': 49, 'train_loss': [3.1422450103642756, 3.0475139398516333, 3.041756492450924, 3.027424746495813, 3.0306837500238704, 3.0761287168491123, 3.061137588477573, 3.041537296552601, 3.0411742523404, 3.067066855225826, 3.0573173871069597, 3.053037326028741, 3.0485928131758797, 3.0444644331200696, 3.033424727024475, 3.021838970710894, 3.0130460116029525, 3.0119158475676913, 3.0049476828311845, 3.0223959340639657, 2.99936858130379, 3.0186836997424162, 3.0075384341865967, 3.042713188686254, 3.0560252549458133, 3.0488906491753522, 3.0467254047744845, 3.0413926774007405, 3.0265100367961506, 3.0205510247704446, 3.016493728555784, 3.011571999707837, 3.024825695833544, 3.04899510137874, 3.035308535113656, 3.012574472310352, 2.9993685344976875, 3.0308893999439057, 2.9982772136758444, 2.98297536446273, 3.010723522104369, 3.0326192773924294, 3.016213185948096, 3.003506569774604, 2.9927232675025803, 2.9459646552618297, 2.926801510383746, 2.9819475843862535, 3.046050301358744, 3.045902821183935], 'train_acc': [9.854750949459541, 12.630322451066316, 12.922692082968155, 13.063056894536958, 12.970165059888988, 10.741445734735617, 11.604632267017239, 12.334072816243062, 12.744896654981007, 11.06919186386211, 11.657354659655278, 11.80639241893076, 11.690448802220274, 11.929639570552139, 12.549298860648552, 13.082685144609991, 13.53230901256208, 13.632047911189014, 13.719690330119775, 13.195889935728898, 14.09262708150745, 12.907856777680395, 12.10309852468595, 11.782427695004381, 11.517902789950334, 11.773298276365754, 11.648225241016652, 11.830813613789074, 12.531496494303244, 12.941863862109264, 13.291748831434413, 13.550567849839313, 13.17671815658779, 11.527945150452824, 11.964559596844868, 13.230353491089684, 13.962761101373063, 12.774110794624601, 13.741829170318436, 14.658651037101956, 13.49784545720129, 12.87521910604733, 13.167132267017237, 13.866902205667541, 13.95842462751973, 15.71789183464797, 16.43637708150745, 15.155747881974879, 12.299609260882276, 12.341832822085891], 'val_loss': [3.0644426743189497, 3.0349468489487963, 2.937319089969, 3.056075155735016, 3.1317387223243713, 3.0748158494631452, 3.0612040162086487, 3.0383493999640145, 3.0917932589848847, 3.078765958547593, 3.0784254868825274, 3.065597256024679, 3.0635557373364763, 3.0573206245899205, 3.0480459531148276, 3.0376950502395625, 3.034784058729808, 3.0276808639367427, 3.075396080811818, 3.0241628984610243, 3.0019533038139343, 3.0462012489636745, 3.0128505726655326, 3.0786322057247166, 3.0653128325939183, 3.065247625112534, 3.061191121737162, 3.055705795685449, 3.0353914002577467, 3.0549549361069994, 3.0220384895801544, 3.026297022898992, 3.0714869300524392, 3.0578286548455558, 3.041488657395044, 3.022506892681122, 3.005700091520945, 3.0218325754006705, 2.9982379376888275, 2.984175731738408, 3.051840265591939, 3.036146362622579, 3.0089104572931924, 3.087508976459503, 2.9331682225068403, 2.9468952119350433, 2.8919649024804435, 3.086480210224788, 3.0532555679480238, 3.056999186674754], 'val_acc': [12.109375000000002, 13.118489583333332, 16.675967261904763, 11.591641865079366, 9.99348958333333, 10.810391865079366, 11.464533730158731, 12.177579365079364, 11.754402281746028, 10.4523189484127, 11.493985615079366, 11.852058531746033, 12.665860615079367, 12.278335813492065, 12.730964781746033, 12.760416666666666, 12.92627728174603, 13.186693948412696, 10.520523313492063, 13.707527281746033, 14.355468750000002, 10.872395833333332, 12.242683531746032, 10.384114583333336, 10.384114583333334, 10.351562500000002, 10.3515625, 12.047371031746033, 12.372891865079366, 12.958829365079366, 12.79296875, 12.337239583333334, 10.677083333333332, 11.005704365079366, 11.36377728174603, 13.186693948412698, 13.935391865079366, 13.192894345238095, 13.225446428571427, 14.755394345238093, 11.532738095238097, 13.450210813492063, 15.208023313492063, 13.160342261904763, 15.243675595238093, 14.787946428571425, 17.102244543650794, 11.275421626984127, 11.070808531746032, 12.636408730158731], 'test_loss': 3.045679204007412, 'test_acc': 13.04098162475822}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_engin(args, model_pretrainembedding_rnn_full, train_dataloader, val_dataloader, state_pretrainembeding_rnn_full)\n",
    "test_engine(args, model_pretrainembedding_rnn_full, test_dataloader, state_pretrainembeding_rnn_full)\n",
    "print(state_pretrainembeding_rnn_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462437a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102960af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d2a2b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A perceptron is one linear layer\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Args:\n",
    "input_dim (int): size of the input features\n",
    "\"\"\"\n",
    "\"\"\"The forward pass of the perceptron\n",
    "Args:\n",
    "x_in (torch.Tensor): an input data tensor\n",
    "x_in.shape should be (batch, num_features) Returns:\n",
    "the resulting tensor. tensor.shape should be (batch,). \"\"\"\n",
    "class Perceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron, self).__init__() \n",
    "        self.fc1 = nn.Linear(input_dim, 1)\n",
    "    def forward(self, x_in):\n",
    "\n",
    "        return torch.sigmoid(self.fc1(x_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "82a2c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A perceptron is one linear layer\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Args:\n",
    "input_dim (int): size of the input features\n",
    "\"\"\"\n",
    "\"\"\"The forward pass of the perceptron\n",
    "Args:\n",
    "x_in (torch.Tensor): an input data tensor\n",
    "x_in.shape should be (batch, num_features) Returns:\n",
    "the resulting tensor. tensor.shape should be (batch,). \"\"\"\n",
    "class Perceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron, self).__init__() \n",
    "        self.fc1 = nn.Linear(input_dim, 1)\n",
    "    def forward(self, x_in):\n",
    "\n",
    "        return torch.sigmoid(self.fc1(x_in)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5489dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4938a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "# Builds function that performs a step in the train loop \n",
    "    def perform_train_step(x_batch, y_batch):\n",
    "        # Sets model to TRAIN mode\n",
    "        model.train()\n",
    "# Step 1 - Computes model's predictions - forward pass\n",
    "        yhat = model(x_batch).squeeze() \n",
    "        y_batch = y_batch.squeeze()\n",
    "# Step 2 - Computes the loss\n",
    "        loss = loss_fn(yhat, y_batch)\n",
    "# Step 3 - Computes gradients for parameters loss.backward()\n",
    "# Step 4 - Updates parameters using gradients and # the learning rate\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "# Returns the loss\n",
    "        return loss.item()\n",
    "# Returns the function that will be called inside the # train loop\n",
    "    return perform_train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a0f5d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf0dcd",
   "metadata": {},
   "source": [
    "**Converting Text Inputs to Vectorized Minibatches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dc9c4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Args:\n",
    "review_df (pandas.DataFrame): the dataset\n",
    "vectorizer (ReviewVectorizer): vectorizer instantiated from dataset\n",
    "        Load dataset and make a new vectorizer from scratch Args:\n",
    "review_csv (str): location of the dataset Returns:\n",
    "            an instance of ReviewDataset\n",
    " selects the splits in the dataset using a column in the dataframe\n",
    "        Args:\n",
    "        split (str): one of \"train\", \"val\", or \"test\"\n",
    "the primary entry point method for PyTorch datasets\n",
    "        Args:\n",
    "        index (int): the index to the data point\n",
    "        Returns:\n",
    "a dict of the data point's features (x_data) and label (y_target)\n",
    "Given a batch size, return the number of batches in the dataset Args:\n",
    "batch_size (int)\n",
    "Returns:\n",
    "number of batches in the dataset \"\"\"\n",
    "from torch.utils.data import Dataset \n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, review_df, vectorizer): \n",
    "        self.review_df = review_df\n",
    "        self._vectorizer = vectorizer\n",
    "        self.train_df = self.review_df[self.review_df.split=='train'] \n",
    "        self.train_size = len(self.train_df)\n",
    "        self.val_df = self.review_df[self.review_df.split=='val'] \n",
    "        self.validation_size = len(self.val_df)\n",
    "        self.test_df = self.review_df[self.review_df.split=='test'] \n",
    "        self.test_size = len(self.test_df)\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)} \n",
    "        self.set_split('train')\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, review_csv): \n",
    "\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        return cls(review_df, ReviewVectorizer.from_dataframe(review_df)) \n",
    "    def get_vectorizer(self):\n",
    "        #\"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "    def set_split(self, split=\"train\"):\n",
    "\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split] \n",
    "    def __len__(self):\n",
    "        return self._target_size \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self._target_df.iloc[index]\n",
    "        review_vector = \\\n",
    "        self._vectorizer.vectorize(row.review)\n",
    "        rating_index = \\\n",
    "        self._vectorizer.rating_vocab.lookup_token(row.rating) \n",
    "        return {'x_data': review_vector,\n",
    "                'y_target': rating_index} \n",
    "    def get_num_batches(self, batch_size):\n",
    "\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd0d86",
   "metadata": {},
   "source": [
    "**The `Vocabulary` Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "af1e745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "#\"\"\"Class to process text and extract Vocabulary for mapping\"\"\"\n",
    "    def __init__(self, token_to_idx=None,mask_token=\"<MASK>\", add_unk=True, unk_token=\"<UNK>\"):\n",
    "        if token_to_idx is None: \n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx \n",
    "        self._idx_to_token = {idx: token for token, idx in self._token_to_idx.items()}\n",
    "        self._add_unk = add_unk \n",
    "        self._unk_token = unk_token \n",
    "        self._mask_token = mask_token\n",
    "        self.unk_index = 1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "    \n",
    "    def to_serializable(self):\n",
    "        #\"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx, 'add_unk': self._add_unk,\n",
    "                'unk_token': self._unk_token} \n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "\n",
    "        return cls(**contents)\n",
    "    def add_token(self, token):\n",
    "\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token] \n",
    "        else:\n",
    "            index = len(self._token_to_idx) \n",
    "            self._token_to_idx[token] = index \n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    def lookup_token(self, token):\n",
    "        if self._add_unk:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "    def lookup_index(self, index):\n",
    "\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index) \n",
    "        return self._idx_to_token[index]\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd517c3",
   "metadata": {},
   "source": [
    "**Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "211897a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "import string\n",
    "class ReviewVectorizer(object):\n",
    "    #\"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, review_vocab, rating_vocab): \n",
    "        self.review_vocab = review_vocab\n",
    "        self.rating_vocab = rating_vocab \n",
    "    def vectorize(self, review):\n",
    "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32) \n",
    "        for token in review.split(\" \"):\n",
    "            if token not in string.punctuation: \n",
    "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
    "        return one_hot \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, review_df, cutoff=25): \n",
    "        review_vocab = Vocabulary(add_unk=True) \n",
    "        rating_vocab = Vocabulary(add_unk=False)\n",
    "        # Add ratings\n",
    "        for job_type in sorted(set(review_df.job_type)):\n",
    "            rating_vocab.add_token(job_type)\n",
    "        # Add top words if count > provided count word_counts = Counter()\n",
    "        for review in review_df.review:\n",
    "            for word in review.split(\" \"):\n",
    "                if word not in string.punctuation:\n",
    "                    word_counts[word] += 1\n",
    "        for word, count in word_counts.items():\n",
    "            if count > cutoff: review_vocab.add_token(word)\n",
    "        return cls(review_vocab, rating_vocab)\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "\n",
    "        review_vocab = Vocabulary.from_serializable(contents['review_vocab']) \n",
    "        rating_vocab = Vocabulary.from_serializable(contents['rating_vocab']) \n",
    "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
    "    def to_serializable(self):\n",
    "        return {'review_vocab': self.review_vocab.to_serializable(), \n",
    "                'rating_vocab': self.rating_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361a992",
   "metadata": {},
   "source": [
    "**A perceptron classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bee1f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "class ReviewClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(ReviewClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=num_features, out_features=1)\n",
    "    def forward(self, x_in, apply_sigmoid=False):\n",
    "        y_out = self.fc1(x_in).squeeze()\n",
    "        if apply_sigmoid:\n",
    "            y_out = torch.sigmoid(y_out)\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d9205",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3f9b2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace \n",
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    frequency_cutoff=25,\n",
    "    model_state_file='model.pth', review_csv='job.csv', \n",
    "    save_dir='model_storage/yelp/', vectorizer_file='vectorizer.json',\n",
    "# No model hyperparameters\n",
    "# Training hyperparameters\n",
    "    batch_size=128,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=100,\n",
    "    seed=1337,\n",
    "# Runtime options\n",
    "    cuda=True,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bfd585d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_target):\n",
    "    y_target = y_target.cpu()\n",
    "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()#.max(dim=1)[1] n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66154588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc8ccd4",
   "metadata": {},
   "source": [
    "## CNN<br>\n",
    "## how to train CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0117bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "import collections\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3184caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "raw_dataset_txt=\"job_description.txt\",\n",
    "window_size=5,\n",
    "train_proportion=0.7,\n",
    "val_proportion=0.15,\n",
    "test_proportion=0.15,\n",
    "output_munged_csv=\"/project2/seek_australia.csv\",\n",
    "seed=1337\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4201d4",
   "metadata": {},
   "source": [
    "1.3 Preprocessing - Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8f088c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean sentences\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4398c6",
   "metadata": {},
   "source": [
    "CBOW training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7435a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "MASK_TOKEN = \"<MASK>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08defc1a",
   "metadata": {},
   "source": [
    "**tqdm instantly makes your loop display a smart progress table - just wrap any iterable in your for loop with tqdm(iterable) and you'll see a progress bar when you run the loop.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f43f1736",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [213]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create windows based on the window_size\u001b[39;00m\n\u001b[1;32m      2\u001b[0m flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m outer_list: [item \u001b[38;5;28;01mfor\u001b[39;00m inner_list \u001b[38;5;129;01min\u001b[39;00m outer_list \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m inner_list]\n\u001b[1;32m      3\u001b[0m windows \u001b[38;5;241m=\u001b[39m flatten([\u001b[38;5;28mlist\u001b[39m(nltk\u001b[38;5;241m.\u001b[39mngrams([MASK_TOKEN] \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m+\u001b[39m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m [MASK_TOKEN] \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mwindow_size, args\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mcleaned_sentences\u001b[49m)])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create cbow data (extract target center word and context words)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "# Create windows based on the window_size\n",
    "flatten = lambda outer_list: [item for inner_list in outer_list for item in inner_list]\n",
    "windows = flatten([list(nltk.ngrams([MASK_TOKEN] * args.window_size + sentence.split(' ') + [MASK_TOKEN] * args.window_size, args.window_size * 2 + 1)) \n",
    "\n",
    "for sentence in tqdm(cleaned_sentences)])\n",
    "# Create cbow data (extract target center word and context words)\n",
    "data = []\n",
    "for window in tqdm(windows):\n",
    "    target_token = window[args.window_size]\n",
    "    context = []\n",
    "    for i, token in enumerate(window):  \n",
    "        if token == MASK_TOKEN or i == args.window_size:\n",
    "            continue\n",
    "        else:\n",
    "            context.append(token)\n",
    "    data.append([' '.join(token for token in context), target_token])\n",
    "# Convert to dataframe\n",
    "cbow_data = pd.DataFrame(data, columns=[\"context\", \"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff488020",
   "metadata": {},
   "source": [
    "**news**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3f51b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a1e02a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "    def __init__(self, token_to_idx=None, mask_token=\"<MASK>\", add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "Args:\n",
    "token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "mask_token (str): the MASK token to add into the Vocabulary; indicates\n",
    "a position that will not be used in updating the model's parameters\n",
    "add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "unk_token (str): the UNK token to add into the Vocabulary\n",
    "\"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token\n",
    "        for token, idx in self._token_to_idx.items()}\n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        self._mask_token = mask_token\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token)\n",
    "    def to_serializable(self):\n",
    "            \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "            return{'token_to_idx': self._token_to_idx,\n",
    "                        'add_unk': self._add_unk,\n",
    "                        'unk_token': self._unk_token,\n",
    "                        'mask_token': self._mask_token}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "Args:\n",
    "token (str): the item to add into the Vocabulary\n",
    "Returns:\n",
    "index (int): the integer corresponding to the token\n",
    "\"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "        self._token_to_idx[token] = index\n",
    "        self._idx_to_token[index] = token\n",
    "        return index\n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"Add a list of tokens into the Vocabulary\n",
    "Args:\n",
    "tokens (list): a list of string tokens\n",
    "Returns:\n",
    "indices (list): a list of indices corresponding to the tokens\n",
    "\"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token\n",
    "        or the UNK index if token isn't present.\n",
    "        Args:\n",
    "        token (str): the token to look up\n",
    "        Returns:\n",
    "        index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "        `unk_index` needs to be >=0 (having been added into the Vocabulary)\n",
    "        for the UNK functionality\n",
    "        \"\"\" \n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        Args:\n",
    "        index (int): the index to look up\n",
    "        Returns:\n",
    "        token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "        KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b48147",
   "metadata": {},
   "source": [
    "**Use on df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4f5f34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, cbow_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        cbow_vocab (Vocabulary): maps words to integers\n",
    "        \"\"\"\n",
    "        self.cbow_vocab = cbow_vocab\n",
    "    def vectorize(self, context, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        context (str): the string of words separated by a space\n",
    "        vector_length (int): an argument for forcing the length of index vector\n",
    "        \"\"\"\n",
    "        indices = [self.cbow_vocab.lookup_token(token) for token in context.split('')]\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "            out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "            out_vector[:len(indices)] = indices\n",
    "            out_vector[len(indices):] = self.cbow_vocab.mask_index\n",
    "        return out_vector\n",
    "    @classmethod\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        cbow_vocab = \\\n",
    "        Vocabulary.from_serializable(contents['cbow_vocab'])\n",
    "        return cls(cbow_vocab=cbow_vocab)\n",
    "    def to_serializable(self):\n",
    "        return {'cbow_vocab': self.cbow_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d8ceb",
   "metadata": {},
   "source": [
    "**The Dataset and Data Loader dataset class uses the class method  `load_dataset_and_make_vectorizer()` to read the input data into a data frame, and then passes the data frame to the Vectorizer class to populate a vocabulary object so that when the `vectorize()` method is called, it performs the appropriate vectorization, in this case returning the vocabulary index of the input context word.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0d352a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, cbow_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        cbow_df (pandas.DataFrame): the dataset\n",
    "        vectorizer (CBOWVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.cbow_df = cbow_df\n",
    "        self._vectorizer = vectorizer\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, cbow_df.context))\n",
    "        self.train_df = self.cbow_df[self.cbow_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        self.val_df = self.cbow_df[self.cbow_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "        self.test_df = self.cbow_df[self.cbow_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "        'val': (self.val_df, self.validation_size),\n",
    "        'test': (self.test_df, self.test_size)}\n",
    "        self.set_split('train')\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, cbow_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        Args:\n",
    "        cbow_csv (str): location of the dataset\n",
    "        Returns:\n",
    "        an instance of CBOWDataset\n",
    "        \"\"\"\n",
    "        cbow_df = pd.read_csv(cbow_csv)\n",
    "        train_cbow_df = cbow_df[cbow_df.split=='train']\n",
    "        return cls(cbow_df, CBOWVectorizer.from_dataframe(train_cbow_df))\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, cbow_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer.\n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        Args:\n",
    "        cbow_csv (str): location of the dataset\n",
    "        vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "        an instance of CBOWDataset\n",
    "        \"\"\"\n",
    "        cbow_df = pd.read_csv(cbow_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(cbow_df, vectorizer)\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        Args:\n",
    "        vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "        an instance of CBOWVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return CBOWVectorizer.from_serializable(json.load(fp))\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        Args:\n",
    "        vectorizer_filepath (str): the location to save the vectorizer\n",
    "            \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "    def set_split(self, split=\"train\"):\n",
    "            \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "            self._target_split = split\n",
    "            self._target_df, self._target_size = self._lookup_dict[split]\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        Args:\n",
    "        index (int): the index to the data point\n",
    "        Returns:\n",
    "        a dictionary holding the data point's features (x_data) and label (y_\n",
    "        ↪target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        context_vector = \\\n",
    "        self._vectorizer.vectorize(row.context, self._max_seq_length)\n",
    "        target_index = self._vectorizer.cbow_vocab.lookup_token(row.target)\n",
    "        return {'x_data': context_vector,'y_target': target_index}\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        Args:\n",
    "        batch_size (int)\n",
    "        Returns:\n",
    "        number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "    def generate_batches(dataset, batch_size, shuffle=True,\n",
    "        drop_last=True, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        A generator function which wraps the PyTorch DataLoader. It will\n",
    "        ensure each tensor is on the write device location.\n",
    "        \"\"\"\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "        shuffle=shuffle, drop_last=drop_last)\n",
    "        for data_dict in dataloader:\n",
    "            out_data_dict = {}\n",
    "            for name, tensor in data_dict.items():\n",
    "                out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4c3e4a8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CBOWClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [218]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCBOWClassifier\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule): \u001b[38;5;66;03m# Simplified cbow Model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vocabulary_size, embedding_size, padding_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m        Args:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m        vocabulary_size (int): number of vocabulary items, controls the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m        padding_idx (int): default 0; Embedding will not use this index\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "Input \u001b[0;32mIn [218]\u001b[0m, in \u001b[0;36mCBOWClassifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vocabulary_size, embedding_size, padding_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    vocabulary_size (int): number of vocabulary items, controls the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    padding_idx (int): default 0; Embedding will not use this index\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28msuper\u001b[39m(\u001b[43mCBOWClassifier\u001b[49m, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(num_embeddings\u001b[38;5;241m=\u001b[39mvocabulary_size,\n\u001b[1;32m     12\u001b[0m embedding_dim\u001b[38;5;241m=\u001b[39membedding_size,\n\u001b[1;32m     13\u001b[0m padding_idx\u001b[38;5;241m=\u001b[39mpadding_idx)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39membedding_size,\n\u001b[1;32m     15\u001b[0m out_features\u001b[38;5;241m=\u001b[39mvocabulary_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CBOWClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "class CBOWClassifier(nn.Module): # Simplified cbow Model\n",
    "    def __init__(self, vocabulary_size, embedding_size, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        vocabulary_size (int): number of vocabulary items, controls the\n",
    "        number of embeddings and prediction vector size\n",
    "        embedding_size (int): size of the embeddings\n",
    "        padding_idx (int): default 0; Embedding will not use this index\n",
    "        \"\"\"\n",
    "    super(CBOWClassifier, self).__init__()\n",
    "    self.embedding = nn.Embedding(num_embeddings=vocabulary_size,\n",
    "    embedding_dim=embedding_size,\n",
    "    padding_idx=padding_idx)\n",
    "    self.fc1 = nn.Linear(in_features=embedding_size,\n",
    "    out_features=vocabulary_size)\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        Args:\n",
    "        x_in (torch.Tensor): an input data tensor.\n",
    "        x_in.shape should be (batch, input_dim)\n",
    "        apply_softmax (bool): a flag for the softmax activation\n",
    "        should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "        the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        x_embedded_sum = F.dropout(self.embedding(x_in).sum(dim=1), 0.3)\n",
    "        y_out = self.fc1(x_embedded_sum)\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9541720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "    'early_stopping_step': 0,\n",
    "    'early_stopping_best_val': 1e8,\n",
    "    'learning_rate': args.learning_rate,\n",
    "    'epoch_index': 0,\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'test_loss': -1,\n",
    "    'test_acc': -1,\n",
    "    'model_filename': args.model_state_file}\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "    Components:\n",
    "    - Early Stopping: Prevent overfitting.\n",
    "    - Model Checkpoint: Model is saved if the model is better\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "    a new train_state\n",
    "    \"\"\"\n",
    "# Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "    # If loss worsened\n",
    "    if loss_t >= train_state['early_stopping_best_val']:\n",
    "        # Update step\n",
    "        train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "    else:\n",
    "    # Save the best model\n",
    "        if loss_t < train_state['early_stopping_best_val']:\n",
    "            torch.save(model.state_dict(), train_state['model_filename'])\n",
    "    # Reset early stopping step\n",
    "    train_state['early_stopping_step'] = 0\n",
    "    # Stop early ?\n",
    "    train_state['stop_early'] = \\\n",
    "    train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "    return train_state\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "26ca1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "11714aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage\\cbow/vectorizer.json\n",
      "\tmodel_storage\\cbow/model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "# Data and Path information\n",
    "    cbow_csv=\"../data/books/frankenstein_with_splits.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage\\cbow\",\n",
    "# Model hyper parameters\n",
    "    embedding_size=50,\n",
    "    # Training hyper parameters\n",
    "    seed=1337,\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=32,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime options\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True\n",
    ")\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "    args.vectorizer_file)\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "    args.model_state_file)\n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "    args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    print(\"Using CUDA: {}\".format(args.cuda))\n",
    "    # Set seed for reproducibility\n",
    "    set_seed_everywhere(args.seed, args.cuda)\n",
    "    # handle dirs\n",
    "    handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a1846",
   "metadata": {},
   "source": [
    "**Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cf62ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(results):\n",
    "# \"\"\"\n",
    "# Pretty print embedding results.\n",
    "# \"\"\"\n",
    "    for item in results:\n",
    "        print (\"...[%.2f] - %s\"%(item[1], item[0]))\n",
    "def get_closest(target_word, word_to_idx, embeddings, n=5):\n",
    "    \"\"\"\n",
    "    Get the n closest\n",
    "    words to your word.\n",
    "    \"\"\"\n",
    "# Calculate distances to all other words\n",
    "    word_embedding = embeddings[word_to_idx[target_word.lower()]]\n",
    "    distances = []\n",
    "    for word, index in word_to_idx.items():\n",
    "        if word == \"<MASK>\" or word == target_word:\n",
    "            continue\n",
    "    distances.append((word, torch.dist(word_embedding, embeddings[index])))\n",
    "    results = sorted(distances, key=lambda x: x[1])[1:n+2]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f57e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40691fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c761050e",
   "metadata": {},
   "source": [
    "**Emphasis on references to `cnn` used in embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "13d92b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad308d",
   "metadata": {},
   "source": [
    "**generate one hot**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "af509e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "            self._token_to_idx = token_to_idx\n",
    "            self._idx_to_token = {idx: token for token, idx in self._token_to_idx.items()}\n",
    "    def to_serializable(self):\n",
    "            \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "            return {'token_to_idx': self._token_to_idx}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "            \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "            return cls(**contents)\n",
    "    def add_token(self, token):\n",
    "            \"\"\"Update mapping dicts based on the token.\n",
    "            Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "            Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "            \"\"\"\n",
    "            if token in self._token_to_idx:\n",
    "                index = self._token_to_idx[token]\n",
    "            else:\n",
    "                index = len(self._token_to_idx)\n",
    "                self._token_to_idx[token] = index\n",
    "                self._idx_to_token[index] = token\n",
    "                return index\n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"Add a list of tokens into the Vocabulary\n",
    "        Args:\n",
    "        tokens (list): a list of string tokens\n",
    "        Returns:\n",
    "        indices (list): a list of indices corresponding to the tokens\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token\n",
    "        Args:\n",
    "        token (str): the token to look up\n",
    "        Returns:\n",
    "        index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        Args:\n",
    "        index (int): the index to look up\n",
    "        Returns:\n",
    "        token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "        KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9c665b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                end_seq_token=\"<END>\"):\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "        'mask_token': self._mask_token,\n",
    "        'begin_seq_token': self._begin_seq_token,'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token\n",
    "        or the UNK index if token isn't present.\n",
    "        Args:\n",
    "        token (str): the token to look up\n",
    "        Returns:\n",
    "        index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "        `unk_index` needs to be >=0 (having been added into the Vocabulary)\n",
    "        for the UNK functionality\n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "75d385c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, title_vocab, category_vocab):\n",
    "        self.title_vocab = title_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "    def vectorize(self, title, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        title (str): the string of words separated by a space\n",
    "        vector_length (int): an argument for forcing the length of index vector\n",
    "        Returns:\n",
    "        the vetorized title (numpy.array)\n",
    "        \"\"\"\n",
    "        indices = [self.title_vocab.begin_seq_index]\n",
    "        indices.extend(self.title_vocab.lookup_token(token)for token in title.split(\" \"))\n",
    "            \n",
    "        indices.append(self.title_vocab.end_seq_index)\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "            out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "            out_vector[:len(indices)] = indices\n",
    "            out_vector[len(indices):] = self.title_vocab.mask_index\n",
    "            return out_vector\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, news_df, cutoff=25):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        Args:\n",
    "        news_df (pandas.DataFrame): the target dataset\n",
    "        cutoff (int): frequency threshold for including in Vocabulary\n",
    "        Returns:\n",
    "        an instance of the NewsVectorizer\n",
    "        \"\"\"\n",
    "        category_vocab = Vocabulary()\n",
    "        for category in sorted(set(news_df.category)):\n",
    "            category_vocab.add_token(category)  \n",
    "            word_counts = Counter()\n",
    "        for title in news_df.title:\n",
    "             for token in title.split(\" \"):\n",
    "                if token not in string.punctuation:\n",
    "                    word_counts[token] += 1\n",
    "        title_vocab = SequenceVocabulary()\n",
    "        for word, word_count in word_counts.items():\n",
    "            if word_count >= cutoff:\n",
    "                title_vocab.add_token(word)\n",
    "        return cls(title_vocab, category_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716897a",
   "metadata": {},
   "source": [
    "NewsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "90084039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self, embedding_size, num_embeddings, num_channels,\n",
    "                hidden_dim, num_classes, dropout_p,\n",
    "                pretrained_embeddings=None, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        embedding_size (int): size of the embedding vectors\n",
    "        num_embeddings (int): number of embedding vectors\n",
    "        filter_width (int): width of the convolutional kernels\n",
    "        num_channels (int): number of convolutional kernels per layer\n",
    "        hidden_dim (int): the size of the hidden dimension\n",
    "        num_classes (int): the number of classes in classification\n",
    "        dropout_p (float): a dropout parameter\n",
    "        pretrained_embeddings (numpy.array): previously trained word embeddings\n",
    "        default is None. If provided,\n",
    "        padding_idx (int): an index representing a null position\n",
    "        \"\"\"\n",
    "        super(NewsClassifier, self).__init__()\n",
    "\n",
    "        if pretrained_embeddings is None:\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
    "            num_embeddings=num_embeddings,\n",
    "            padding_idx=padding_idx)\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
    "            num_embeddings=num_embeddings,\n",
    "            padding_idx=padding_idx,\n",
    "            _weight=pretrained_embeddings)\n",
    "\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_size,\n",
    "            out_channels=num_channels, kernel_size=3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
    "            kernel_size=3, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
    "            kernel_size=3, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
    "            kernel_size=3),\n",
    "            nn.ELU()\n",
    "            )\n",
    "\n",
    "        self._dropout_p = dropout_p\n",
    "        self.fc1 = nn.Linear(num_channels, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        Args:\n",
    "        x_in (torch.Tensor): an input data tensor.\n",
    "        x_in.shape should be (batch, dataset._max_seq_length)\n",
    "        apply_softmax (bool): a flag for the softmax activation\n",
    "should be false if used with the Cross Entropy losses\n",
    "Returns:\n",
    "the resulting tensor. tensor.shape should be (batch, num_classes)\n",
    "\"\"\"\n",
    "        # embed and permute so features are channels\n",
    "        x_embedded = self.emb(x_in).permute(0, 2, 1)\n",
    "        features = self.convnet(x_embedded)\n",
    "        # average and remove the extra dimension\n",
    "        remaining_size = features.size(dim=2)\n",
    "        features = F.avg_pool1d(features, remaining_size).squeeze(dim=2)\n",
    "        features = F.dropout(features, p=self._dropout_p)\n",
    "        # mlp classifier\n",
    "        intermediate_vector = F.relu(F.dropout(self.fc1(features), p=self._dropout_p))\n",
    "        prediction_vector = self.fc2(intermediate_vector)\n",
    "        if apply_softmax:\n",
    "             prediction_vector = F.softmax(prediction_vector, dim=1)\n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f3cca",
   "metadata": {},
   "source": [
    "Using pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f92308f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the reviews\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d9bdf759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(title, classifier, vectorizer, max_length):\n",
    "    \"\"\"Predict a News category for a new title\n",
    "    Args:\n",
    "    title (str): a raw title string\n",
    "    classifier (NewsClassifier): an instance of the trained classifier\n",
    "    vectorizer (NewsVectorizer): the corresponding vectorizer\n",
    "    max_length (int): the max sequence length\n",
    "    Note: CNNs are sensitive to the input data tensor size.\n",
    "    This ensures to keep it the same size as the training data\n",
    "    \"\"\"\n",
    "    title = preprocess_text(title)\n",
    "    vectorized_title = \\\n",
    "    torch.tensor(vectorizer.vectorize(title, vector_length=max_length))\n",
    "    result = classifier(vectorized_title.unsqueeze(0), apply_softmax=True)\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    predicted_category = vectorizer.category_vocab.lookup_index(indices.item())\n",
    "    return {'category': predicted_category,\n",
    "    'probability': probability_values.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9dbe4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    samples = {}\n",
    "    for cat in dataset.val_df.category.unique():\n",
    "        samples[cat] = dataset.val_df.title[dataset.val_df.category==cat].tolist()[:5]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661cd63",
   "metadata": {},
   "source": [
    "# Task 2: Multi-class Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19167a17",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f1483069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5fc13831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token\n",
    "                                for token, idx in self._token_to_idx.items()}\n",
    "    def to_serializable(self):\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(**contents)\n",
    "   \n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    def add_many(self, tokens):\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "    def lookup_token(self, token):\n",
    "        return self._token_to_idx[token]\n",
    "    def lookup_index(self, index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fcd364c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                end_seq_token=\"<END>\"):\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "        \n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                        'mask_token': self._mask_token,\n",
    "                        'begin_seq_token': self._begin_seq_token,\n",
    "                        'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "    def lookup_token(self, token):\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6e482ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameVectorizer(object):\n",
    "    def __init__(self, char_vocab, nationality_vocab):\n",
    "        self.char_vocab = char_vocab\n",
    "        self.nationality_vocab = nationality_vocab\n",
    "    def vectorize(self, surname, vector_length=-1):\n",
    "        indices = [self.char_vocab.begin_seq_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(token)\n",
    "                        for token in surname)\n",
    "        indices.append(self.char_vocab.end_seq_index)\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "        \n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.char_vocab.mask_index\n",
    "        \n",
    "        return out_vector, len(indices)\n",
    "    def to_serializable(self):\n",
    "        return {'char_vocab': self.char_vocab.to_serializable(),\n",
    "                'nationality_vocab': self.nationality_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "124ea4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameDataset(Dataset):\n",
    "    def __init__(self, surname_df, vectorizer):\n",
    "        self.surname_df = surname_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self._max_seq_length = max(map(len, self.surname_df.surname)) + 2\n",
    "\n",
    "        self.train_df = self.surname_df[self.surname_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                            'val': (self.val_df, self.validation_size),\n",
    "                            'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        # Class weights\n",
    "        class_counts = self.train_df.nationality.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.nationality_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, surname_csv):\n",
    "        surname_df = pd.read_csv(surname_csv)\n",
    "        train_surname_df = surname_df[surname_df.split=='train']\n",
    "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, surname_csv, vectorizer_filepath):\n",
    "        surname_df = pd.read_csv(surname_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(surname_df, vectorizer)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    "        surname_vector, vec_length = \\\n",
    "            self._vectorizer.vectorize(row.surname, self._max_seq_length)\n",
    "        \n",
    "        nationality_index = \\\n",
    "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
    "        return {'x_data': surname_vector,\n",
    "                'y_target': nationality_index,\n",
    "                'x_length': vec_length}\n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size\n",
    "    def generate_batches(dataset, batch_size, shuffle=True,\n",
    "        drop_last=True, device=\"cpu\"):\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                                shuffle=shuffle, drop_last=drop_last)\n",
    "    \n",
    "        for data_dict in dataloader:\n",
    "            out_data_dict = {}\n",
    "            for name, tensor in data_dict.items():\n",
    "                out_data_dict[name] = data_dict[name].to(device)\n",
    "            yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2c394708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_gather(y_out, x_lengths):\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "    \n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        out.append(y_out[batch_index, column_index])\n",
    "    \n",
    "    return torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ff65a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmanRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_first=False):\n",
    "        super(ElmanRNN, self).__init__()\n",
    "        \n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "        self.batch_first = batch_first\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def _initial_hidden(self, batch_size):\n",
    "        return torch.zeros((batch_size, self.hidden_size))\n",
    "    \n",
    "    def forward(self, x_in, initial_hidden=None):\n",
    "        if self.batch_first:\n",
    "            batch_size, seq_size, feat_size = x_in.size()\n",
    "            x_in = x_in.permute(1, 0, 2)\n",
    "        else:\n",
    "            seq_size, batch_size, feat_size = x_in.size()\n",
    "        hiddens = []\n",
    "        \n",
    "        if initial_hidden is None:\n",
    "            initial_hidden = self._initial_hidden(batch_size)\n",
    "            initial_hidden = initial_hidden.to(x_in.device)\n",
    "        hidden_t = initial_hidden\n",
    "            \n",
    "        for t in range(seq_size):\n",
    "            hidden_t = self.rnn_cell(x_in[t], hidden_t)\n",
    "            hiddens.append(hidden_t)\n",
    "        \n",
    "        hiddens = torch.stack(hiddens)\n",
    "            \n",
    "        if self.batch_first:\n",
    "            hiddens = hiddens.permute(1, 0, 2)\n",
    "        return hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5c665209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameClassifier(nn.Module):\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "        rnn_hidden_size, batch_first=True, padding_idx=0):\n",
    "        super(SurnameClassifier, self).__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings=num_embeddings,\n",
    "                                embedding_dim=embedding_size,\n",
    "                                padding_idx=padding_idx)\n",
    "        self.rnn = ElmanRNN(input_size=embedding_size,\n",
    "                            hidden_size=rnn_hidden_size,\n",
    "                            batch_first=batch_first)\n",
    "        self.fc1 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                            out_features=rnn_hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                                out_features=num_classes)\n",
    "        \n",
    "        def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "            x_embedded = self.emb(x_in)\n",
    "            y_out = self.rnn(x_embedded)\n",
    "            \n",
    "            if x_lengths is not None:\n",
    "                y_out = column_gather(y_out, x_lengths)\n",
    "            else:\n",
    "                y_out = y_out[:, -1, :]\n",
    "            \n",
    "            y_out = F.relu(self.fc1(F.dropout(y_out, 0.5)))\n",
    "            y_out = self.fc2(F.dropout(y_out, 0.5))\n",
    "            \n",
    "            if apply_softmax:\n",
    "                y_out = F.softmax(y_out, dim=1)\n",
    "            return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a862b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "46d9aba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "# Data and path information\n",
    "    surname_csv=\"../data/surnames/surnames_with_splits.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch6/surname_classification\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=100,\n",
    "    rnn_hidden_size=64,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=64,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "    \n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "    \n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "    \n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                        args.model_state_file)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4ea45741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "        # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "        # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "            # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "    return train_state\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "66868e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nationality(surname, classifier, vectorizer):\n",
    "    vectorized_surname, vec_length = vectorizer.vectorize(surname)\n",
    "    vectorized_surname = torch.tensor(vectorized_surname).unsqueeze(dim=0)\n",
    "    vec_length = torch.tensor([vec_length], dtype=torch.int64)\n",
    "    result = classifier(vectorized_surname, vec_length, apply_softmax=True)\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    index = indices.item()\n",
    "    prob_value = probability_values.item()\n",
    "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
    "    return {'nationality': predicted_nationality, 'probability': prob_value, 'surname': surname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acd415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
